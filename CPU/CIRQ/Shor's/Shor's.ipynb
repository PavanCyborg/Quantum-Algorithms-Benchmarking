{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb892a-1753-4ca4-b867-d2b7f19dcc10",
   "metadata": {},
   "source": [
    "# Custom Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc63908-52eb-41c3-9f1a-545fce488cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign these values as per your requirements.\n",
    "global min_qubits,max_qubits,skip_qubits,max_circuits,num_shots,Noise_Inclusion\n",
    "\n",
    "min_qubits=3\n",
    "max_qubits=13\n",
    "max_circuits=3\n",
    "num_shots=1000\n",
    "Noise_Inclusion = False\n",
    "saveplots = False\n",
    "\n",
    "\n",
    "Type_of_Simulator = \"Simulator\" #Inputs are \"Simulator\" or \"DensityMatrixSimulator\"\n",
    "\n",
    "Memory_utilization_plot = True\n",
    "gate_counts_plots = True\n",
    "Store_Data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060362a1-64fa-4ad6-ad17-ec0b825634ee",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1169dd7-e2b7-4a40-ba84-3c3cd2d7edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cirq\n",
    "import cirq_utils\n",
    "import time,math\n",
    "import matplotlib.pyplot as plt\n",
    "from shors_utils import getAngles, getAngle, modinv, generate_base, verify_order\n",
    "\n",
    "# saved circuits for display\n",
    "QC_ = None\n",
    "PHIADD_ = None\n",
    "CCPHIADDMODN_ = None\n",
    "CMULTAMODN_ = None\n",
    "CUA_ = None\n",
    "QFT_ = None\n",
    "\n",
    "benchmark_name = \"Deutsch-Jozsa\"\n",
    "\n",
    "# Selection of basis gate set for transpilation\n",
    "basis_selector = \"CZTarget\"\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3b451-e323-4482-8ef3-626632e87b56",
   "metadata": {},
   "source": [
    "# Declaring Backend :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9c2d2-0439-4967-982c-1d40a2fb7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Type_of_Simulator == \"Simulator\":\n",
    "    backend = cirq.Simulator()      # Use Cirq Simulator by default\n",
    "    \n",
    "elif Type_of_Simulator == \"DensityMatrixSimulator\":\n",
    "    backend = cirq.DensityMatrixSimulator()\n",
    "# elif Type_of_Simulator == \"ClassicalStateSimulator\":\n",
    "#     backend = cirq.ClassicalStateSimulator()\n",
    "elif Type_of_Simulator == \"CliffordSimulator\":\n",
    "    backend = cirq.CliffordSimulator()\n",
    "    #only use if ckt has only Clifford Gates for faster execution.\n",
    "else:\n",
    "    print(\"Enter valid Simulator.....\")\n",
    "\n",
    "QV_=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ee7c3-6b88-45bd-8fff-bcb0a44e9d0f",
   "metadata": {},
   "source": [
    "# Algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5d14e-553b-4549-bb52-bab4860109a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gates = 0\n",
    "depth = 0\n",
    "QFTI_ = None\n",
    "############### QFT Circuit\n",
    "def qft_gate(input_size):\n",
    "    global QFT_, num_gates, depth\n",
    "    # allocate qubits\n",
    "    qr = [cirq.GridQubit(i, 0) for i in range(input_size)]\n",
    "    qc = cirq.Circuit()\n",
    "\n",
    "    # Generate multiple groups of diminishing angle CRZs and H gate\n",
    "    for i_qubit in range(0, input_size):\n",
    "    \n",
    "        # start laying out gates from highest order qubit (the hidx)\n",
    "        hidx = input_size - i_qubit - 1\n",
    "        \n",
    "        # if not the highest order qubit, add multiple controlled RZs of decreasing angle\n",
    "        if hidx < input_size - 1:   \n",
    "            num_crzs = i_qubit\n",
    "            for j in range(0, num_crzs):\n",
    "                divisor = 2 ** (num_crzs - j)\n",
    "                qc.append(cirq.CZ(qr[hidx],qr[input_size - j - 1])**(1.0/divisor))\n",
    "                num_gates += 1\n",
    "                depth += 1\n",
    "            \n",
    "        # followed by an H gate (applied to all qubits)\n",
    "        qc.append(cirq.H(qr[hidx]))\n",
    "        num_gates += 1\n",
    "        depth += 1\n",
    "\n",
    "    if QFT_ == None or input_size <= 5:\n",
    "        if input_size < 9: QFT_ = qc\n",
    "        \n",
    "    return cirq_utils.to_gate(num_qubits=input_size, circ=qc, name=\"qft\")\n",
    "        \n",
    "############### Inverse QFT Circuit\n",
    "\n",
    "def inv_qft_gate(input_size):\n",
    "    global QFTI_, num_gates, depth\n",
    "    # allocate qubits\n",
    "    qr = [cirq.GridQubit(i, 0) for i in range(input_size)]\n",
    "    qc = cirq.Circuit()\n",
    "\n",
    "    # Generate multiple groups of diminishing angle CRZs and H gate\n",
    "    for i_qubit in reversed(range(0, input_size)):\n",
    "    \n",
    "        # start laying out gates from highest order qubit (the hidx)\n",
    "        hidx = input_size - i_qubit - 1\n",
    "        \n",
    "        # precede with an H gate (applied to all qubits)\n",
    "        qc.append(cirq.H(qr[hidx]))\n",
    "        num_gates += 1\n",
    "        depth += 1\n",
    "        \n",
    "        # if not the highest order qubit, add multiple controlled RZs of decreasing angle\n",
    "        if hidx < input_size - 1:   \n",
    "            num_crzs = i_qubit\n",
    "            for j in reversed(range(0, num_crzs)):\n",
    "                divisor = 2 ** (num_crzs - j)\n",
    "                qc.append(cirq.CZ(qr[hidx],qr[input_size - j - 1])**(-1.0/divisor))\n",
    "                num_gates += 1\n",
    "                depth += 1\n",
    "\n",
    "    if QFTI_ == None or input_size <= 5:\n",
    "        if input_size < 9: QFTI_ = qc\n",
    "        \n",
    "    return cirq_utils.to_gate(num_qubits=input_size, circ=qc, name=\"inv_qft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3794ba-6d5b-46e9-8237-36db5e8b4d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Circuit Definition\n",
    "\n",
    "# Creation of the circuit that performs addition by a in Fourier Space\n",
    "# Can also be used for subtraction by setting the parameter inv to a value different from 0\n",
    "def phiADD(num_qubits, a):\n",
    "    # allocate qubits\n",
    "    qr = cirq.GridQubit.rect(1,num_qubits,0)\n",
    "    qc = cirq.Circuit()\n",
    "\n",
    "    angle = getAngles(a, num_qubits)\n",
    "    for i in range(0, num_qubits):\n",
    "        # addition\n",
    "        qc.append(cirq.rz(angle[i]).on(qr[i]))\n",
    "\n",
    "    global PHIADD_\n",
    "    if PHIADD_ == None or num_qubits <= 3:\n",
    "        if num_qubits < 4: PHIADD_ = qc\n",
    "\n",
    "    return cirq_utils.to_gate(num_qubits=num_qubits, circ=qc, name=\"\\u03C6ADD\")\n",
    "\n",
    "\n",
    "# Single controlled version of the phiADD circuit\n",
    "def cphiADD(num_qubits, a):\n",
    "    phiadd_gate = phiADD(num_qubits, a)\n",
    "    cphiadd_gate = cirq.ops.ControlledGate(phiadd_gate, num_controls=1)\n",
    "    return cphiadd_gate\n",
    "\n",
    "\n",
    "# Doubly controlled version of the phiADD circuit\n",
    "def ccphiADD(num_qubits, a):\n",
    "    phiadd_gate = phiADD(num_qubits, a)\n",
    "    ccphiadd_gate = cirq.ops.ControlledGate(phiadd_gate, num_controls=2)\n",
    "    return ccphiadd_gate\n",
    "\n",
    "\n",
    "# Circuit that implements doubly controlled modular addition by a (num qubits should be bit count for number N)\n",
    "def ccphiADDmodN(num_qubits, a, N):\n",
    "    qr_ctl = cirq.GridQubit.rect(1,2,0)\n",
    "    qr_main = cirq.GridQubit.rect(1,num_qubits + 1, 1)\n",
    "    qr_ancilla = cirq.GridQubit.rect(1,1,2)\n",
    "    qc = cirq.Circuit()\n",
    "\n",
    "    # Generate relevant gates for circuit\n",
    "    ccphiadda_gate = ccphiADD(num_qubits + 1, a)\n",
    "    ccphiadda_inv_gate = cirq.inverse(ccphiADD(num_qubits + 1, a))\n",
    "    phiaddN_inv_gate = cirq.inverse(phiADD(num_qubits + 1, N))\n",
    "    cphiaddN_gate = cphiADD(num_qubits + 1, N)\n",
    "\n",
    "    # Create circuit\n",
    "    qc.append(ccphiadda_gate.on(*qr_ctl, *qr_main))\n",
    "    qc.append(phiaddN_inv_gate.on(*qr_main))\n",
    "\n",
    "    qc.append(inv_qft_gate(num_qubits + 1).on(*qr_main))\n",
    "    qc.append(cirq.CNOT(qr_main[-1], qr_ancilla[0]))\n",
    "    qc.append(qft_gate(num_qubits + 1).on(*qr_main))\n",
    "\n",
    "    qc.append(cphiaddN_gate.on(*qr_ancilla, *qr_main))\n",
    "    qc.append(ccphiadda_inv_gate.on(*qr_ctl, *qr_main))\n",
    "\n",
    "    qc.append(inv_qft_gate(num_qubits + 1).on(*qr_main))\n",
    "\n",
    "    qc.append(cirq.X(qr_main[-1]))\n",
    "    qc.append(cirq.CNOT(qr_main[-1], qr_ancilla[0]))\n",
    "    qc.append(cirq.X(qr_main[-1]))\n",
    "\n",
    "    qc.append(qft_gate(num_qubits + 1).on(*qr_main))\n",
    "\n",
    "    qc.append(ccphiadda_gate.on(*qr_ctl, *qr_main))\n",
    "\n",
    "    global CCPHIADDMODN_\n",
    "    if CCPHIADDMODN_ == None or num_qubits <= 2:\n",
    "        if num_qubits < 3: CCPHIADDMODN_ = qc\n",
    "\n",
    "    return cirq_utils.to_gate(num_qubits=num_qubits + 4, circ=qc, name=\"cc\\u03C6ADDmodN\")\n",
    "\n",
    "# Circuit that implements the inverse of doubly controlled modular addition by a\n",
    "def ccphiADDmodN_inv(num_qubits, a, N):\n",
    "    cchpiAddmodN_circ = ccphiADDmodN(num_qubits, a, N)\n",
    "    cchpiAddmodN_inv_gate = cirq.inverse(cchpiAddmodN_circ)\n",
    "\n",
    "    return cchpiAddmodN_inv_gate\n",
    "\n",
    "\n",
    "# Creates circuit that implements single controlled modular multiplication by a. n represents the number of bits needed to represent the integer number N\n",
    "def cMULTamodN(n, a, N):\n",
    "    qr_ctl = cirq.GridQubit.rect(1,1,0)\n",
    "    qr_x = cirq.GridQubit.rect(1,n,1)\n",
    "    qr_main_ancilla = cirq.GridQubit.rect(1, n+2,2)\n",
    "    qc = cirq.Circuit()\n",
    "\n",
    "    # quantum Fourier transform only on auxillary qubits\n",
    "    qc.append(qft_gate(n + 1).on(*qr_main_ancilla[:n+1]))\n",
    "\n",
    "    for i in range(n):\n",
    "        ccphiADDmodN_gate = ccphiADDmodN(n, (2 ** i) * a % N, N)\n",
    "\n",
    "        qc.append(ccphiADDmodN_gate.on(*qr_ctl, qr_x[i], *qr_main_ancilla))\n",
    "\n",
    "    # inverse quantum Fourier transform only on auxillary qubits\n",
    "    qc.append(inv_qft_gate(n + 1).on(*qr_main_ancilla[:n+1]))\n",
    "\n",
    "    global CMULTAMODN_\n",
    "    if CMULTAMODN_ == None or n <= 2:\n",
    "        if n < 3: CMULTAMODN_ = qc\n",
    "\n",
    "    return cirq_utils.to_gate(num_qubits=2*n+3, circ=qc, name=\"cMULTamodN\")\n",
    "\n",
    "\n",
    "# Creates circuit that implements single controlled Ua gate. n represents the number of bits\n",
    "# needed to represent the integer number N\n",
    "def controlled_Ua(n, a, exponent, N):\n",
    "    qr_ctl = cirq.GridQubit.rect(1,1,0)\n",
    "    qr_x = cirq.GridQubit.rect(1,n,1)\n",
    "    qr_main = cirq.GridQubit.rect(1,n,2)\n",
    "    qr_ancilla = cirq.GridQubit.rect(1, 2,3)\n",
    "    qc = cirq.Circuit()\n",
    "\n",
    "    # Generate Gates\n",
    "    a_inv = modinv(a ** exponent, N)\n",
    "    cMULTamodN_gate = cMULTamodN(n, a ** exponent, N)\n",
    "    cMULTamodN_inv_gate = cirq.inverse(cMULTamodN(n, a_inv, N))\n",
    "\n",
    "    qc.append(cMULTamodN_gate.on(*qr_ctl,*qr_x,*qr_main,*qr_ancilla))\n",
    "\n",
    "    for i in range(n):\n",
    "        qc.append(cirq.CSWAP(*qr_ctl, qr_x[i], qr_main[i]))\n",
    "\n",
    "    qc.append(cMULTamodN_inv_gate.on(*qr_ctl,*qr_x,*qr_main,*qr_ancilla))\n",
    "\n",
    "    global CUA_\n",
    "    if CUA_ == None or n <= 2:\n",
    "        if n < 3: CUA_ = qc\n",
    "\n",
    "    return cirq_utils.to_gate(num_qubits=2*n+3, circ=qc, name=f\"C-U^{a ** exponent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a893a1e-b787-4d00-a815-0e479ad222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Shor's Order Finding Algorithm given a 'number' to factor,\n",
    "# the 'base' of exponentiation, and the number of qubits required 'input_size'\n",
    "\n",
    "def ShorsAlgorithm(number, base, method):\n",
    "    # Create count of qubits to use to represent the number to factor\n",
    "    # NOTE: this should match the number of bits required to represent (number)\n",
    "    n = int(math.ceil(math.log(number, 2)))\n",
    "\n",
    "    # Standard Shors Algorithm\n",
    "    if method == 1:\n",
    "        num_qubits = 4 * n + 2\n",
    "\n",
    "        print(f\"... running Shors to find order of [ {base}^x mod {number} ] using num_qubits={num_qubits}\")\n",
    "\n",
    "        # Create a circuit and allocate necessary qubits\n",
    "        qr_counting = cirq.GridQubit.rect(1,2*n,0)  # Register for sequential QFT\n",
    "        qr_mult = cirq.GridQubit.rect(1,n,1)  # Register for multiplications\n",
    "        qr_aux = cirq.GridQubit.rect(1,n+2,2) # Register for addition and multiplication\n",
    "        qc = cirq.Circuit()\n",
    "\n",
    "        # Initialize multiplication register to 1 and counting register to superposition state\n",
    "        qc.append(cirq.H.on_each(*qr_counting))\n",
    "        qc.append(cirq.X(qr_mult[0]))\n",
    "\n",
    "        # Apply Multiplication Gates for exponentiation\n",
    "        for i in reversed(range(2 * n)):\n",
    "            cUa_gate = controlled_Ua(n, int(base), 2 ** (2 * n - 1 - i), number)\n",
    "            qc.append(cUa_gate.on(qr_counting[i],*qr_mult,*qr_aux))\n",
    "\n",
    "        qc.append(inv_qft_gate(2 * n).on(*qr_counting))\n",
    "\n",
    "        # measure counting register\n",
    "        qc.append(cirq.measure(*[qr_counting[i_qubit] for i_qubit in range(2*n)], key='result'))\n",
    "\n",
    "    # Method 2 requires mid circuit measurement currently unavailable on cirq hardware\n",
    "    '''\n",
    "    elif method == 2:\n",
    "\n",
    "        # Create a circuit and allocate necessary qubits\n",
    "        num_qubits = 2 * n + 3\n",
    "\n",
    "        print(f\"... running Shors to find order of [ {base}^x mod {number} ] using num_qubits={num_qubits}\")\n",
    "\n",
    "        qr_counting = QuantumRegister(1)  # Single qubit for sequential QFT\n",
    "        qr_mult = QuantumRegister(n)  # Register for multiplications\n",
    "        qr_aux = QuantumRegister(n + 2)  # Register for addition and multiplication\n",
    "        cr_data = ClassicalRegister(2 * n)  # Register for measured values of QFT\n",
    "        cr_aux = ClassicalRegister(\n",
    "            1)  # Register to reset the state of the counting register based on previous measurements\n",
    "        qc = QuantumCircuit(qr_counting, qr_mult, qr_aux, cr_data, cr_aux, name=\"main\")\n",
    "\n",
    "        # Initialize multiplication register to 1\n",
    "        qc.x(qr_mult[0])\n",
    "\n",
    "        # perform modular exponentiation 2*n times\n",
    "        for k in range(2 * n):\n",
    "\n",
    "            # Reset the top qubit to 0 if the previous measurement was 1\n",
    "            qc.x(qr_counting).c_if(cr_aux, 1)\n",
    "            qc.h(qr_counting)\n",
    "\n",
    "            cUa_gate = controlled_Ua(n, base, 2 ** (2 * n - 1 - k), number)\n",
    "\n",
    "            # Create relevant temporary qubit list\n",
    "            qubits = [qr_counting[0]];\n",
    "            qubits.extend([i for i in qr_mult]);\n",
    "            qubits.extend([i for i in qr_aux])\n",
    "\n",
    "            qc.append(cUa_gate, qubits)\n",
    "\n",
    "            # perform inverse QFT --> Rotations conditioned on previous outcomes\n",
    "            for i in range(2 ** k):\n",
    "                qc.p(getAngle(i, k), qr_counting[0]).c_if(cr_data, i)\n",
    "\n",
    "            qc.h(qr_counting)\n",
    "            qc.measure(qr_counting[0], cr_data[k])\n",
    "            qc.measure(qr_counting[0], cr_aux[0])\n",
    "    '''\n",
    "    global QC_, QFT_\n",
    "    if QC_ == None or n <= 2:\n",
    "        if n < 3: QC_ = qc\n",
    "    if QFT_ == None or n <= 2:\n",
    "        if n < 3: QFT_ = qft_gate(n + 1)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbc5d3-98fa-46ef-80c3-06c4a7a97be0",
   "metadata": {},
   "source": [
    "# Noise Parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2c64e-c22c-4773-8a47-41964407fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of depolarizing noise model\n",
    "depolarizing_error = cirq.depolarize(p=0.01)  # p is the probability of an error\n",
    "\n",
    "# Example of bit flip noise model\n",
    "bit_flip_error = cirq.bit_flip(p=0.01)  # p is the probability of a bit flip error\n",
    "\n",
    "# Example of phase flip noise model\n",
    "phase_flip_error = cirq.phase_flip(p=0.01)  # p is the probability of a phase flip error\n",
    "\n",
    "# Example of amplitude damping noise model\n",
    "amplitude_damping_error = cirq.amplitude_damp(gamma=0.01)  # gamma is the damping parameter\n",
    "\n",
    "noise_parameters = [depolarizing_error,bit_flip_error,phase_flip_error,amplitude_damping_error]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8506b56-e48a-448a-9a80-63fa86ba1029",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fidelity Calculations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267a29f-ebca-4ceb-9c1b-7dab35fe013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniform distribution function commonly used\n",
    "def rescale_fidelity(fidelity, floor_fidelity, new_floor_fidelity):\n",
    "    \"\"\"\n",
    "    Linearly rescales our fidelities to allow comparisons of fidelities across benchmarks\n",
    "    \n",
    "    fidelity: raw fidelity to rescale\n",
    "    floor_fidelity: threshold fidelity which is equivalent to random guessing\n",
    "    new_floor_fidelity: what we rescale the floor_fidelity to \n",
    "\n",
    "    Ex, with floor_fidelity = 0.25, new_floor_fidelity = 0.0:\n",
    "        1 -> 1;\n",
    "        0.25 -> 0;\n",
    "        0.5 -> 0.3333;\n",
    "    \"\"\"\n",
    "    rescaled_fidelity = (1-new_floor_fidelity)/(1-floor_fidelity) * (fidelity - 1) + 1\n",
    "    \n",
    "    # ensure fidelity is within bounds (0, 1)\n",
    "    if rescaled_fidelity < 0:\n",
    "        rescaled_fidelity = 0.0\n",
    "    if rescaled_fidelity > 1:\n",
    "        rescaled_fidelity = 1.0\n",
    "    \n",
    "    return rescaled_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9266f5c-9c2f-4313-a012-a8be66e58bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_dist(num_state_qubits):\n",
    "    dist = {}\n",
    "    for i in range(2**num_state_qubits):\n",
    "        key = bin(i)[2:].zfill(num_state_qubits)\n",
    "        dist[key] = 1/(2**num_state_qubits)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fad0c7-6b52-416d-9bae-252b693df350",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis methods to be expanded and eventually compiled into a separate analysis.py file\n",
    "import math, functools\n",
    "\n",
    "def hellinger_fidelity_with_expected(p, q):\n",
    "    \"\"\" p: result distribution, may be passed as a counts distribution\n",
    "        q: the expected distribution to be compared against\n",
    "\n",
    "    References:\n",
    "        `Hellinger Distance @ wikipedia <https://en.wikipedia.org/wiki/Hellinger_distance>`_\n",
    "        Qiskit Hellinger Fidelity Function\n",
    "    \"\"\"\n",
    "    p_sum = sum(p.values())\n",
    "    q_sum = sum(q.values())\n",
    "\n",
    "    if q_sum == 0:\n",
    "        print(\"ERROR: polarization_fidelity(), expected distribution is invalid, all counts equal to 0\")\n",
    "        return 0\n",
    "\n",
    "    p_normed = {}\n",
    "    for key, val in p.items():\n",
    "        p_normed[key] = val/p_sum\n",
    "        # if p_sum != 0:\n",
    "        #     p_normed[key] = val/p_sum\n",
    "        # else:\n",
    "        #     p_normed[key] = 0\n",
    "\n",
    "    q_normed = {}\n",
    "    for key, val in q.items():\n",
    "        q_normed[key] = val/q_sum\n",
    "\n",
    "    total = 0\n",
    "    for key, val in p_normed.items():\n",
    "        if key in q_normed.keys():\n",
    "            total += (np.sqrt(val) - np.sqrt(q_normed[key]))**2\n",
    "            del q_normed[key]\n",
    "        else:\n",
    "            total += val\n",
    "    total += sum(q_normed.values())\n",
    "    \n",
    "    # in some situations (error mitigation) this can go negative, use abs value\n",
    "    if total < 0:\n",
    "        print(f\"WARNING: using absolute value in fidelity calculation\")\n",
    "        total = abs(total)\n",
    "        \n",
    "    dist = np.sqrt(total)/np.sqrt(2)\n",
    "    fidelity = (1-dist**2)**2\n",
    "\n",
    "    return fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84c6f2-6d6b-44d6-9998-17df560ae18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarization_fidelity(counts, correct_dist, thermal_dist=None):\n",
    "    \"\"\"\n",
    "    Combines Hellinger fidelity and polarization rescaling into fidelity calculation\n",
    "    used in every benchmark\n",
    "\n",
    "    counts: the measurement outcomes after `num_shots` algorithm runs\n",
    "    correct_dist: the distribution we expect to get for the algorithm running perfectly\n",
    "    thermal_dist: optional distribution to pass in distribution from a uniform\n",
    "                  superposition over all states. If `None`: generated as \n",
    "                  `uniform_dist` with the same qubits as in `counts`\n",
    "                  \n",
    "    returns both polarization fidelity and the hellinger fidelity\n",
    "\n",
    "    Polarization from: `https://arxiv.org/abs/2008.11294v1`\n",
    "    \"\"\"\n",
    "    num_measured_qubits = len(list(correct_dist.keys())[0])\n",
    "    #print(num_measured_qubits)\n",
    "    \n",
    "    counts = {k.zfill(num_measured_qubits): v for k, v in counts.items()}\n",
    "    \n",
    "    # calculate hellinger fidelity between measured expectation values and correct distribution\n",
    "    hf_fidelity = hellinger_fidelity_with_expected(counts,correct_dist)\n",
    "    \n",
    "    # to limit cpu and memory utilization, skip noise correction if more than 16 measured qubits\n",
    "    if num_measured_qubits > 16:\n",
    "        return { 'fidelity':hf_fidelity, 'hf_fidelity':hf_fidelity }\n",
    "\n",
    "    # if not provided, generate thermal dist based on number of qubits\n",
    "    if thermal_dist == None:\n",
    "        thermal_dist = uniform_dist(num_measured_qubits)\n",
    "\n",
    "    # set our fidelity rescaling value as the hellinger fidelity for a depolarized state\n",
    "    floor_fidelity = hellinger_fidelity_with_expected(thermal_dist, correct_dist)\n",
    "\n",
    "    # rescale fidelity result so uniform superposition (random guessing) returns fidelity\n",
    "    # rescaled to 0 to provide a better measure of success of the algorithm (polarization)\n",
    "    new_floor_fidelity = 0\n",
    "    fidelity = rescale_fidelity(hf_fidelity, floor_fidelity, new_floor_fidelity)\n",
    "\n",
    "    return { 'fidelity':fidelity, 'hf_fidelity':hf_fidelity }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e52a5-c4d6-4bba-a9ef-b811084a58cc",
   "metadata": {},
   "source": [
    "### Mathematical formulae:\n",
    "\n",
    "**hf_fidelity :** \n",
    "$$ F_s(P_{ideal},P_{output}) = \\biggr[\\sum_{x}\\sqrt{P_{output}(x)P_{ideal}(x)}\\biggr]^2$$\n",
    "\n",
    "**floor_fidelity :**\n",
    "$$F_s(P_{ideal},P_{uniform})$$\n",
    "\n",
    "$$\\implies F_{raw}(P_{ideal},P_{output}) = \\frac{F_s(P_{ideal},P_{output}) - F_s(P_{ideal},P_{uniform})}{1-F_s(P_{ideal},P_{uniform})}$$\n",
    "\n",
    "**fidelity (or Normalized or Rescaled fidelity) :**\n",
    "$$F(P_{ideal},P_{output}) = max\\biggr\\{F_{raw}(P_{ideal},P_{output}),0\\biggr\\}$$\n",
    "\n",
    "\n",
    "### Example:\n",
    "\n",
    "The equations provided in the paper outline a process for calculating normalized fidelities in the context of quantum computing benchmarks. Here's a detailed explanation of each equation and its significance:\n",
    "\n",
    "### Equation (1): State Fidelity\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( \\sum_x \\sqrt{P_{\\text{output}}(x)} \\sqrt{P_{\\text{ideal}}(x)} \\right)^2 $$\n",
    "\n",
    "This equation calculates the state fidelity, $ F_s $, which measures the similarity between the ideal probability distribution $ P_{\\text{ideal}} $ and the output probability distribution $ P_{\\text{output}} $. The square root of the product of probabilities for each state $ x $ is summed, and the result is squared to get the fidelity.\n",
    "\n",
    "### Equation (2): Normalized Fidelity\n",
    "$$ F(P_{\\text{ideal}}, P_{\\text{output}}) = \\max(F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}), 0) $$\n",
    "\n",
    "This equation defines the normalized fidelity, $ F $, which ensures that the fidelity is non-negative. It takes the raw fidelity $ F_{\\text{raw}} $ and applies a max function to ensure the result is at least 0.\n",
    "\n",
    "### Equation (3): Raw Fidelity\n",
    "$$ F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}) = \\frac{F_s (P_{\\text{ideal}}, P_{\\text{output}}) - F_s (P_{\\text{ideal}}, P_{\\text{uni}})}{1 - F_s (P_{\\text{ideal}}, P_{\\text{uni}})} $$\n",
    "\n",
    "The raw fidelity $ F_{\\text{raw}} $ adjusts the state fidelity by comparing it to a uniform distribution $ P_{\\text{uni}} $. This adjustment accounts for the baseline performance of random guessing.\n",
    "\n",
    "- $ P_{\\text{uni}} $: A uniform probability distribution where all states are equally probable.\n",
    "\n",
    "### Explanation with Example\n",
    "\n",
    "Let's consider a simple example with 2 qubits.\n",
    "\n",
    "#### 1. State Fidelity Calculation\n",
    "- **Ideal distribution ($ P_{\\text{ideal}} $)**: \\{ \"00\": 0.25, \"01\": 0.25, \"10\": 0.25, \"11\": 0.25 \\}\n",
    "- **Output distribution ($ P_{\\text{output}} $)**: \\{ \"00\": 0.5, \"01\": 0.25, \"10\": 0.25, \"11\": 0.0 \\}\n",
    "\n",
    "First, compute $ F_s (P_{\\text{ideal}}, P_{\\text{output}}) $:\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( \\sqrt{0.5} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.0} \\cdot \\sqrt{0.25} \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( 0.3536 + 0.25 + 0.25 + 0 \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( 0.8536 \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = 0.7286 $$\n",
    "\n",
    "#### 2. Uniform Distribution Fidelity\n",
    "- **Uniform distribution ($ P_{\\text{uni}} $)**: \\{ \"00\": 0.25, \"01\": 0.25, \"10\": 0.25, \"11\": 0.25 \\}\n",
    "\n",
    "Compute $ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) $:\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) = \\left( \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) = \\left( 0.25 + 0.25 + 0.25 + 0.25 \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) = 1.0 $$\n",
    "\n",
    "#### 3. Raw Fidelity Calculation\n",
    "$$ F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}) = \\frac{0.7286 - 1.0}{1 - 1.0} $$\n",
    "$$ F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}) = \\frac{-0.2714}{0} $$\n",
    "Since dividing by zero is undefined, we need to handle this case. If the uniform distribution fidelity is 1, raw fidelity is set to -1.\n",
    "\n",
    "#### 4. Normalized Fidelity Calculation\n",
    "$$ F(P_{\\text{ideal}}, P_{\\text{output}}) = \\max(-1, 0) $$\n",
    "$$ F(P_{\\text{ideal}}, P_{\\text{output}}) = 0 $$\n",
    "\n",
    "In this example, the normalized fidelity is 0, indicating that the output distribution is no better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7d14a-92ee-46f4-bff2-0ce6de620c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions of Volumetric Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f39ea1-f924-4b81-9ad0-5d8b785912a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "############### Color Map functions\n",
    " \n",
    "# Create a selection of colormaps from which to choose; default to custom_spectral\n",
    "cmap_spectral = plt.get_cmap('Spectral')\n",
    "cmap_greys = plt.get_cmap('Greys')\n",
    "cmap_blues = plt.get_cmap('Blues')\n",
    "cmap_custom_spectral = None\n",
    "\n",
    "# the default colormap is the spectral map\n",
    "cmap = cmap_spectral\n",
    "cmap_orig = cmap_spectral\n",
    "\n",
    "# current cmap normalization function (default None)\n",
    "cmap_norm = None\n",
    "\n",
    "default_fade_low_fidelity_level = 0.16\n",
    "default_fade_rate = 0.7\n",
    "\n",
    "\n",
    "# Specify a normalization function here (default None)\n",
    "def set_custom_cmap_norm(vmin, vmax):\n",
    "\n",
    "    global cmap_norm\n",
    "    \n",
    "    if vmin == vmax or (vmin == 0.0 and vmax == 1.0):\n",
    "        print(\"... setting cmap norm to None\")\n",
    "        cmap_norm = None\n",
    "    else:\n",
    "        print(f\"... setting cmap norm to [{vmin}, {vmax}]\")\n",
    "        cmap_norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "# Remake the custom spectral colormap with user settings\n",
    "def set_custom_cmap_style(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "            \n",
    "    #print(\"... set custom map style\")\n",
    "    global cmap, cmap_custom_spectral, cmap_orig\n",
    "    cmap_custom_spectral = create_custom_spectral_cmap(\n",
    "                fade_low_fidelity_level=fade_low_fidelity_level, fade_rate=fade_rate)\n",
    "    cmap = cmap_custom_spectral\n",
    "    cmap_orig = cmap_custom_spectral\n",
    "\n",
    "\n",
    "# Create the custom spectral colormap from the base spectral\n",
    "def create_custom_spectral_cmap(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "\n",
    "    # determine the breakpoint from the fade level\n",
    "    num_colors = 100\n",
    "    breakpoint = round(fade_low_fidelity_level * num_colors)\n",
    "    \n",
    "    # get color list for spectral map\n",
    "    spectral_colors = [cmap_spectral(v/num_colors) for v in range(num_colors)]\n",
    "\n",
    "    #print(fade_rate)\n",
    "    \n",
    "    # create a list of colors to replace those below the breakpoint\n",
    "    # and fill with \"faded\" color entries (in reverse)\n",
    "    low_colors = [0] * breakpoint\n",
    "    #for i in reversed(range(breakpoint)):\n",
    "    for i in range(breakpoint):\n",
    "    \n",
    "        # x is index of low colors, normalized 0 -> 1\n",
    "        x = i / breakpoint\n",
    "    \n",
    "        # get color at this index\n",
    "        bc = spectral_colors[i]\n",
    "        r0 = bc[0]\n",
    "        g0 = bc[1]\n",
    "        b0 = bc[2]\n",
    "        z0 = bc[3]\n",
    "        \n",
    "        r_delta = 0.92 - r0\n",
    "        \n",
    "        #print(f\"{x} {bc} {r_delta}\")\n",
    "         \n",
    "        # compute saturation and greyness ratio\n",
    "        sat_ratio = 1 - x\n",
    "        \n",
    "        #grey_ratio = 1 - x\n",
    "        '''  attempt at a reflective gradient   \n",
    "        if i >= breakpoint/2:\n",
    "            xf = 2*(x - 0.5)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (yf + 0.5)\n",
    "        else:\n",
    "            xf = 2*(0.5 - x)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (0.5 - yf)\n",
    "        '''   \n",
    "        grey_ratio = 1 - math.pow(x, 1/fade_rate)\n",
    "        \n",
    "        #print(f\"  {xf} {yf} \")\n",
    "        #print(f\"  {sat_ratio} {grey_ratio}\")\n",
    "\n",
    "        r = r0 + r_delta * sat_ratio\n",
    "        \n",
    "        g_delta = r - g0\n",
    "        b_delta = r - b0\n",
    "        g = g0 + g_delta * grey_ratio\n",
    "        b = b0 + b_delta * grey_ratio \n",
    "            \n",
    "        #print(f\"{r} {g} {b}\\n\")    \n",
    "        low_colors[i] = (r,g,b,z0)\n",
    "        \n",
    "    #print(low_colors)\n",
    "\n",
    "    # combine the faded low colors with the regular spectral cmap to make a custom version\n",
    "    cmap_custom_spectral = ListedColormap(low_colors + spectral_colors[breakpoint:])\n",
    "\n",
    "    #spectral_colors = [cmap_custom_spectral(v/10) for v in range(10)]\n",
    "    #for i in range(10): print(spectral_colors[i])\n",
    "    #print(\"\")\n",
    "    \n",
    "    return cmap_custom_spectral\n",
    "\n",
    "# Make the custom spectral color map the default on module init\n",
    "set_custom_cmap_style()\n",
    "\n",
    "# Arrange the stored annotations optimally and add to plot \n",
    "def anno_volumetric_data(ax, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True):\n",
    "    \n",
    "    # sort all arrays by the x point of the text (anno_offs)\n",
    "    global x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos\n",
    "    all_annos = sorted(zip(x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos))\n",
    "    x_anno_offs = [a for a,b,c,d,e in all_annos]\n",
    "    y_anno_offs = [b for a,b,c,d,e in all_annos]\n",
    "    anno_labels = [c for a,b,c,d,e in all_annos]\n",
    "    x_annos = [d for a,b,c,d,e in all_annos]\n",
    "    y_annos = [e for a,b,c,d,e in all_annos]\n",
    "    \n",
    "    #print(f\"{x_anno_offs}\")\n",
    "    #print(f\"{y_anno_offs}\")\n",
    "    #print(f\"{anno_labels}\")\n",
    "    \n",
    "    for i in range(len(anno_labels)):\n",
    "        x_anno = x_annos[i]\n",
    "        y_anno = y_annos[i]\n",
    "        x_anno_off = x_anno_offs[i]\n",
    "        y_anno_off = y_anno_offs[i]\n",
    "        label = anno_labels[i]\n",
    "        \n",
    "        if i > 0:\n",
    "            x_delta = abs(x_anno_off - x_anno_offs[i - 1])\n",
    "            y_delta = abs(y_anno_off - y_anno_offs[i - 1])\n",
    "            \n",
    "            if y_delta < 0.7 and x_delta < 2:\n",
    "                y_anno_off = y_anno_offs[i] = y_anno_offs[i - 1] - 0.6\n",
    "                #x_anno_off = x_anno_offs[i] = x_anno_offs[i - 1] + 0.1\n",
    "                    \n",
    "        ax.annotate(label,\n",
    "            xy=(x_anno+0.0, y_anno+0.1),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.0,\n",
    "                width=0.5, headwidth=4, headlength=5, edgecolor=(0.8,0.8,0.8)),\n",
    "            xytext=(x_anno_off + labelpos[0], y_anno_off + labelpos[1]),\n",
    "            rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='baseline',\n",
    "            color=(0.2,0.2,0.2),\n",
    "            clip_on=True)\n",
    "    if saveplots == True:\n",
    "        plt.savefig(\"VolumetricPlotSample.jpg\")\n",
    "\n",
    "# Plot one group of data for volumetric presentation    \n",
    "def plot_volumetric_data(ax, w_data, d_data, f_data, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True, w_max=18, do_label=False, do_border=True,\n",
    "        x_size=1.0, y_size=1.0, zorder=1, offset_flag=False,\n",
    "        max_depth=0, suppress_low_fidelity=False):\n",
    "\n",
    "    # since data may come back out of order, save point at max y for annotation\n",
    "    i_anno = 0\n",
    "    x_anno = 0 \n",
    "    y_anno = 0\n",
    "    \n",
    "    # plot data rectangles\n",
    "    low_fidelity_count = True\n",
    "    \n",
    "    last_y = -1\n",
    "    k = 0\n",
    "\n",
    "    # determine y-axis dimension for one pixel to use for offset of bars that start at 0\n",
    "    (_, dy) = get_pixel_dims(ax)\n",
    "    \n",
    "    # do this loop in reverse to handle the case where earlier cells are overlapped by later cells\n",
    "    for i in reversed(range(len(d_data))):\n",
    "        x = depth_index(d_data[i], depth_base)\n",
    "        y = float(w_data[i])\n",
    "        f = f_data[i]\n",
    "        \n",
    "        # each time we star a new row, reset the offset counter\n",
    "        # DEVNOTE: this is highly specialized for the QA area plots, where there are 8 bars\n",
    "        # that represent time starting from 0 secs.  We offset by one pixel each and center the group\n",
    "        if y != last_y:\n",
    "            last_y = y;\n",
    "            k = 3              # hardcoded for 8 cells, offset by 3\n",
    "        \n",
    "        #print(f\"{i = } {x = } {y = }\")\n",
    "        \n",
    "        if max_depth > 0 and d_data[i] > max_depth:\n",
    "            #print(f\"... excessive depth (2), skipped; w={y} d={d_data[i]}\")\n",
    "            break;\n",
    "            \n",
    "        # reject cells with low fidelity\n",
    "        if suppress_low_fidelity and f < suppress_low_fidelity_level:\n",
    "            if low_fidelity_count: break\n",
    "            else: low_fidelity_count = True\n",
    "        \n",
    "        # the only time this is False is when doing merged gradation plots\n",
    "        if do_border == True:\n",
    "        \n",
    "            # this case is for an array of x_sizes, i.e. each box has different width\n",
    "            if isinstance(x_size, list):\n",
    "                \n",
    "                # draw each of the cells, with no offset\n",
    "                if not offset_flag:\n",
    "                    ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size[i], y_size=y_size, zorder=zorder))\n",
    "                    \n",
    "                # use an offset for y value, AND account for x and width to draw starting at 0\n",
    "                else:\n",
    "                    ax.add_patch(box_at((x/2 + x_size[i]/4), y + k*dy, f, type=type, fill=fill, x_size=x+ x_size[i]/2, y_size=y_size, zorder=zorder))\n",
    "                \n",
    "            # this case is for only a single cell\n",
    "            else:\n",
    "                ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size, y_size=y_size))\n",
    "\n",
    "        # save the annotation point with the largest y value\n",
    "        if y >= y_anno:\n",
    "            x_anno = x\n",
    "            y_anno = y\n",
    "            i_anno = i\n",
    "        \n",
    "        # move the next bar down (if using offset)\n",
    "        k -= 1\n",
    "    \n",
    "    # if no data rectangles plotted, no need for a label\n",
    "    if x_anno == 0 or y_anno == 0:\n",
    "        return\n",
    "        \n",
    "    x_annos.append(x_anno)\n",
    "    y_annos.append(y_anno)\n",
    "    \n",
    "    anno_dist = math.sqrt( (y_anno - 1)**2 + (x_anno - 1)**2 )\n",
    "    \n",
    "    # adjust radius of annotation circle based on maximum width of apps\n",
    "    anno_max = 10\n",
    "    if w_max > 10:\n",
    "        anno_max = 14\n",
    "    if w_max > 14:\n",
    "        anno_max = 18\n",
    "        \n",
    "    scale = anno_max / anno_dist\n",
    "\n",
    "    # offset of text from end of arrow\n",
    "    if scale > 1:\n",
    "        x_anno_off = scale * x_anno - x_anno - 0.5\n",
    "        y_anno_off = scale * y_anno - y_anno\n",
    "    else:\n",
    "        x_anno_off = 0.7\n",
    "        y_anno_off = 0.5\n",
    "        \n",
    "    x_anno_off += x_anno\n",
    "    y_anno_off += y_anno\n",
    "    \n",
    "    # print(f\"... {xx} {yy} {anno_dist}\")\n",
    "    x_anno_offs.append(x_anno_off)\n",
    "    y_anno_offs.append(y_anno_off)\n",
    "    \n",
    "    anno_labels.append(label)\n",
    "    \n",
    "    if do_label:\n",
    "        ax.annotate(label, xy=(x_anno+labelpos[0], y_anno+labelpos[1]), rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='bottom', color=(0.2,0.2,0.2))\n",
    "\n",
    "x_annos = []\n",
    "y_annos = []\n",
    "x_anno_offs = []\n",
    "y_anno_offs = []\n",
    "anno_labels = []\n",
    "\n",
    "# init arrays to hold annotation points for label spreading\n",
    "def vplot_anno_init ():\n",
    "\n",
    "    global x_annos, y_annos, x_anno_offs, y_anno_offs, anno_labels\n",
    "    \n",
    "    x_annos = []\n",
    "    y_annos = []\n",
    "    x_anno_offs = []\n",
    "    y_anno_offs = []\n",
    "    anno_labels = []\n",
    "\n",
    "# Number of ticks on volumetric depth axis\n",
    "max_depth_log = 22\n",
    "\n",
    "# average transpile factor between base QV depth and our depth based on results from QV notebook\n",
    "QV_transpile_factor = 12.7 \n",
    "\n",
    "# format a number using K,M,B,T for large numbers, optionally rounding to 'digits' decimal places if num > 1\n",
    "# (sign handling may be incorrect)\n",
    "def format_number(num, digits=0):\n",
    "    if isinstance(num, str): num = float(num)\n",
    "    num = float('{:.3g}'.format(abs(num)))\n",
    "    sign = ''\n",
    "    metric = {'T': 1000000000000, 'B': 1000000000, 'M': 1000000, 'K': 1000, '': 1}\n",
    "    for index in metric:\n",
    "        num_check = num / metric[index]\n",
    "        if num_check >= 1:\n",
    "            num = round(num_check, digits)\n",
    "            sign = index\n",
    "            break\n",
    "    numstr = f\"{str(num)}\"\n",
    "    if '.' in numstr:\n",
    "        numstr = numstr.rstrip('0').rstrip('.')\n",
    "    return f\"{numstr}{sign}\"\n",
    "\n",
    "# Return the color associated with the spcific value, using color map norm\n",
    "def get_color(value):\n",
    "    \n",
    "    # if there is a normalize function installed, scale the data\n",
    "    if cmap_norm:\n",
    "        value = float(cmap_norm(value))\n",
    "        \n",
    "    if cmap == cmap_spectral:\n",
    "        value = 0.05 + value*0.9\n",
    "    elif cmap == cmap_blues:\n",
    "        value = 0.00 + value*1.0\n",
    "    else:\n",
    "        value = 0.0 + value*0.95\n",
    "        \n",
    "    return cmap(value)\n",
    "\n",
    "# Return the x and y equivalent to a single pixel for the given plot axis\n",
    "def get_pixel_dims(ax):\n",
    "\n",
    "    # transform 0 -> 1 to pixel dimensions\n",
    "    pixdims = ax.transData.transform([(0,1),(1,0)])-ax.transData.transform((0,0))\n",
    "    xpix = pixdims[1][0]\n",
    "    ypix = pixdims[0][1]\n",
    "    \n",
    "    #determine x- and y-axis dimension for one pixel \n",
    "    dx = (1 / xpix)\n",
    "    dy = (1 / ypix)\n",
    "    \n",
    "    return (dx, dy)\n",
    "\n",
    "############### Helper functions\n",
    " \n",
    "# return the base index for a circuit depth value\n",
    "# take the log in the depth base, and add 1\n",
    "def depth_index(d, depth_base):\n",
    "    if depth_base <= 1:\n",
    "        return d\n",
    "    if d == 0:\n",
    "        return 0\n",
    "    return math.log(d, depth_base) + 1\n",
    "\n",
    "# draw a box at x,y with various attributes   \n",
    "def box_at(x, y, value, type=1, fill=True, x_size=1.0, y_size=1.0, alpha=1.0, zorder=1):\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Rectangle((x - (x_size/2), y - (y_size/2)), x_size, y_size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5*y_size,\n",
    "             zorder=zorder)\n",
    "\n",
    "# draw a circle at x,y with various attributes \n",
    "def circle_at(x, y, value, type=1, fill=True):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Circle((x, y), size/2,\n",
    "             alpha = 0.7,                       # DEVNOTE: changed to 0.7 from 0.5, to handle only one cell\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5)\n",
    "             \n",
    "def box4_at(x, y, value, type=1, fill=True, alpha=1.0):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.3,0.3,0.3)\n",
    "    ec = fc\n",
    "    \n",
    "    return Rectangle((x - size/8, y - size/2), size/4, size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.1)\n",
    "\n",
    "# Draw a Quantum Volume rectangle with specified width and depth, and grey-scale value \n",
    "def qv_box_at(x, y, qv_width, qv_depth, value, depth_base):\n",
    "    #print(f\"{qv_width} {qv_depth} {depth_index(qv_depth, depth_base)}\")\n",
    "    return Rectangle((x - 0.5, y - 0.5), depth_index(qv_depth, depth_base), qv_width,\n",
    "             edgecolor = (value,value,value),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=1)\n",
    "\n",
    "def bkg_box_at(x, y, value=0.9):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "             \n",
    "def bkg_empty_box_at(x, y):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (1.0,1.0,1.0),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "\n",
    "# Plot the background for the volumetric analysis    \n",
    "def plot_volumetric_background(max_qubits=11, QV=32, depth_base=2, suptitle=None, avail_qubits=0, colorbar_label=\"Avg Result Fidelity\"):\n",
    "\n",
    "    if suptitle == None:\n",
    "        suptitle = f\"Volumetric Positioning\\nCircuit Dimensions and Fidelity Overlaid on Quantum Volume = {QV}\"\n",
    "\n",
    "    QV0 = QV\n",
    "    qv_estimate = False\n",
    "    est_str = \"\"\n",
    "    if QV == 0:                 # QV = 0 indicates \"do not draw QV background or label\"\n",
    "        QV = 2048\n",
    "        \n",
    "    elif QV < 0:                # QV < 0 indicates \"add est. to label\"\n",
    "        QV = -QV\n",
    "        qv_estimate = True\n",
    "        est_str = \" (est.)\"\n",
    "        \n",
    "    if avail_qubits > 0 and max_qubits > avail_qubits:\n",
    "        max_qubits = avail_qubits\n",
    "        \n",
    "    max_width = 13\n",
    "    if max_qubits > 11: max_width = 18\n",
    "    if max_qubits > 14: max_width = 20\n",
    "    if max_qubits > 16: max_width = 24\n",
    "    if max_qubits > 24: max_width = 33\n",
    "    #print(f\"... {avail_qubits} {max_qubits} {max_width}\")\n",
    "    \n",
    "    plot_width = 6.8\n",
    "    plot_height = 0.5 + plot_width * (max_width / max_depth_log)\n",
    "    #print(f\"... {plot_width} {plot_height}\")\n",
    "    \n",
    "    # define matplotlib figure and axis; use constrained layout to fit colorbar to right\n",
    "    fig, ax = plt.subplots(figsize=(plot_width, plot_height), constrained_layout=True)\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    plt.xlim(0, max_depth_log)\n",
    "    plt.ylim(0, max_width)\n",
    "\n",
    "    # circuit depth axis (x axis)\n",
    "    xbasis = [x for x in range(1,max_depth_log)]\n",
    "    xround = [depth_base**(x-1) for x in xbasis]\n",
    "    xlabels = [format_number(x) for x in xround]\n",
    "    ax.set_xlabel('Circuit Depth')\n",
    "    ax.set_xticks(xbasis)  \n",
    "    plt.xticks(xbasis, xlabels, color='black', rotation=45, ha='right', va='top', rotation_mode=\"anchor\")\n",
    "    \n",
    "    # other label options\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-60, ha='left')\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-45, ha='left', va='center', rotation_mode=\"anchor\")\n",
    "\n",
    "    # circuit width axis (y axis)\n",
    "    ybasis = [y for y in range(1,max_width)]\n",
    "    yround = [1,2,3,4,5,6,7,8,10,12,15]     # not used now\n",
    "    ylabels = [str(y) for y in yround]      # not used now \n",
    "    #ax.set_ylabel('Circuit Width (Number of Qubits)')\n",
    "    ax.set_ylabel('Circuit Width')\n",
    "    ax.set_yticks(ybasis)\n",
    "\n",
    "    #create simple line plot (not used right now)\n",
    "    #ax.plot([0, 10],[0, 10])\n",
    "    \n",
    "    log2QV = math.log2(QV)\n",
    "    QV_width = log2QV\n",
    "    QV_depth = log2QV * QV_transpile_factor\n",
    "    \n",
    "    # show a quantum volume rectangle of QV = 64 e.g. (6 x 6)\n",
    "    if QV0 != 0:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.87, depth_base))\n",
    "    else:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.91, depth_base))\n",
    "    \n",
    "    # the untranspiled version is commented out - we do not show this by default\n",
    "    # also show a quantum volume rectangle un-transpiled\n",
    "    # ax.add_patch(qv_box_at(1, 1, QV_width, QV_width, 0.80, depth_base))\n",
    "\n",
    "    # show 2D array of volumetric cells based on this QV_transpiled\n",
    "    # DEVNOTE: we use +1 only to make the visuals work; s/b without\n",
    "    # Also, the second arg of the min( below seems incorrect, needs correction\n",
    "    maxprod = (QV_width + 1) * (QV_depth + 1)\n",
    "    for w in range(1, min(max_width, round(QV) + 1)):\n",
    "        \n",
    "        # don't show VB squares if width greater than known available qubits\n",
    "        if avail_qubits != 0 and w > avail_qubits:\n",
    "            continue\n",
    "        \n",
    "        i_success = 0\n",
    "        for d in xround:\n",
    "        \n",
    "            # polarization factor for low circuit widths\n",
    "            maxtest = maxprod / ( 1 - 1 / (2**w) )\n",
    "            \n",
    "            # if circuit would fail here, don't draw box\n",
    "            if d > maxtest: continue\n",
    "            if w * d > maxtest: continue\n",
    "            \n",
    "            # guess for how to capture how hardware decays with width, not entirely correct\n",
    "\n",
    "            # # reduce maxtext by a factor of number of qubits > QV_width\n",
    "            # # just an approximation to account for qubit distances\n",
    "            # if w > QV_width:\n",
    "            #     over = w - QV_width \n",
    "            #     maxtest = maxtest / (1 + (over/QV_width))\n",
    "\n",
    "            # draw a box at this width and depth\n",
    "            id = depth_index(d, depth_base) \n",
    "            \n",
    "            # show vb rectangles; if not showing QV, make all hollow (or less dark)\n",
    "            if QV0 == 0:\n",
    "                #ax.add_patch(bkg_empty_box_at(id, w))\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.95))\n",
    "            \n",
    "            else:\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.9))\n",
    "            \n",
    "            # save index of last successful depth\n",
    "            i_success += 1\n",
    "        \n",
    "        # plot empty rectangle after others       \n",
    "        d = xround[i_success]\n",
    "        id = depth_index(d, depth_base) \n",
    "        ax.add_patch(bkg_empty_box_at(id, w))\n",
    "        \n",
    "    \n",
    "    # Add annotation showing quantum volume\n",
    "    if QV0 != 0:\n",
    "        t = ax.text(max_depth_log - 2.0, 1.5, f\"QV{est_str}={QV}\", size=12,\n",
    "                horizontalalignment='right', verticalalignment='center', color=(0.2,0.2,0.2),\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=(.9,.9,.9), ec=\"grey\", lw=1))\n",
    "                \n",
    "    # add colorbar to right of plot\n",
    "    plt.colorbar(cm.ScalarMappable(cmap=cmap), cax=None, ax=ax,\n",
    "            shrink=0.6, label=colorbar_label, panchor=(0.0, 0.7))\n",
    "            \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c7b52-ddf0-4331-bded-4cf824ccbe83",
   "metadata": {},
   "source": [
    "# Benchmarking Essentials and Fidelity Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ffdf2-b8d2-404a-aff2-0775e40c1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate circuit depth\n",
    "def calculate_circuit_depth(qc):\n",
    "    # Calculate the depth of the circuit\n",
    "    depth = len(cirq.Circuit(qc.all_operations()))\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2ae02-3b68-42aa-a168-d12f5e7ccf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transpiled_depth(qc,basis_selector): #TO DO\n",
    "    if basis_selector == \"CZTarget\":\n",
    "        gateset = cirq.CZTargetGateset(allow_partial_czs=True)\n",
    "        optimized_circuit = cirq.optimize_for_target_gateset(qc, gateset=gateset)\n",
    "        #To ensure optimized circuit is equivalent to original circuit in terms of final measurements\n",
    "        cirq.testing.assert_circuits_with_terminal_measurements_are_equivalent(qc, optimized_circuit)     \n",
    "        #print(\"\\nCircuit compiled for CZ Target Gateset (Optimized/Transpiled ckt):\", optimized_circuit, \"\\n\", sep=\"\\n\")\n",
    "\n",
    "    elif basis_selector == \"SqrtIswapTarget\":\n",
    "        gateset = cirq.SqrtIswapTargetGateset()\n",
    "        optimized_circuit = cirq.optimize_for_target_gateset(qc, gateset=gateset)   #sqrt_iswap_circuit\n",
    "        #cirq.testing.assert_circuits_with_terminal_measurements_are_equivalent(qc, optimized_circuit)\n",
    "        #print(\"\\nCircuit compiled for sqrt_iswap_circuit (Optimized/Transpiled ckt):\", optimized_circuit, \"\\n\", sep=\"\\n\")\n",
    "       \n",
    "    transpiled_depth = calculate_circuit_depth(optimized_circuit)\n",
    "    return transpiled_depth,optimized_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0490105-27e8-443d-9d83-6f6ef17b1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fidelity_data(fidelity_data, Hf_fidelity_data, title):\n",
    "    avg_fidelity_means = []\n",
    "    avg_Hf_fidelity_means = []\n",
    "    avg_num_qubits_values = list(fidelity_data.keys())\n",
    "\n",
    "    # Calculate the average fidelity and Hamming fidelity for each unique number of qubits\n",
    "    for num_qubits in avg_num_qubits_values:\n",
    "        avg_fidelity = np.average(fidelity_data[num_qubits])\n",
    "        avg_fidelity_means.append(avg_fidelity)\n",
    "\n",
    "        avg_Hf_fidelity = np.mean(Hf_fidelity_data[num_qubits])\n",
    "        avg_Hf_fidelity_means.append(avg_Hf_fidelity)\n",
    "    \n",
    "    return avg_fidelity_means,avg_Hf_fidelity_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede6470-47df-413f-9795-a590d47d79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory():\n",
    "    import resource\n",
    "    usage = resource.getrusage(resource.RUSAGE_SELF)\n",
    "    max_mem = usage.ru_maxrss/1024 #in MB\n",
    "    return max_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23f947-1109-4498-9f9c-2e38db9ff1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(res):\n",
    "    # get measurement array\n",
    "    measurements = res.measurements['result']\n",
    "        \n",
    "    # Initialize an empty dictionary for counts\n",
    "    counts = {}\n",
    "    \n",
    "    # Iterate through measurements and populate counts\n",
    "    for row in measurements:\n",
    "        # Convert row to a string for use as dictionary key\n",
    "        key = \"\".join([str(x) for x in reversed(row)])\n",
    "    \n",
    "        # Update counts dictionary\n",
    "        if key in counts:\n",
    "            counts[key] += 1\n",
    "        else:\n",
    "            counts[key] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fc8cb-3402-4966-b5b8-2e9c0c9bed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count gate occurrences\n",
    "def count_gates(circuit):\n",
    "    gate_counts = {}\n",
    "    for operation in circuit.all_operations():\n",
    "        gate = operation.gate\n",
    "        if isinstance(gate,cirq.MeasurementGate)==False:\n",
    "            if isinstance(gate, cirq_utils.to_gate):\n",
    "                gate_name = gate.name\n",
    "            else:\n",
    "                gate_name = gate\n",
    "\n",
    "            if gate_name in gate_counts:\n",
    "                gate_counts[gate_name] += 1\n",
    "            else:\n",
    "                gate_counts[gate_name] = 1\n",
    "    return gate_counts\n",
    "    \n",
    "\n",
    "def update_counts(gates,custom_gates):\n",
    "    operations = {}\n",
    "    for key, value in gates.items():\n",
    "        operations[key] = value\n",
    "    for key, value in custom_gates.items():\n",
    "        if key in operations:\n",
    "            operations[key] += value\n",
    "        else:\n",
    "            operations[key] = value       \n",
    "    return operations\n",
    "\n",
    "def get_gate_counts(gates,custom_gate_defs):\n",
    "    result = gates.copy()\n",
    "    # Iterate over the gate counts in the quantum circuit\n",
    "    for gate, count in gates.items():\n",
    "        if gate in custom_gate_defs:\n",
    "            custom_gate_ops = custom_gate_defs[gate]\n",
    "            # Multiply custom gate operations by the count of the custom gate in the circuit\n",
    "            for _ in range(count):\n",
    "                result = update_counts(result, custom_gate_ops)\n",
    "            # Remove the custom gate entry as we have expanded it\n",
    "            del result[gate]\n",
    "    return result\n",
    "\n",
    "dict_of_qc = dict() \n",
    "custom_gates_defs = dict()\n",
    "\n",
    "# Function to count operations recursively\n",
    "def count_operations(qc):\n",
    "    dict_of_qc.clear()\n",
    "    circuit_traverser(qc,None)\n",
    "    operations = dict()\n",
    "    operations = dict_of_qc[\"qc\"]\n",
    "    del dict_of_qc[\"qc\"]\n",
    "    #print(\"dict_of_qc :\",dict_of_qc)\n",
    "    for keys in operations.keys():\n",
    "        if isinstance(keys,cirq.Gate)==False:\n",
    "        #if keys not in list_of_gates:\n",
    "            for k,v in dict_of_qc.items():\n",
    "                if k in operations.keys():\n",
    "                    custom_gates_defs[k] = v\n",
    "                    operations=get_gate_counts(operations,custom_gates_defs)\n",
    "                    custom_gates_defs.clear()\n",
    "        \n",
    "    return operations\n",
    "\n",
    "def circuit_traverser(qc,key=None):\n",
    "    if key == None:\n",
    "        key = \"qc\"\n",
    "    dict_of_qc[key]=count_gates(qc)\n",
    "    for i in qc.all_operations():\n",
    "        if isinstance(i.gate,cirq_utils.to_gate):\n",
    "            qc_1 = i.gate.circ.copy()\n",
    "            #print(qc_1)\n",
    "            circuit_traverser(qc_1,i.gate.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a855d-01e3-440f-9d9c-9487e42daa5a",
   "metadata": {},
   "source": [
    "# Analyzer Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3e7d5-171f-44d6-963b-6c6cd7f40e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_shor_dist(num_bits, order, num_shots):\n",
    "    # num_bits represent the number of bits to represent the number N in question\n",
    "\n",
    "    # Qubits measureed always 2 * num_bits for the three methods implemented in this benchmark\n",
    "    qubits_measured = 2 * num_bits\n",
    "    dist = {}\n",
    "\n",
    "    # Conver float to int\n",
    "    r = int(order)\n",
    "\n",
    "    # Generate expected distribution\n",
    "    q = int(2 ** (qubits_measured))\n",
    "\n",
    "    for i in range(r):\n",
    "        key = bin(int(q * (i / r)))[2:].zfill(qubits_measured)\n",
    "        dist[key] = num_shots / r\n",
    "\n",
    "        '''\n",
    "            for c in range(2 ** qubits_measured):\n",
    "                key = bin(c)[2:].zfill(qubits_measured)\n",
    "                amp = 0\n",
    "                for i in range(int(q/r) - 1):\n",
    "                    amp += np.exp(2*math.pi* 1j * i * (r * c % q)/q )\n",
    "                amp = amp * np.sqrt(r) / q\n",
    "                dist[key] = abs(amp) ** 2\n",
    "        '''\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39b754-8226-4e2a-ad5f-7eb05330ec2a",
   "metadata": {},
   "source": [
    "# RUN Function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b0d25-644b-42bc-b362-7d0fe51cfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 1\n",
    "#NOTE: Methods 2 & 3 are yet to be implemented\n",
    "def run (min_qubits=min_qubits, max_qubits=max_qubits, \n",
    "         max_circuits=max_circuits, num_shots=num_shots, method=method):\n",
    "\n",
    "    creation_times = []\n",
    "    elapsed_times = []\n",
    "    circuit_depths = []\n",
    "    transpiled_depths = []\n",
    "    fidelity_data = {}\n",
    "    Hf_fidelity_data = {}\n",
    "    numckts = []\n",
    "    mem_usage = []\n",
    "    algorithmic_1Q_gate_counts = []\n",
    "    algorithmic_2Q_gate_counts = []\n",
    "    transpiled_1Q_gate_counts = []\n",
    "    transpiled_2Q_gate_counts = []\n",
    "    \n",
    "    print(f\"{benchmark_name} Benchmark Program - {Type_of_Simulator}\")\n",
    "\n",
    "    # Each method has a different minimum amount of qubits to run and a certain multiple of qubits that can be run\n",
    "    qubit_multiple = 2  # Standard for Method 2 and 3(To be implemented)\n",
    "\n",
    "    max_qubits = max(max_qubits, min_qubits)  # max must be >= min\n",
    "\n",
    "    if method == 1:\n",
    "        min_qubits = max(min_qubits, 10)  # need min of 10\n",
    "        qubit_multiple = 4\n",
    "    elif method == 2:\n",
    "        min_qubits = max(min_qubits, 7)  # need min of 7\n",
    "\n",
    "    if max_qubits < min_qubits:\n",
    "        print(\n",
    "            f\"Max number of qubits {max_qubits} is too low to run method {method} of Shor's Order Finding\")\n",
    "        return\n",
    "\n",
    "    global max_ckts\n",
    "    max_ckts = max_circuits\n",
    "\n",
    "    global min_qbits,max_qbits,skp_qubits\n",
    "\n",
    "    min_qbits = min_qubits\n",
    "    max_qbits = max_qubits\n",
    "    skp_qubits = qubit_multiple\n",
    "    \n",
    "    print(f\"min, max qubits = {min_qubits} {max_qubits}\")\n",
    "\n",
    "    # Execute Benchmark Program N times for multiple circuit sizes\n",
    "    for num_qubits in range(min_qubits, max_qubits + 1,  qubit_multiple):\n",
    "        fidelity_data[num_qubits] = []\n",
    "        Hf_fidelity_data[num_qubits] = []\n",
    "        \n",
    "        input_size = num_qubits - 1\n",
    "\n",
    "        if method == 1:\n",
    "            num_bits = int((num_qubits - 2) / 4)\n",
    "        elif method == 2:\n",
    "            num_bits = int((num_qubits - 3) / 2)\n",
    "\n",
    "        # determine number of circuits to execute for this group\n",
    "        num_circuits = min(2 ** (input_size), max_circuits)\n",
    "\n",
    "        print(f\"************\\nExecuting [{num_circuits}] circuits with num_qubits = {num_qubits}\")\n",
    "        \n",
    "        \n",
    "        num_circuits =  min(2 ** (input_size), max_circuits)\n",
    "        numckts.append(num_circuits)\n",
    "        for _ in range(num_circuits):\n",
    "            print(\"*********************************************\")\n",
    "            print(f\"qc of {num_qubits} qubits for {_}\")\n",
    "\n",
    "            base = 1\n",
    "            while base == 1:\n",
    "                # Ensure N is a number using the greatest bit\n",
    "                number = np.random.randint(2 ** (num_bits - 1) + 1, 2 ** num_bits)\n",
    "                order = np.random.randint(2, number)\n",
    "                base = generate_base(number, order)\n",
    "\n",
    "            # Checking if generated order can be reduced. Can also run through prime list in shors utils\n",
    "            if order % 2 == 0: order = 2\n",
    "            if order % 3 == 0: order = 3\n",
    "\n",
    "            number_order = (number, order)\n",
    "            print(f\"Generated {number=}, {base=}, {order=}\")\n",
    "            \n",
    "            #creation of Quantum Circuit.\n",
    "            ts = time.time()\n",
    "            qc = ShorsAlgorithm(number, base, method=method)   \n",
    "            #creation time\n",
    "            creation_time = time.time() - ts\n",
    "            creation_times.append(creation_time)\n",
    "            #print(qc)\n",
    "            print(f\"creation time = {creation_time*1000} ms\")\n",
    "            \n",
    "            # Calculate circuit depth\n",
    "            depth = calculate_circuit_depth(qc)\n",
    "            circuit_depths.append(depth)\n",
    "            \n",
    "            n1q,n2q = 0,0\n",
    "            #algorithmic Gate Counts \n",
    "            if gate_counts_plots == True:\n",
    "                operations = count_operations(qc)\n",
    "                transformed_operations = {}\n",
    "                for k,v in operations.items():\n",
    "                    if isinstance(k,cirq.Gate) and not isinstance(k,cirq_utils.to_gate):\n",
    "                        num_qbits=k.num_qubits()\n",
    "                        transformed_operations[k] = {'count': v, 'num_qubits': num_qbits}\n",
    "                for k,v in transformed_operations.items():\n",
    "                    temp = v\n",
    "                    if temp[\"num_qubits\"]>1:\n",
    "                        n2q += temp[\"count\"]\n",
    "                    else:\n",
    "                        n1q += temp[\"count\"]\n",
    "\n",
    "                algorithmic_1Q_gate_counts.append(n1q)\n",
    "                algorithmic_2Q_gate_counts.append(n2q)\n",
    "            \n",
    "            # Calculate transpiled circuit depth\n",
    "            transpiled_depth,qc = calculate_transpiled_depth(qc,basis_selector)\n",
    "            transpiled_depths.append(transpiled_depth)\n",
    "            #print(qc)\n",
    "\n",
    "            print(f\"Algorithmic Depth = {depth} and Normalized Depth = {transpiled_depth}\")\n",
    "            if Noise_Inclusion == True:\n",
    "                for i in noise_parameters:\n",
    "                    qc= qc.with_noise(i)\n",
    "                    print(i)\n",
    "\n",
    "            #Transpiled Gate Counts\n",
    "            tr_n1q,tr_n2q = 0,0\n",
    "            if gate_counts_plots == True:\n",
    "                operations = count_gates(qc)\n",
    "                transformed_operations = {}\n",
    "                for k,v in operations.items():\n",
    "                    if isinstance(k,cirq.Gate) and not isinstance(k,cirq_utils.to_gate):\n",
    "                        num_qbits=k.num_qubits()\n",
    "                        transformed_operations[k] = {'count': v, 'num_qubits': num_qbits}\n",
    "                for k,v in transformed_operations.items():\n",
    "                    temp = v\n",
    "                    if temp[\"num_qubits\"]>1:\n",
    "                        tr_n2q += temp[\"count\"]\n",
    "                    else:\n",
    "                        tr_n1q += temp[\"count\"]\n",
    "\n",
    "\n",
    "                transpiled_1Q_gate_counts.append(n1q)\n",
    "                transpiled_2Q_gate_counts.append(n2q)\n",
    "\n",
    "                print(f\"Algorithmic 1Q gates = {n1q} ,Algorithmic 2Q gates = {n2q}\")\n",
    "                print(f\"Normalized 1Q gates = {tr_n1q} ,Normalized 2Q gates = {tr_n2q}\")\n",
    "                \n",
    "            #execution\n",
    "            ts = time.time()\n",
    "            job =  backend.run(qc,repetitions=num_shots) \n",
    "            \n",
    "            #retrieving the result \n",
    "            result = job\n",
    "            #print(result)\n",
    "            \n",
    "            #calculating elapsed time\n",
    "            elapsed_time = time.time() - ts\n",
    "            elapsed_times.append(elapsed_time)\n",
    "\n",
    "            print(f\"Elapsed time = {elapsed_time*1000} ms\")\n",
    "\n",
    "            #counts in result object \n",
    "            counts = get_counts(result)\n",
    "            #print(\"Counts = \",counts)\n",
    "\n",
    "            #Correct distribution to compare with counts\n",
    "            print(\"order =\",order)\n",
    "            if  method == 1:\n",
    "                num_bits = int((num_qubits - 2) / 4)\n",
    "            elif method == 2:\n",
    "                num_bits = int((num_qubits - 3) / 2)\n",
    "\n",
    "            # Only classical data qubits are important and removing first auxiliary qubit from count\n",
    "            if method == 2:\n",
    "                temp_counts = {}\n",
    "                for key, item in counts.items():\n",
    "                    temp_counts[key[2:]] = item\n",
    "                counts = temp_counts\n",
    "\n",
    "            # generate correct distribution\n",
    "            correct_dist = expected_shor_dist(num_bits, order, num_shots)\n",
    "            \n",
    "            #fidelity calculation comparision of counts and correct_dist \n",
    "            fidelity_dict = polarization_fidelity(counts, correct_dist)\n",
    "            fidelity_data[num_qubits].append(fidelity_dict['fidelity'])\n",
    "            Hf_fidelity_data[num_qubits].append(fidelity_dict['hf_fidelity'])\n",
    "            \n",
    "\n",
    "            #maximum memory utilization (if required)\n",
    "            if Memory_utilization_plot == True:\n",
    "                max_mem = get_memory()\n",
    "                print(f\"Maximum Memory Utilized: {max_mem} MB\")\n",
    "                mem_usage.append(max_mem)\n",
    "\n",
    "            print(\"*********************************************\")\n",
    "    \n",
    "    # print the last circuit created\n",
    "    print(\"Sample Circuit:\"); print(QC_ if QC_ != None else \"  ... too large!\")\n",
    "    print(\"\\nControlled Ua Operator 'cUa' =\"); print(CUA_ if CUA_ != None else \" ... too large!\")\n",
    "    print(\"\\nControlled Multiplier Operator 'cMULTamodN' =\"); print(CMULTAMODN_ if CMULTAMODN_ != None else \" ... too large!\")\n",
    "    print(\"\\nControlled Modular Adder Operator 'ccphiamodN' =\"); print(CCPHIADDMODN_ if CCPHIADDMODN_ != None else \" ... too large!\")\n",
    "    print(\"\\nPhi Adder Operator '\\u03C6ADD' =\"); print(PHIADD_ if PHIADD_ != None else \" ... too large!\")\n",
    "\n",
    "    qr_state = cirq.GridQubit.rect(1, QFT_.num_qubits,0)  # we need to create registers to print circuits in cirq\n",
    "    print(\"\\nQFT Circuit =\"); print(cirq.Circuit(cirq.decompose(QFT_.on(*qr_state))) if QFT_ != None else \"  ... too large!\")\n",
    "    \n",
    "    return (creation_times, elapsed_times, circuit_depths, transpiled_depths, \n",
    "            fidelity_data, Hf_fidelity_data, numckts , algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts,\n",
    "    transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74a319-b5c7-4d24-a75e-def3e1f0bcc0",
   "metadata": {},
   "source": [
    "# Triggering RUN function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1e5eb-6be5-455e-9951-e13d0afea3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute the benchmark program, accumulate metrics, and calculate circuit depths\n",
    "(creation_times, elapsed_times, circuit_depths,transpiled_depths, fidelity_data, Hf_fidelity_data, numckts,  \n",
    "algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts, transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage) = run()\n",
    "\n",
    "# Define the range of qubits for the x-axis\n",
    "num_qubits_range = range(min_qbits, max_qbits+1,skp_qubits)\n",
    "print(\"num_qubits_range =\",num_qubits_range)\n",
    "\n",
    "# Calculate average creation time, elapsed time, quantum processing time, and circuit depth for each number of qubits\n",
    "avg_creation_times = []\n",
    "avg_elapsed_times = []\n",
    "avg_quantum_times = []\n",
    "avg_circuit_depths = []\n",
    "avg_transpiled_depths = []\n",
    "avg_1Q_algorithmic_gate_counts = []\n",
    "avg_2Q_algorithmic_gate_counts = []\n",
    "avg_1Q_Transpiled_gate_counts = []\n",
    "avg_2Q_Transpiled_gate_counts = []\n",
    "max_memory = []\n",
    "\n",
    "start = 0\n",
    "for num in numckts:\n",
    "    avg_creation_times.append(np.mean(creation_times[start:start+num]))\n",
    "    avg_elapsed_times.append(np.mean(elapsed_times[start:start+num]))\n",
    "    avg_circuit_depths.append(np.mean(circuit_depths[start:start+num]))\n",
    "    avg_transpiled_depths.append(np.mean(transpiled_depths[start:start+num]))\n",
    "    if gate_counts_plots == True:\n",
    "        avg_1Q_algorithmic_gate_counts.append(int(np.mean(algorithmic_1Q_gate_counts[start:start+num])))\n",
    "        avg_2Q_algorithmic_gate_counts.append(int(np.mean(algorithmic_2Q_gate_counts[start:start+num])))\n",
    "        avg_1Q_Transpiled_gate_counts.append(int(np.mean(transpiled_1Q_gate_counts[start:start+num])))\n",
    "        avg_2Q_Transpiled_gate_counts.append(int(np.mean(transpiled_2Q_gate_counts[start:start+num])))\n",
    "    if Memory_utilization_plot == True:max_memory.append(np.max(mem_usage[start:start+num]))\n",
    "    start += num\n",
    "\n",
    "# Calculate the fidelity data\n",
    "avg_f, avg_Hf = plot_fidelity_data(fidelity_data, Hf_fidelity_data, \"Fidelity Comparison\")\n",
    "\n",
    "if Store_Data:\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    # Prepare the data dictionary\n",
    "    data = {\n",
    "        \"configuration\":{\n",
    "        \"min_qbits\":min_qbits,\n",
    "        \"max_qbits\":max_qbits,\n",
    "        \"skp_qubits\":skp_qubits,\n",
    "        \"Type_of_Simulator\":Type_of_Simulator,\n",
    "        \"benchmark_name\":benchmark_name,\n",
    "        \"QV_\":QV_},\n",
    "        \"avg_creation_times\": avg_creation_times,\n",
    "        \"avg_elapsed_times\": avg_elapsed_times,\n",
    "        \"avg_quantum_times\": avg_quantum_times,\n",
    "        \"avg_circuit_depths\": avg_circuit_depths,\n",
    "        \"avg_transpiled_depths\": avg_transpiled_depths,\n",
    "        \"avg_1Q_algorithmic_gate_counts\": avg_1Q_algorithmic_gate_counts,\n",
    "        \"avg_2Q_algorithmic_gate_counts\": avg_2Q_algorithmic_gate_counts,\n",
    "        \"avg_1Q_Transpiled_gate_counts\": avg_1Q_Transpiled_gate_counts,\n",
    "        \"avg_2Q_Transpiled_gate_counts\": avg_2Q_Transpiled_gate_counts,\n",
    "        \"max_memory\": max_memory,\n",
    "        \"Average_fidelity\":avg_f,\n",
    "        \"Average_Hellinger_fidelity\":avg_Hf\n",
    "    }\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Add the timestamp to the data\n",
    "    data['last_updated'] = current_time\n",
    "    \n",
    "    # Define the file name\n",
    "    file_name = '__data.json'\n",
    "    \n",
    "    # Write the data to the file\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    \n",
    "    print(f\"***** Data has been saved to {file_name} ******\")\n",
    "\n",
    "# Plot histograms for average creation time, average elapsed time, average quantum processing time, and average circuit depth versus the number of qubits\n",
    "\n",
    "def autolabel(rects,ax,str='{:.3f}',text_color=\"black\"):\n",
    "        max_y_value=ax.get_ylim()[1]  # Get the maximum value on the y-axis\n",
    "        threshold=0.3*max_y_value   # Define threshold as 30% of max y-axis value\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            if height < threshold:\n",
    "                rotation = 90\n",
    "                va = 'bottom'  # Place text above the bar\n",
    "                xytext = (0, 3)  # Offset slightly above the bar\n",
    "            else:\n",
    "                rotation = 90\n",
    "                va = 'center'  # Place text inside the bar\n",
    "                xytext = (0, 0)  # No offset\n",
    "            ax.annotate(str.format(height),  # Formatting to two decimal places\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height / 2),\n",
    "                        xytext=xytext,\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va=va, color=text_color, rotation=rotation)\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "# Determine the number of subplots and their arrangement\n",
    "if Memory_utilization_plot and gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7) = plt.subplots(7, 1, figsize=(18, 30))\n",
    "    # Plotting for both memory utilization and gate counts\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6, ax7 are available\n",
    "elif Memory_utilization_plot:\n",
    "    fig, (ax1, ax2, ax3, ax6, ax7) = plt.subplots(5, 1, figsize=(8, 13))\n",
    "    # Plotting for memory utilization only\n",
    "    # ax1, ax2, ax3, ax6, ax7 are available\n",
    "elif gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(18, 30))\n",
    "    # Plotting for gate counts only\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6 are available\n",
    "else:\n",
    "    fig, (ax1, ax2, ax3, ax6) = plt.subplots(4, 1, figsize=(18, 30))\n",
    "    # Default plotting\n",
    "    # ax1, ax2, ax3, ax6 are available\n",
    "\n",
    "fig.suptitle(f\"General Benchmarks : {Type_of_Simulator} - {benchmark_name}\", fontsize=13)\n",
    "for i in range(len(avg_creation_times)): #converting seconds to milli seconds by multiplying 1000\n",
    "    avg_creation_times[i] *= 1000\n",
    "\n",
    "ax1.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "x = ax1.bar(num_qubits_range, avg_creation_times, color='deepskyblue')\n",
    "autolabel(ax1.patches, ax1)\n",
    "ax1.set_xlabel('Number of Qubits',fontsize=9)\n",
    "ax1.set_ylabel('Average Creation Time (ms)',fontsize=9)\n",
    "ax1.set_title('Average Creation Time vs Number of Qubits',fontsize=9)\n",
    "\n",
    "\n",
    "ax2.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "\n",
    "for i in range(len(avg_elapsed_times)): #converting seconds to milli seconds by multiplying 1000\n",
    "    avg_elapsed_times[i] *= 1000\n",
    "\n",
    "\n",
    "Elapsed= ax2.bar(np.array(num_qubits_range), avg_elapsed_times, width=bar_width, color='cyan', label='Elapsed Time')\n",
    "autolabel(Elapsed,ax2,str='{:.1f}')\n",
    "ax2.set_xlabel('Number of Qubits',fontsize=9)\n",
    "ax2.set_ylabel('Average Time (ms)',fontsize=9)\n",
    "ax2.set_title('Average Time vs Number of Qubits',fontsize=9)\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Normalized = ax3.bar(np.array(num_qubits_range) - bar_width / 2, avg_transpiled_depths, color='cyan', label='Normalized Depth', width=bar_width)  # Adjust width here\n",
    "Algorithmic = ax3.bar(np.array(num_qubits_range) + bar_width / 2,avg_circuit_depths, color='deepskyblue', label='Algorithmic Depth', width=bar_width)  # Adjust width here\n",
    "autolabel(Normalized,ax3,str='{:.2f}')\n",
    "autolabel(Algorithmic,ax3,str='{:.2f}')\n",
    "ax3.set_xlabel('Number of Qubits',fontsize=9)\n",
    "ax3.set_ylabel('Average Circuit Depth',fontsize=9)\n",
    "ax3.set_title('Average Circuit Depth vs Number of Qubits',fontsize=9)\n",
    "ax3.legend()\n",
    "\n",
    "if gate_counts_plots == True:\n",
    "    ax4.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_1Q_counts = ax4.bar(np.array(num_qubits_range) - bar_width / 2, avg_1Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_1Q_counts = ax4.bar(np.array(num_qubits_range) + bar_width / 2, avg_1Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_1Q_counts,ax4,str='{}')\n",
    "    autolabel(Algorithmic_1Q_counts,ax4,str='{}')\n",
    "    ax4.set_xlabel('Number of Qubits',fontsize=9)\n",
    "    ax4.set_ylabel('Average 1-Qubit Gate Counts',fontsize=9)\n",
    "    ax4.set_title('Average 1-Qubit Gate Counts vs Number of Qubits',fontsize=9)\n",
    "    ax4.legend()\n",
    "    \n",
    "    ax5.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_2Q_counts = ax5.bar(np.array(num_qubits_range) - bar_width / 2, avg_2Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_2Q_counts = ax5.bar(np.array(num_qubits_range) + bar_width / 2, avg_2Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_2Q_counts,ax5,str='{}')\n",
    "    autolabel(Algorithmic_2Q_counts,ax5,str='{}')\n",
    "    ax5.set_xlabel('Number of Qubits',fontsize=9)\n",
    "    ax5.set_ylabel('Average 2-Qubit Gate Counts',fontsize=9)\n",
    "    ax5.set_title('Average 2-Qubit Gate Counts vs Number of Qubits',fontsize=9)\n",
    "    ax5.legend()\n",
    "\n",
    "\n",
    "ax6.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Hellinger = ax6.bar(np.array(num_qubits_range) - bar_width / 2, avg_Hf, width=bar_width, label='Hellinger Fidelity',color='cyan')  # Adjust width here\n",
    "Normalized = ax6.bar(np.array(num_qubits_range) + bar_width / 2, avg_f, width=bar_width, label='Normalized Fidelity', color='deepskyblue')  # Adjust width here\n",
    "autolabel(Hellinger,ax6,str='{:.2f}')\n",
    "autolabel(Normalized,ax6,str='{:.2f}')\n",
    "ax6.set_xlabel('Number of Qubits',fontsize=9)\n",
    "ax6.set_ylabel('Average Value',fontsize=9)\n",
    "ax6.set_title(\"Fidelity Comparison\",fontsize=9)\n",
    "ax6.legend()\n",
    "\n",
    "if Memory_utilization_plot == True:\n",
    "    ax7.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    x = ax7.bar(num_qubits_range, max_memory, color='turquoise', width=bar_width, label=\"Memory Utilizations\")\n",
    "    autolabel(ax7.patches, ax7,str=\"{:.1f}\")\n",
    "    ax7.set_xlabel('Number of Qubits',fontsize=9)\n",
    "    ax7.set_ylabel('Maximum Memory Utilized (MB)',fontsize=9)\n",
    "    ax7.set_title('Memory Utilized vs Number of Qubits',fontsize=9)\n",
    "\n",
    "\n",
    "# Adjust layout to avoid overlapping\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.96], h_pad=2.5)\n",
    "plt.subplots_adjust(top=0.92)\n",
    "if saveplots == True:\n",
    "    plt.savefig(\"ParameterPlotsSample.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Quantum Volume Plot\n",
    "Suptitle = f\"Volumetric Positioning - {Type_of_Simulator}\"\n",
    "appname=benchmark_name\n",
    "if QV_ == None:\n",
    "    QV=2048\n",
    "else:\n",
    "    QV=QV_\n",
    "depth_base =2\n",
    "\n",
    "ax = plot_volumetric_background(max_qubits=max_qbits, QV=QV,depth_base=depth_base, suptitle=Suptitle, colorbar_label=\"Avg Result Fidelity\")\n",
    "\n",
    "w_data = num_qubits_range\n",
    "# determine width for circuit\n",
    "w_max = 0\n",
    "for i in range(len(w_data)):\n",
    "    y = float(w_data[i])\n",
    "    w_max = max(w_max, y)\n",
    "\n",
    "d_tr_data = avg_transpiled_depths\n",
    "f_data = avg_f\n",
    "\n",
    "plot_volumetric_data(ax, w_data, d_tr_data, f_data, depth_base, fill=True,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, w_max=w_max)\n",
    "anno_volumetric_data(ax, depth_base,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, fill=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
