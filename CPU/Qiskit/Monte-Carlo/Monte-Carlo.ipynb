{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a822d6-1b01-4e4a-b7fe-b8f9afd1027f",
   "metadata": {},
   "source": [
    "# Custom Parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0db73-47c9-4849-9733-0accaa7b3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign these values as per your requirements.\n",
    "global min_qubits,max_qubits,skip_qubits,max_circuits,num_shots,Noise_Inclusion\n",
    "method = 1\n",
    "min_qubits=4  # must be at least (MIN_STATE_QUBITS=1) + 3 = 4\n",
    "## for method-1 min_qubits = 5 (MIN_STATE_QUBITS = 2)+3 = 5\n",
    "\n",
    "max_qubits=10 # Because circuit size grows significantly with num_qubits limit the max_qubits here ...\n",
    "\n",
    "skip_qubits=1 \n",
    "max_circuits=3\n",
    "num_shots=1000\n",
    "\n",
    "epsilon=0.05\n",
    "degree=2\n",
    "\n",
    "Noise_Inclusion = False\n",
    "saveplots = False\n",
    "Memory_utilization_plot = True\n",
    "gate_counts_plots = True\n",
    "\n",
    "Store_Data = False\n",
    "save_to_excel = False\n",
    "\n",
    "Type_of_Simulator = \"built_in\" #Inputs are \"built_in\" or \"FAKE\" or \"FAKEV2\"\n",
    "backend_name  = \"qasm_simulator\" #Can refer to the README files for the available backends\n",
    "\n",
    "#Change your Specification of Simulator in Declaring Backend Section\n",
    "#By Default : built_in -> qasm_simulator and FAKE -> FakeSantiago() and FAKEV2 -> FakeSantiagoV2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad27634-a5ff-488c-bfdf-aae35ad06f04",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08898f1-ec8d-43b8-9899-5b2da4461909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import functools\n",
    "import mc_utils as mc_utils\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, Aer, transpile, execute\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from qiskit.circuit.library.standard_gates.ry import RYGate\n",
    "# Import from Qiskit Aer noise module\n",
    "from qiskit_aer.noise import (NoiseModel, QuantumError, ReadoutError,pauli_error, depolarizing_error, thermal_relaxation_error,reset_error)\n",
    "\n",
    "# Benchmark Name\n",
    "benchmark_name = f\"Monte Carlo Sampling Method-{method}\"\n",
    "\n",
    "\n",
    "# Selection of basis gate set for transpilation\n",
    "# Note: selector 1 is a hardware agnostic gate set\n",
    "basis_selector = 1\n",
    "basis_gates_array = [\n",
    "    [],\n",
    "    ['rx', 'ry', 'rz', 'cx'],       # a common basis set, default\n",
    "    ['cx', 'rz', 'sx', 'x'],        # IBM default basis set\n",
    "    ['rx', 'ry', 'rxx'],            # IonQ default basis set\n",
    "    ['h', 'p', 'cx'],               # another common basis set\n",
    "    ['u', 'cx']                     # general unitaries basis gates\n",
    "]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "num_gates = 0\n",
    "depth = 0\n",
    "QV_=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9696563-c5b9-430c-8694-d909dbad8289",
   "metadata": {},
   "source": [
    "# Declaring Backend :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c67fc-8e7c-4c20-aad2-421c4ebe3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_QV(backend):\n",
    "    import json\n",
    "\n",
    "    # Assuming backend.conf_filename is the filename and backend.dirname is the directory path\n",
    "    conf_filename = backend.dirname + \"/\" + backend.conf_filename\n",
    "    \n",
    "    # Open the JSON file\n",
    "    with open(conf_filename, 'r') as file:\n",
    "        # Load the JSON data\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extract the quantum_volume parameter\n",
    "    QV = data.get('quantum_volume', None)\n",
    "    return QV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc3806-7f6a-4b23-96e5-927fc039fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkbackend(backend_name,Type_of_Simulator):\n",
    "    if Type_of_Simulator == \"built_in\":\n",
    "        available_backends = []\n",
    "        for i in Aer.backends():\n",
    "            available_backends.append(i.name)\n",
    "        if backend_name in available_backends:\n",
    "            platform = backend_name\n",
    "            return platform\n",
    "        else:\n",
    "            print(f\"incorrect backend name or backend not available. Using qasm_simulator by default !!!!\")\n",
    "            print(f\"available backends are : {available_backends}\")\n",
    "            platform = \"qasm_simulator\"\n",
    "            return platform\n",
    "    elif Type_of_Simulator == \"FAKE\" or Type_of_Simulator == \"FAKEV2\":    \n",
    "        import qiskit.providers.fake_provider as fake_backends\n",
    "        if hasattr(fake_backends,backend_name) is True:\n",
    "            print(f\"Backend {backend_name} is available for type {Type_of_Simulator}.\")\n",
    "            backend_class = getattr(fake_backends,backend_name)\n",
    "            backend_instance = backend_class()\n",
    "            return backend_instance\n",
    "        else:\n",
    "            print(f\"Backend {backend_name} is not available or incorrect for type {Type_of_Simulator}. Executing with FakeSantiago!!!\")\n",
    "            if Type_of_Simulator == \"FAKEV2\":\n",
    "                backend_class = getattr(fake_backends,\"FakeSantiagoV2\")\n",
    "            else:\n",
    "                backend_class = getattr(fake_backends,\"FakeSantiago\")\n",
    "            backend_instance = backend_class()\n",
    "            return backend_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48184c2-00c5-4a30-a51d-68543c8916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Type_of_Simulator == \"built_in\":\n",
    "    platform = checkbackend(backend_name,Type_of_Simulator)\n",
    "    #By default using \"Qasm Simulator\"\n",
    "    backend = Aer.get_backend(platform)\n",
    "    QV_=None\n",
    "    print(f\"{platform} device is capable of running {backend.num_qubits}\")\n",
    "    print(f\"backend version is {backend.backend_version}\")\n",
    "elif Type_of_Simulator == \"FAKE\":\n",
    "    basis_selector = 0\n",
    "    backend = checkbackend(backend_name,Type_of_Simulator) \n",
    "    QV_ = get_QV(backend)\n",
    "    platform = backend.properties().backend_name +\"-\"+ backend.properties().backend_version #Replace this string with the backend Provider's name as this is used for Plotting.\n",
    "    max_qubits=backend.configuration().n_qubits\n",
    "    \n",
    "    print(f\"{platform} device is capable of running {backend.configuration().n_qubits}\")\n",
    "    print(f\"{platform} has QV={QV_}\")\n",
    "    if max_qubits > 30:\n",
    "        print(f\"Device is capable with max_qubits = {max_qubits}\")\n",
    "        max_qubit = 30\n",
    "    print(f\"Using fake backend {platform} with max_qubits {max_qubits}\")\n",
    "\n",
    "elif Type_of_Simulator == \"FAKEV2\":\n",
    "    basis_selector = 0\n",
    "    if \"V2\" not in backend_name:\n",
    "        backend_name = backend_name+\"V2\"\n",
    "    backend = checkbackend(backend_name,Type_of_Simulator)\n",
    "    QV_ = get_QV(backend)\n",
    "    platform = backend.name +\"-\" +backend.backend_version \n",
    "    max_qubits=backend.num_qubits\n",
    "    print(f\"{platform} device is capable of running {backend.num_qubits}\")\n",
    "    print(f\"{platform} has QV={QV_}\")\n",
    "    if max_qubits > 30:\n",
    "        print(f\"Device is capable with max_qubits = {max_qubits}\")\n",
    "        max_qubit = 30\n",
    "    print(f\"Using fake backend {platform} with max_qubits {max_qubits}\")\n",
    "else:\n",
    "    print(\"Enter valid Simulator.....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef0d41-62cd-41be-9e50-4fd41ff6b891",
   "metadata": {},
   "source": [
    "# Algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0aad18-387b-4498-824f-13b5e695c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved circuits and subcircuits for display\n",
    "A_ = None\n",
    "Q_ = None\n",
    "cQ_ = None\n",
    "QC_ = None\n",
    "R_ = None\n",
    "F_ = None\n",
    "QFTI_ = None\n",
    "\n",
    "# default function is f(x) = x^2\n",
    "f_of_X = functools.partial(mc_utils.power_f, power=2)\n",
    "\n",
    "# default distribution is gaussian distribution\n",
    "p_distribution = mc_utils.gaussian_dist\n",
    "\n",
    "############### Circuit Definition\n",
    "\n",
    "def MonteCarloSampling(target_dist, f, num_state_qubits, num_counting_qubits, epsilon=0.05, degree=2, method=2):\n",
    "    \n",
    "    A_qr = QuantumRegister(num_state_qubits+1)\n",
    "    A = QuantumCircuit(A_qr, name=f\"A_ckt\")\n",
    "\n",
    "    num_qubits = num_state_qubits + 1 + num_counting_qubits\n",
    "    \n",
    "    # initialize R and F circuits\n",
    "    R_qr = QuantumRegister(num_state_qubits+1)\n",
    "    F_qr = QuantumRegister(num_state_qubits+1)\n",
    "    R = QuantumCircuit(R_qr, name=f\"R\")\n",
    "    F = QuantumCircuit(F_qr, name=f\"F\")\n",
    "    \n",
    "    # method 1 takes in the abitrary function f and arbitrary dist\n",
    "    if method == 1:\n",
    "        state_prep(R, R_qr, target_dist, num_state_qubits)\n",
    "        f_on_objective(F, F_qr, f, epsilon=epsilon, degree=degree)\n",
    "    # method 2 chooses to have lower circuit depth by choosing specific f and dist\n",
    "    elif method == 2:\n",
    "        uniform_prep(R, R_qr, num_state_qubits)\n",
    "        square_on_objective(F, F_qr)\n",
    "    \n",
    "    # append R and F circuits to A\n",
    "    A.append(R.to_gate(), A_qr)\n",
    "    A.append(F.to_gate(), A_qr)\n",
    "\n",
    "    # run AE subroutine given our A composed of R and F\n",
    "    qc = AE_Subroutine(num_state_qubits, num_counting_qubits, A, method)\n",
    "\n",
    "    # save smaller circuit example for display\n",
    "    global QC_, R_, F_\n",
    "    if QC_ == None or num_qubits <= 5:\n",
    "        if num_qubits < 9: QC_ = qc\n",
    "    if (R_ and F_) == None or num_state_qubits <= 3:\n",
    "        if num_state_qubits < 5: R_ = R; F_ = F\n",
    "    \n",
    "    return qc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74fe4e-870c-4c61-bbfe-e31aa1abd73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############              \n",
    "                    \n",
    "def f_on_objective(qc, qr, f, epsilon=0.05, degree=2):\n",
    "    \"\"\"\n",
    "    Assume last qubit is the objective. Function f is evaluated on first n-1 qubits\n",
    "    \"\"\"\n",
    "    num_state_qubits = qc.num_qubits - 1\n",
    "    c_star = (2*epsilon)**(1/(degree+1))\n",
    "    \n",
    "    f_ = functools.partial(f, num_state_qubits=num_state_qubits)\n",
    "    zeta_ = functools.partial(mc_utils.zeta_from_f, func=f_, epsilon=epsilon, degree=degree, c=c_star)\n",
    "    \n",
    "    x_eval = np.linspace(0.0, 2**(num_state_qubits) - 1, num= degree+1)\n",
    "    poly = Polynomial(polyfit(x_eval, zeta_(x_eval), degree))\n",
    "    \n",
    "    b_exp = mc_utils.binary_expansion(num_state_qubits, poly)\n",
    "    \n",
    "    for controls in b_exp.keys():\n",
    "        theta = 2*b_exp[controls]\n",
    "        controls = list(controls)\n",
    "        if len(controls)==0:\n",
    "            qc.ry(-theta, qr[num_state_qubits])\n",
    "        else:\n",
    "            # define a MCRY gate:\n",
    "            # this does the same thing as qc.mcry, but is clearer in the circuit printing\n",
    "            MCRY = RYGate(-theta).control(len(controls))\n",
    "            qc.append(MCRY, [*(qr[i] for i in controls), qr[num_state_qubits]])\n",
    "\n",
    "def square_on_objective(qc, qr):\n",
    "    \"\"\"\n",
    "    Assume last qubit is the objective.\n",
    "    Shifted square wave function: if x is even, f(x) = 0; if x i s odd, f(x) = 1\n",
    "    \"\"\"\n",
    "    num_state_qubits = qc.num_qubits - 1\n",
    "    for control in range(num_state_qubits):\n",
    "        qc.cx(control, num_state_qubits)\n",
    "\n",
    "def state_prep(qc, qr, target_dist, num_state_qubits):\n",
    "    \"\"\"\n",
    "    Use controlled Ry gates to construct the superposition Sum \\sqrt{p_i} |i>\n",
    "    \"\"\"\n",
    "    r_probs = mc_utils.region_probs(target_dist, num_state_qubits)\n",
    "    regions = r_probs.keys()\n",
    "    r_norm = {}\n",
    "    \n",
    "    for r in regions:\n",
    "        num_controls = len(r) - 1\n",
    "        super_key = r[:num_controls]\n",
    "\n",
    "        if super_key=='':\n",
    "            r_norm[super_key] = 1\n",
    "        elif super_key == '1':\n",
    "            r_norm[super_key] = r_probs[super_key]\n",
    "            r_norm['0'] = 1-r_probs[super_key]\n",
    "        else:\n",
    "            try:\n",
    "                r_norm[super_key] = r_probs[super_key]\n",
    "                \n",
    "            except KeyError:\n",
    "                r_norm[super_key] = r_norm[super_key[:num_controls-1]] - r_probs[super_key[:num_controls-1] + '1']\n",
    "        \n",
    "        \n",
    "        norm = r_norm[super_key]\n",
    "        p = 0\n",
    "        if norm != 0:\n",
    "            p = r_probs[r] / norm\n",
    "        theta = 2*np.arcsin(np.sqrt(p))\n",
    "        \n",
    "        if r == '1':\n",
    "            qc.ry(-theta, num_state_qubits-1)\n",
    "        else:\n",
    "            controls = [qr[num_state_qubits-1 - i] for i in range(num_controls)]\n",
    "            \n",
    "            # define a MCRY gate:\n",
    "            # this does the same thing as qc.mcry, but is clearer in the circuit printing\n",
    "            MCRY = RYGate(-theta).control(num_controls, ctrl_state=r[:-1])\n",
    "            qc.append(MCRY, [*controls, qr[num_state_qubits-1 - num_controls]])\n",
    "\n",
    "def uniform_prep(qc, qr, num_state_qubits):\n",
    "    \"\"\"\n",
    "    Generates a uniform distribution over all states\n",
    "    \"\"\"\n",
    "    for i in range(num_state_qubits):\n",
    "        qc.h(i)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afaccb-a06f-44b5-a5c7-00cc1b2d77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE_Subroutine(num_state_qubits, num_counting_qubits, A_circuit, method):\n",
    "\n",
    "    num_qubits = num_state_qubits + num_counting_qubits\n",
    "    \n",
    "    qr_state = QuantumRegister(num_state_qubits+1)\n",
    "    qr_counting = QuantumRegister(num_counting_qubits)\n",
    "    cr = ClassicalRegister(num_counting_qubits)\n",
    "    qc = QuantumCircuit(qr_state, qr_counting, cr, name=f\"qmc({method})-{num_qubits}-{0}\")\n",
    "\n",
    "    A = A_circuit\n",
    "    cQ, Q = Ctrl_Q(num_state_qubits, A)\n",
    "    \n",
    "    # save small example subcircuits for visualization\n",
    "    global A_, Q_, cQ_, QFTI_\n",
    "    if (cQ_ and Q_) == None or num_state_qubits <= 6:\n",
    "        if num_state_qubits < 9: cQ_ = cQ; Q_ = Q\n",
    "    if A_ == None or num_state_qubits <= 3:\n",
    "        if num_state_qubits < 5: A_ = A\n",
    "    if QFTI_ == None or num_counting_qubits <= 3:\n",
    "        if num_counting_qubits < 4: QFTI_ = inv_qft_gate(num_counting_qubits)\n",
    "\n",
    "    # Prepare state from A, and counting qubits with H transform \n",
    "    qc.append(A, qr_state)\n",
    "    for i in range(num_counting_qubits):\n",
    "        qc.h(qr_counting[i])\n",
    "    \n",
    "    repeat = 1\n",
    "    for j in reversed(range(num_counting_qubits)):\n",
    "        for _ in range(repeat):\n",
    "            qc.append(cQ, [qr_counting[j]] + [qr_state[l] for l in range(num_state_qubits+1)])\n",
    "        repeat *= 2\n",
    "    \n",
    "    qc.barrier()\n",
    "    \n",
    "    # inverse quantum Fourier transform only on counting qubits\n",
    "    qc.append(inv_qft_gate(num_counting_qubits), qr_counting)\n",
    "    print(inv_qft_gate(num_counting_qubits))\n",
    "    qc.barrier()\n",
    "    \n",
    "    qc.measure([qr_counting[m] for m in range(num_counting_qubits)], list(range(num_counting_qubits)))\n",
    "    \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd41ea-92cb-4cfc-9ac1-a008e7acf63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "   \n",
    "# Construct the grover-like operator and a controlled version of it\n",
    "def Ctrl_Q(num_state_qubits, A_circ):\n",
    "\n",
    "    # index n is the objective qubit, and indexes 0 through n-1 are state qubits\n",
    "    qc = QuantumCircuit(num_state_qubits+1, name=f\"Q\")\n",
    "    \n",
    "    temp_A = copy.copy(A_circ)\n",
    "    A_gate = temp_A.to_gate()\n",
    "    A_gate_inv = temp_A.inverse().to_gate()\n",
    "    \n",
    "    ### Each cycle in Q applies in order: -S_chi, A_circ_inverse, S_0, A_circ \n",
    "    # -S_chi\n",
    "    qc.x(num_state_qubits)\n",
    "    qc.z(num_state_qubits)\n",
    "    qc.x(num_state_qubits)\n",
    "        \n",
    "    # A_circ_inverse\n",
    "    qc.append(A_gate_inv, [i for i in range(num_state_qubits+1)])\n",
    "        \n",
    "    # S_0\n",
    "    for i in range(num_state_qubits+1):\n",
    "        qc.x(i)\n",
    "    qc.h(num_state_qubits)\n",
    "    \n",
    "    qc.mcx([x for x in range(num_state_qubits)], num_state_qubits)\n",
    "    \n",
    "    qc.h(num_state_qubits)\n",
    "    for i in range(num_state_qubits+1):\n",
    "        qc.x(i)\n",
    "        \n",
    "    # A_circ\n",
    "    qc.append(A_gate, [i for i in range(num_state_qubits+1)])\n",
    "    \n",
    "    # Create a gate out of the Q operator\n",
    "    qc.to_gate(label='Q')\n",
    "    \n",
    "    # and also a controlled version of it\n",
    "    Ctrl_Q_ = qc.control(1)\n",
    "    \n",
    "    # and return both\n",
    "    return Ctrl_Q_, qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacd7d6-3b9e-4db5-9ef1-ab56b4148a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Inverse QFT Circuit\n",
    "\n",
    "def inv_qft_gate(input_size):\n",
    "    global QFTI_, num_gates, depth\n",
    "    qr = QuantumRegister(input_size); qc = QuantumCircuit(qr, name=\"inv_qft\")\n",
    "    \n",
    "    # Generate multiple groups of diminishing angle CRZs and H gate\n",
    "    for i_qubit in reversed(range(0, input_size)):\n",
    "    \n",
    "        # start laying out gates from highest order qubit (the hidx)\n",
    "        hidx = input_size - i_qubit - 1\n",
    "        \n",
    "        # precede with an H gate (applied to all qubits)\n",
    "        qc.h(qr[hidx])\n",
    "        num_gates += 1\n",
    "        depth += 1\n",
    "        \n",
    "        # if not the highest order qubit, add multiple controlled RZs of decreasing angle\n",
    "        if hidx < input_size - 1:   \n",
    "            num_crzs = i_qubit\n",
    "            for j in reversed(range(0, num_crzs)):\n",
    "                divisor = 2 ** (num_crzs - j)\n",
    "                qc.crz( -math.pi / divisor , qr[hidx], qr[input_size - j - 1])\n",
    "                num_gates += 1\n",
    "                depth += 1\n",
    "            \n",
    "        qc.barrier()  \n",
    "    \n",
    "    if QFTI_ == None or input_size <= 5:\n",
    "        if input_size < 9: QFTI_= qc\n",
    "        \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64285ed-41c7-42d4-bc25-232fc21ffbc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Noise Parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d366f-4910-4ac3-8779-428f9cf538b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty noise model\n",
    "noise_parameters = NoiseModel()\n",
    "\n",
    "if Type_of_Simulator == \"built_in\":\n",
    "    # Add depolarizing error to all single qubit gates with error rate 0.05% and to all two qubit gates with error rate 0.5%\n",
    "    depol_one_qb_error = 0.05\n",
    "    depol_two_qb_error = 0.005\n",
    "    noise_parameters.add_all_qubit_quantum_error(depolarizing_error(depol_one_qb_error, 1), ['rx', 'ry', 'rz'])\n",
    "    noise_parameters.add_all_qubit_quantum_error(depolarizing_error(depol_two_qb_error, 2), ['cx'])\n",
    "    \n",
    "    # Add amplitude damping error to all single qubit gates with error rate 0.0% and to all two qubit gates with error rate 0.0%\n",
    "    amp_damp_one_qb_error = 0.0\n",
    "    amp_damp_two_qb_error = 0.0\n",
    "    noise_parameters.add_all_qubit_quantum_error(depolarizing_error(amp_damp_one_qb_error, 1), ['rx', 'ry', 'rz'])\n",
    "    noise_parameters.add_all_qubit_quantum_error(depolarizing_error(amp_damp_two_qb_error, 2), ['cx'])\n",
    "    \n",
    "    # Add reset noise to all single qubit resets\n",
    "    reset_to_zero_error = 0.005\n",
    "    reset_to_one_error = 0.005\n",
    "    noise_parameters.add_all_qubit_quantum_error(reset_error(reset_to_zero_error, reset_to_one_error),[\"reset\"])\n",
    "    \n",
    "    # Add readout error\n",
    "    p0given1_error = 0.000\n",
    "    p1given0_error = 0.000\n",
    "    error_meas = ReadoutError([[1 - p1given0_error, p1given0_error], [p0given1_error, 1 - p0given1_error]])\n",
    "    noise_parameters.add_all_qubit_readout_error(error_meas)\n",
    "    \n",
    "    #print(noise_parameters)\n",
    "\n",
    "elif Type_of_Simulator == \"FAKE\"or\"FAKEV2\":\n",
    "    noise_parameters = NoiseModel.from_backend(backend)\n",
    "    #print(noise_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da879bde-b8b2-4c76-abfc-6db07d1322a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fidelity Calculations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3aa897-0708-47dd-b00d-3d6c54243ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis methods to be expanded and eventually compiled into a separate analysis.py file\n",
    "import math, functools\n",
    "\n",
    "def hellinger_fidelity_with_expected(p, q):\n",
    "    \"\"\" p: result distribution, may be passed as a counts distribution\n",
    "        q: the expected distribution to be compared against\n",
    "\n",
    "    References:\n",
    "        `Hellinger Distance @ wikipedia <https://en.wikipedia.org/wiki/Hellinger_distance>`_\n",
    "        Qiskit Hellinger Fidelity Function\n",
    "    \"\"\"\n",
    "    p_sum = sum(p.values())\n",
    "    q_sum = sum(q.values())\n",
    "\n",
    "    if q_sum == 0:\n",
    "        print(\"ERROR: polarization_fidelity(), expected distribution is invalid, all counts equal to 0\")\n",
    "        return 0\n",
    "\n",
    "    p_normed = {}\n",
    "    for key, val in p.items():\n",
    "        p_normed[key] = val/p_sum\n",
    "        # if p_sum != 0:\n",
    "        #     p_normed[key] = val/p_sum\n",
    "        # else:\n",
    "        #     p_normed[key] = 0\n",
    "\n",
    "    q_normed = {}\n",
    "    for key, val in q.items():\n",
    "        q_normed[key] = val/q_sum\n",
    "\n",
    "    total = 0\n",
    "    for key, val in p_normed.items():\n",
    "        if key in q_normed.keys():\n",
    "            total += (np.sqrt(val) - np.sqrt(q_normed[key]))**2\n",
    "            del q_normed[key]\n",
    "        else:\n",
    "            total += val\n",
    "    total += sum(q_normed.values())\n",
    "    \n",
    "    # in some situations (error mitigation) this can go negative, use abs value\n",
    "    if total < 0:\n",
    "        print(f\"WARNING: using absolute value in fidelity calculation\")\n",
    "        total = abs(total)\n",
    "        \n",
    "    dist = np.sqrt(total)/np.sqrt(2)\n",
    "    fidelity = (1-dist**2)**2\n",
    "\n",
    "    return fidelity\n",
    "\n",
    "def polarization_fidelity(counts, correct_dist, thermal_dist=None):\n",
    "    \"\"\"\n",
    "    Combines Hellinger fidelity and polarization rescaling into fidelity calculation\n",
    "    used in every benchmark\n",
    "\n",
    "    counts: the measurement outcomes after `num_shots` algorithm runs\n",
    "    correct_dist: the distribution we expect to get for the algorithm running perfectly\n",
    "    thermal_dist: optional distribution to pass in distribution from a uniform\n",
    "                  superposition over all states. If `None`: generated as \n",
    "                  `uniform_dist` with the same qubits as in `counts`\n",
    "                  \n",
    "    returns both polarization fidelity and the hellinger fidelity\n",
    "\n",
    "    Polarization from: `https://arxiv.org/abs/2008.11294v1`\n",
    "    \"\"\"\n",
    "    num_measured_qubits = len(list(correct_dist.keys())[0])\n",
    "    #print(num_measured_qubits)\n",
    "    \n",
    "    counts = {k.zfill(num_measured_qubits): v for k, v in counts.items()}\n",
    "    \n",
    "    # calculate hellinger fidelity between measured expectation values and correct distribution\n",
    "    hf_fidelity = hellinger_fidelity_with_expected(counts,correct_dist)\n",
    "    \n",
    "    # to limit cpu and memory utilization, skip noise correction if more than 16 measured qubits\n",
    "    if num_measured_qubits > 16:\n",
    "        return { 'fidelity':hf_fidelity, 'hf_fidelity':hf_fidelity }\n",
    "\n",
    "    # if not provided, generate thermal dist based on number of qubits\n",
    "    if thermal_dist == None:\n",
    "        thermal_dist = uniform_dist(num_measured_qubits)\n",
    "\n",
    "    # set our fidelity rescaling value as the hellinger fidelity for a depolarized state\n",
    "    floor_fidelity = hellinger_fidelity_with_expected(thermal_dist, correct_dist)\n",
    "\n",
    "    # rescale fidelity result so uniform superposition (random guessing) returns fidelity\n",
    "    # rescaled to 0 to provide a better measure of success of the algorithm (polarization)\n",
    "    new_floor_fidelity = 0\n",
    "    fidelity = rescale_fidelity(hf_fidelity, floor_fidelity, new_floor_fidelity)\n",
    "    return { 'fidelity':fidelity, 'hf_fidelity':hf_fidelity }\n",
    "\n",
    "## Uniform distribution function commonly used\n",
    "def rescale_fidelity(fidelity, floor_fidelity, new_floor_fidelity):\n",
    "    \"\"\"\n",
    "    Linearly rescales our fidelities to allow comparisons of fidelities across benchmarks\n",
    "    \n",
    "    fidelity: raw fidelity to rescale\n",
    "    floor_fidelity: threshold fidelity which is equivalent to random guessing\n",
    "    new_floor_fidelity: what we rescale the floor_fidelity to \n",
    "\n",
    "    Ex, with floor_fidelity = 0.25, new_floor_fidelity = 0.0:\n",
    "        1 -> 1;\n",
    "        0.25 -> 0;\n",
    "        0.5 -> 0.3333;\n",
    "    \"\"\"\n",
    "    rescaled_fidelity = (1-new_floor_fidelity)/(1-floor_fidelity) * (fidelity - 1) + 1\n",
    "    \n",
    "    # ensure fidelity is within bounds (0, 1)\n",
    "    if rescaled_fidelity < 0:\n",
    "        rescaled_fidelity = 0.0\n",
    "    if rescaled_fidelity > 1:\n",
    "        rescaled_fidelity = 1.0\n",
    "    return rescaled_fidelity\n",
    "\n",
    "def uniform_dist(num_state_qubits):\n",
    "    dist = {}\n",
    "    for i in range(2**num_state_qubits):\n",
    "        key = bin(i)[2:].zfill(num_state_qubits)\n",
    "        dist[key] = 1/(2**num_state_qubits)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c141e72-d128-4bb7-85f4-df1410602541",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions of Volumetric Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f398687-4a60-4c5c-9d5c-5ec29528f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "############### Color Map functions\n",
    " \n",
    "# Create a selection of colormaps from which to choose; default to custom_spectral\n",
    "cmap_spectral = plt.get_cmap('Spectral')\n",
    "cmap_greys = plt.get_cmap('Greys')\n",
    "cmap_blues = plt.get_cmap('Blues')\n",
    "cmap_custom_spectral = None\n",
    "\n",
    "# the default colormap is the spectral map\n",
    "cmap = cmap_spectral\n",
    "cmap_orig = cmap_spectral\n",
    "\n",
    "# current cmap normalization function (default None)\n",
    "cmap_norm = None\n",
    "\n",
    "default_fade_low_fidelity_level = 0.16\n",
    "default_fade_rate = 0.7\n",
    "\n",
    "\n",
    "# Specify a normalization function here (default None)\n",
    "def set_custom_cmap_norm(vmin, vmax):\n",
    "\n",
    "    global cmap_norm\n",
    "    \n",
    "    if vmin == vmax or (vmin == 0.0 and vmax == 1.0):\n",
    "        print(\"... setting cmap norm to None\")\n",
    "        cmap_norm = None\n",
    "    else:\n",
    "        print(f\"... setting cmap norm to [{vmin}, {vmax}]\")\n",
    "        cmap_norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "# Remake the custom spectral colormap with user settings\n",
    "def set_custom_cmap_style(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "            \n",
    "    #print(\"... set custom map style\")\n",
    "    global cmap, cmap_custom_spectral, cmap_orig\n",
    "    cmap_custom_spectral = create_custom_spectral_cmap(\n",
    "                fade_low_fidelity_level=fade_low_fidelity_level, fade_rate=fade_rate)\n",
    "    cmap = cmap_custom_spectral\n",
    "    cmap_orig = cmap_custom_spectral\n",
    "\n",
    "\n",
    "# Create the custom spectral colormap from the base spectral\n",
    "def create_custom_spectral_cmap(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "\n",
    "    # determine the breakpoint from the fade level\n",
    "    num_colors = 100\n",
    "    breakpoint = round(fade_low_fidelity_level * num_colors)\n",
    "    \n",
    "    # get color list for spectral map\n",
    "    spectral_colors = [cmap_spectral(v/num_colors) for v in range(num_colors)]\n",
    "\n",
    "    #print(fade_rate)\n",
    "    \n",
    "    # create a list of colors to replace those below the breakpoint\n",
    "    # and fill with \"faded\" color entries (in reverse)\n",
    "    low_colors = [0] * breakpoint\n",
    "    #for i in reversed(range(breakpoint)):\n",
    "    for i in range(breakpoint):\n",
    "    \n",
    "        # x is index of low colors, normalized 0 -> 1\n",
    "        x = i / breakpoint\n",
    "    \n",
    "        # get color at this index\n",
    "        bc = spectral_colors[i]\n",
    "        r0 = bc[0]\n",
    "        g0 = bc[1]\n",
    "        b0 = bc[2]\n",
    "        z0 = bc[3]\n",
    "        \n",
    "        r_delta = 0.92 - r0\n",
    "        \n",
    "        #print(f\"{x} {bc} {r_delta}\")\n",
    "         \n",
    "        # compute saturation and greyness ratio\n",
    "        sat_ratio = 1 - x\n",
    "        \n",
    "        #grey_ratio = 1 - x\n",
    "        '''  attempt at a reflective gradient   \n",
    "        if i >= breakpoint/2:\n",
    "            xf = 2*(x - 0.5)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (yf + 0.5)\n",
    "        else:\n",
    "            xf = 2*(0.5 - x)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (0.5 - yf)\n",
    "        '''   \n",
    "        grey_ratio = 1 - math.pow(x, 1/fade_rate)\n",
    "        \n",
    "        #print(f\"  {xf} {yf} \")\n",
    "        #print(f\"  {sat_ratio} {grey_ratio}\")\n",
    "\n",
    "        r = r0 + r_delta * sat_ratio\n",
    "        \n",
    "        g_delta = r - g0\n",
    "        b_delta = r - b0\n",
    "        g = g0 + g_delta * grey_ratio\n",
    "        b = b0 + b_delta * grey_ratio \n",
    "            \n",
    "        #print(f\"{r} {g} {b}\\n\")    \n",
    "        low_colors[i] = (r,g,b,z0)\n",
    "        \n",
    "    #print(low_colors)\n",
    "\n",
    "    # combine the faded low colors with the regular spectral cmap to make a custom version\n",
    "    cmap_custom_spectral = ListedColormap(low_colors + spectral_colors[breakpoint:])\n",
    "\n",
    "    #spectral_colors = [cmap_custom_spectral(v/10) for v in range(10)]\n",
    "    #for i in range(10): print(spectral_colors[i])\n",
    "    #print(\"\")\n",
    "    \n",
    "    return cmap_custom_spectral\n",
    "\n",
    "# Make the custom spectral color map the default on module init\n",
    "set_custom_cmap_style()\n",
    "\n",
    "# Arrange the stored annotations optimally and add to plot \n",
    "def anno_volumetric_data(ax, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True):\n",
    "    \n",
    "    # sort all arrays by the x point of the text (anno_offs)\n",
    "    global x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos\n",
    "    all_annos = sorted(zip(x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos))\n",
    "    x_anno_offs = [a for a,b,c,d,e in all_annos]\n",
    "    y_anno_offs = [b for a,b,c,d,e in all_annos]\n",
    "    anno_labels = [c for a,b,c,d,e in all_annos]\n",
    "    x_annos = [d for a,b,c,d,e in all_annos]\n",
    "    y_annos = [e for a,b,c,d,e in all_annos]\n",
    "    \n",
    "    #print(f\"{x_anno_offs}\")\n",
    "    #print(f\"{y_anno_offs}\")\n",
    "    #print(f\"{anno_labels}\")\n",
    "    \n",
    "    for i in range(len(anno_labels)):\n",
    "        x_anno = x_annos[i]\n",
    "        y_anno = y_annos[i]\n",
    "        x_anno_off = x_anno_offs[i]\n",
    "        y_anno_off = y_anno_offs[i]\n",
    "        label = anno_labels[i]\n",
    "        \n",
    "        if i > 0:\n",
    "            x_delta = abs(x_anno_off - x_anno_offs[i - 1])\n",
    "            y_delta = abs(y_anno_off - y_anno_offs[i - 1])\n",
    "            \n",
    "            if y_delta < 0.7 and x_delta < 2:\n",
    "                y_anno_off = y_anno_offs[i] = y_anno_offs[i - 1] - 0.6\n",
    "                #x_anno_off = x_anno_offs[i] = x_anno_offs[i - 1] + 0.1\n",
    "                    \n",
    "        ax.annotate(label,\n",
    "            xy=(x_anno+0.0, y_anno+0.1),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.0,\n",
    "                width=0.5, headwidth=4, headlength=5, edgecolor=(0.8,0.8,0.8)),\n",
    "            xytext=(x_anno_off + labelpos[0], y_anno_off + labelpos[1]),\n",
    "            rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='baseline',\n",
    "            color=(0.2,0.2,0.2),\n",
    "            clip_on=True)\n",
    "    if saveplots == True:\n",
    "        plt.savefig(\"VolumetricPlotSample.jpg\")\n",
    "\n",
    "# Plot one group of data for volumetric presentation    \n",
    "def plot_volumetric_data(ax, w_data, d_data, f_data, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True, w_max=18, do_label=False, do_border=True,\n",
    "        x_size=1.0, y_size=1.0, zorder=1, offset_flag=False,\n",
    "        max_depth=0, suppress_low_fidelity=False):\n",
    "\n",
    "    # since data may come back out of order, save point at max y for annotation\n",
    "    i_anno = 0\n",
    "    x_anno = 0 \n",
    "    y_anno = 0\n",
    "    \n",
    "    # plot data rectangles\n",
    "    low_fidelity_count = True\n",
    "    \n",
    "    last_y = -1\n",
    "    k = 0\n",
    "\n",
    "    # determine y-axis dimension for one pixel to use for offset of bars that start at 0\n",
    "    (_, dy) = get_pixel_dims(ax)\n",
    "    \n",
    "    # do this loop in reverse to handle the case where earlier cells are overlapped by later cells\n",
    "    for i in reversed(range(len(d_data))):\n",
    "        x = depth_index(d_data[i], depth_base)\n",
    "        y = float(w_data[i])\n",
    "        f = f_data[i]\n",
    "        \n",
    "        # each time we star a new row, reset the offset counter\n",
    "        # DEVNOTE: this is highly specialized for the QA area plots, where there are 8 bars\n",
    "        # that represent time starting from 0 secs.  We offset by one pixel each and center the group\n",
    "        if y != last_y:\n",
    "            last_y = y;\n",
    "            k = 3              # hardcoded for 8 cells, offset by 3\n",
    "        \n",
    "        #print(f\"{i = } {x = } {y = }\")\n",
    "        \n",
    "        if max_depth > 0 and d_data[i] > max_depth:\n",
    "            #print(f\"... excessive depth (2), skipped; w={y} d={d_data[i]}\")\n",
    "            break;\n",
    "            \n",
    "        # reject cells with low fidelity\n",
    "        if suppress_low_fidelity and f < suppress_low_fidelity_level:\n",
    "            if low_fidelity_count: break\n",
    "            else: low_fidelity_count = True\n",
    "        \n",
    "        # the only time this is False is when doing merged gradation plots\n",
    "        if do_border == True:\n",
    "        \n",
    "            # this case is for an array of x_sizes, i.e. each box has different width\n",
    "            if isinstance(x_size, list):\n",
    "                \n",
    "                # draw each of the cells, with no offset\n",
    "                if not offset_flag:\n",
    "                    ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size[i], y_size=y_size, zorder=zorder))\n",
    "                    \n",
    "                # use an offset for y value, AND account for x and width to draw starting at 0\n",
    "                else:\n",
    "                    ax.add_patch(box_at((x/2 + x_size[i]/4), y + k*dy, f, type=type, fill=fill, x_size=x+ x_size[i]/2, y_size=y_size, zorder=zorder))\n",
    "                \n",
    "            # this case is for only a single cell\n",
    "            else:\n",
    "                ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size, y_size=y_size))\n",
    "\n",
    "        # save the annotation point with the largest y value\n",
    "        if y >= y_anno:\n",
    "            x_anno = x\n",
    "            y_anno = y\n",
    "            i_anno = i\n",
    "        \n",
    "        # move the next bar down (if using offset)\n",
    "        k -= 1\n",
    "    \n",
    "    # if no data rectangles plotted, no need for a label\n",
    "    if x_anno == 0 or y_anno == 0:\n",
    "        return\n",
    "        \n",
    "    x_annos.append(x_anno)\n",
    "    y_annos.append(y_anno)\n",
    "    \n",
    "    anno_dist = math.sqrt( (y_anno - 1)**2 + (x_anno - 1)**2 )\n",
    "    \n",
    "    # adjust radius of annotation circle based on maximum width of apps\n",
    "    anno_max = 10\n",
    "    if w_max > 10:\n",
    "        anno_max = 14\n",
    "    if w_max > 14:\n",
    "        anno_max = 18\n",
    "        \n",
    "    scale = anno_max / anno_dist\n",
    "\n",
    "    # offset of text from end of arrow\n",
    "    if scale > 1:\n",
    "        x_anno_off = scale * x_anno - x_anno - 0.5\n",
    "        y_anno_off = scale * y_anno - y_anno\n",
    "    else:\n",
    "        x_anno_off = 0.7\n",
    "        y_anno_off = 0.5\n",
    "        \n",
    "    x_anno_off += x_anno\n",
    "    y_anno_off += y_anno\n",
    "    \n",
    "    # print(f\"... {xx} {yy} {anno_dist}\")\n",
    "    x_anno_offs.append(x_anno_off)\n",
    "    y_anno_offs.append(y_anno_off)\n",
    "    \n",
    "    anno_labels.append(label)\n",
    "    \n",
    "    if do_label:\n",
    "        ax.annotate(label, xy=(x_anno+labelpos[0], y_anno+labelpos[1]), rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='bottom', color=(0.2,0.2,0.2))\n",
    "\n",
    "x_annos = []\n",
    "y_annos = []\n",
    "x_anno_offs = []\n",
    "y_anno_offs = []\n",
    "anno_labels = []\n",
    "\n",
    "# init arrays to hold annotation points for label spreading\n",
    "def vplot_anno_init ():\n",
    "\n",
    "    global x_annos, y_annos, x_anno_offs, y_anno_offs, anno_labels\n",
    "    \n",
    "    x_annos = []\n",
    "    y_annos = []\n",
    "    x_anno_offs = []\n",
    "    y_anno_offs = []\n",
    "    anno_labels = []\n",
    "\n",
    "# Number of ticks on volumetric depth axis\n",
    "max_depth_log = 22\n",
    "\n",
    "# average transpile factor between base QV depth and our depth based on results from QV notebook\n",
    "QV_transpile_factor = 12.7 \n",
    "\n",
    "# format a number using K,M,B,T for large numbers, optionally rounding to 'digits' decimal places if num > 1\n",
    "# (sign handling may be incorrect)\n",
    "def format_number(num, digits=0):\n",
    "    if isinstance(num, str): num = float(num)\n",
    "    num = float('{:.3g}'.format(abs(num)))\n",
    "    sign = ''\n",
    "    metric = {'T': 1000000000000, 'B': 1000000000, 'M': 1000000, 'K': 1000, '': 1}\n",
    "    for index in metric:\n",
    "        num_check = num / metric[index]\n",
    "        if num_check >= 1:\n",
    "            num = round(num_check, digits)\n",
    "            sign = index\n",
    "            break\n",
    "    numstr = f\"{str(num)}\"\n",
    "    if '.' in numstr:\n",
    "        numstr = numstr.rstrip('0').rstrip('.')\n",
    "    return f\"{numstr}{sign}\"\n",
    "\n",
    "# Return the color associated with the spcific value, using color map norm\n",
    "def get_color(value):\n",
    "    \n",
    "    # if there is a normalize function installed, scale the data\n",
    "    if cmap_norm:\n",
    "        value = float(cmap_norm(value))\n",
    "        \n",
    "    if cmap == cmap_spectral:\n",
    "        value = 0.05 + value*0.9\n",
    "    elif cmap == cmap_blues:\n",
    "        value = 0.00 + value*1.0\n",
    "    else:\n",
    "        value = 0.0 + value*0.95\n",
    "        \n",
    "    return cmap(value)\n",
    "\n",
    "# Return the x and y equivalent to a single pixel for the given plot axis\n",
    "def get_pixel_dims(ax):\n",
    "\n",
    "    # transform 0 -> 1 to pixel dimensions\n",
    "    pixdims = ax.transData.transform([(0,1),(1,0)])-ax.transData.transform((0,0))\n",
    "    xpix = pixdims[1][0]\n",
    "    ypix = pixdims[0][1]\n",
    "    \n",
    "    #determine x- and y-axis dimension for one pixel \n",
    "    dx = (1 / xpix)\n",
    "    dy = (1 / ypix)\n",
    "    \n",
    "    return (dx, dy)\n",
    "\n",
    "############### Helper functions\n",
    " \n",
    "# return the base index for a circuit depth value\n",
    "# take the log in the depth base, and add 1\n",
    "def depth_index(d, depth_base):\n",
    "    if depth_base <= 1:\n",
    "        return d\n",
    "    if d == 0:\n",
    "        return 0\n",
    "    return math.log(d, depth_base) + 1\n",
    "\n",
    "# draw a box at x,y with various attributes   \n",
    "def box_at(x, y, value, type=1, fill=True, x_size=1.0, y_size=1.0, alpha=1.0, zorder=1):\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Rectangle((x - (x_size/2), y - (y_size/2)), x_size, y_size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5*y_size,\n",
    "             zorder=zorder)\n",
    "\n",
    "# draw a circle at x,y with various attributes \n",
    "def circle_at(x, y, value, type=1, fill=True):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Circle((x, y), size/2,\n",
    "             alpha = 0.7,                       # DEVNOTE: changed to 0.7 from 0.5, to handle only one cell\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5)\n",
    "             \n",
    "def box4_at(x, y, value, type=1, fill=True, alpha=1.0):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.3,0.3,0.3)\n",
    "    ec = fc\n",
    "    \n",
    "    return Rectangle((x - size/8, y - size/2), size/4, size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.1)\n",
    "\n",
    "# Draw a Quantum Volume rectangle with specified width and depth, and grey-scale value \n",
    "def qv_box_at(x, y, qv_width, qv_depth, value, depth_base):\n",
    "    #print(f\"{qv_width} {qv_depth} {depth_index(qv_depth, depth_base)}\")\n",
    "    return Rectangle((x - 0.5, y - 0.5), depth_index(qv_depth, depth_base), qv_width,\n",
    "             edgecolor = (value,value,value),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=1)\n",
    "\n",
    "def bkg_box_at(x, y, value=0.9):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "             \n",
    "def bkg_empty_box_at(x, y):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (1.0,1.0,1.0),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "\n",
    "# Plot the background for the volumetric analysis    \n",
    "def plot_volumetric_background(max_qubits=11, QV=32, depth_base=2, suptitle=None, avail_qubits=0, colorbar_label=\"Avg Result Fidelity\"):\n",
    "\n",
    "    if suptitle == None:\n",
    "        suptitle = f\"Volumetric Positioning\\nCircuit Dimensions and Fidelity Overlaid on Quantum Volume = {QV}\"\n",
    "\n",
    "    QV0 = QV\n",
    "    qv_estimate = False\n",
    "    est_str = \"\"\n",
    "    if QV == 0:                 # QV = 0 indicates \"do not draw QV background or label\"\n",
    "        QV = 2048\n",
    "        \n",
    "    elif QV < 0:                # QV < 0 indicates \"add est. to label\"\n",
    "        QV = -QV\n",
    "        qv_estimate = True\n",
    "        est_str = \" (est.)\"\n",
    "        \n",
    "    if avail_qubits > 0 and max_qubits > avail_qubits:\n",
    "        max_qubits = avail_qubits\n",
    "        \n",
    "    max_width = 13\n",
    "    if max_qubits > 11: max_width = 18\n",
    "    if max_qubits > 14: max_width = 20\n",
    "    if max_qubits > 16: max_width = 24\n",
    "    if max_qubits > 24: max_width = 33\n",
    "    #print(f\"... {avail_qubits} {max_qubits} {max_width}\")\n",
    "    \n",
    "    plot_width = 6.8\n",
    "    plot_height = 0.5 + plot_width * (max_width / max_depth_log)\n",
    "    #print(f\"... {plot_width} {plot_height}\")\n",
    "    \n",
    "    # define matplotlib figure and axis; use constrained layout to fit colorbar to right\n",
    "    fig, ax = plt.subplots(figsize=(plot_width, plot_height), constrained_layout=True)\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    plt.xlim(0, max_depth_log)\n",
    "    plt.ylim(0, max_width)\n",
    "\n",
    "    # circuit depth axis (x axis)\n",
    "    xbasis = [x for x in range(1,max_depth_log)]\n",
    "    xround = [depth_base**(x-1) for x in xbasis]\n",
    "    xlabels = [format_number(x) for x in xround]\n",
    "    ax.set_xlabel('Circuit Depth')\n",
    "    ax.set_xticks(xbasis)  \n",
    "    plt.xticks(xbasis, xlabels, color='black', rotation=45, ha='right', va='top', rotation_mode=\"anchor\")\n",
    "    \n",
    "    # other label options\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-60, ha='left')\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-45, ha='left', va='center', rotation_mode=\"anchor\")\n",
    "\n",
    "    # circuit width axis (y axis)\n",
    "    ybasis = [y for y in range(1,max_width)]\n",
    "    yround = [1,2,3,4,5,6,7,8,10,12,15]     # not used now\n",
    "    ylabels = [str(y) for y in yround]      # not used now \n",
    "    #ax.set_ylabel('Circuit Width (Number of Qubits)')\n",
    "    ax.set_ylabel('Circuit Width')\n",
    "    ax.set_yticks(ybasis)\n",
    "\n",
    "    #create simple line plot (not used right now)\n",
    "    #ax.plot([0, 10],[0, 10])\n",
    "    \n",
    "    log2QV = math.log2(QV)\n",
    "    QV_width = log2QV\n",
    "    QV_depth = log2QV * QV_transpile_factor\n",
    "    \n",
    "    # show a quantum volume rectangle of QV = 64 e.g. (6 x 6)\n",
    "    if QV0 != 0:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.87, depth_base))\n",
    "    else:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.91, depth_base))\n",
    "    \n",
    "    # the untranspiled version is commented out - we do not show this by default\n",
    "    # also show a quantum volume rectangle un-transpiled\n",
    "    # ax.add_patch(qv_box_at(1, 1, QV_width, QV_width, 0.80, depth_base))\n",
    "\n",
    "    # show 2D array of volumetric cells based on this QV_transpiled\n",
    "    # DEVNOTE: we use +1 only to make the visuals work; s/b without\n",
    "    # Also, the second arg of the min( below seems incorrect, needs correction\n",
    "    maxprod = (QV_width + 1) * (QV_depth + 1)\n",
    "    for w in range(1, min(max_width, round(QV) + 1)):\n",
    "        \n",
    "        # don't show VB squares if width greater than known available qubits\n",
    "        if avail_qubits != 0 and w > avail_qubits:\n",
    "            continue\n",
    "        \n",
    "        i_success = 0\n",
    "        for d in xround:\n",
    "        \n",
    "            # polarization factor for low circuit widths\n",
    "            maxtest = maxprod / ( 1 - 1 / (2**w) )\n",
    "            \n",
    "            # if circuit would fail here, don't draw box\n",
    "            if d > maxtest: continue\n",
    "            if w * d > maxtest: continue\n",
    "            \n",
    "            # guess for how to capture how hardware decays with width, not entirely correct\n",
    "\n",
    "            # # reduce maxtext by a factor of number of qubits > QV_width\n",
    "            # # just an approximation to account for qubit distances\n",
    "            # if w > QV_width:\n",
    "            #     over = w - QV_width \n",
    "            #     maxtest = maxtest / (1 + (over/QV_width))\n",
    "\n",
    "            # draw a box at this width and depth\n",
    "            id = depth_index(d, depth_base) \n",
    "            \n",
    "            # show vb rectangles; if not showing QV, make all hollow (or less dark)\n",
    "            if QV0 == 0:\n",
    "                #ax.add_patch(bkg_empty_box_at(id, w))\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.95))\n",
    "            \n",
    "            else:\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.9))\n",
    "            \n",
    "            # save index of last successful depth\n",
    "            i_success += 1\n",
    "        \n",
    "        # plot empty rectangle after others       \n",
    "        d = xround[i_success]\n",
    "        id = depth_index(d, depth_base) \n",
    "        ax.add_patch(bkg_empty_box_at(id, w))\n",
    "        \n",
    "    \n",
    "    # Add annotation showing quantum volume\n",
    "    if QV0 != 0:\n",
    "        t = ax.text(max_depth_log - 2.0, 1.5, f\"QV{est_str}={QV}\", size=12,\n",
    "                horizontalalignment='right', verticalalignment='center', color=(0.2,0.2,0.2),\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=(.9,.9,.9), ec=\"grey\", lw=1))\n",
    "                \n",
    "    # add colorbar to right of plot\n",
    "    plt.colorbar(cm.ScalarMappable(cmap=cmap), cax=None, ax=ax,\n",
    "            shrink=0.6, label=colorbar_label, panchor=(0.0, 0.7))\n",
    "            \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da132d-e6e0-45c3-aa4a-fa4a33f8b3b7",
   "metadata": {},
   "source": [
    "# Benchmarking Essentials and Fidelity Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e84de2-4d3b-4d2f-8dc3-5e8d868530d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate circuit depth\n",
    "def calculate_circuit_depth(qc):\n",
    "    # Calculate the depth of the circuit\n",
    "    depth = qc.depth()\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbda76c-f37f-4957-90f2-8f62024a61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transpiled_depth(qc,basis_selector):\n",
    "    # use either the backend or one of the basis gate sets\n",
    "    if basis_selector == 0:\n",
    "        qc = transpile(qc, backend) \n",
    "    else:\n",
    "        basis_gates = basis_gates_array[basis_selector]\n",
    "        qc = transpile(qc, basis_gates=basis_gates, seed_transpiler=0)\n",
    "    transpiled_depth = qc.depth()\n",
    "    return transpiled_depth,qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e0648-2e4d-4a7d-ba88-c6fba3cfdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fidelity_data(fidelity_data, Hf_fidelity_data, title):\n",
    "    avg_fidelity_means = []\n",
    "    avg_Hf_fidelity_means = []\n",
    "    std_f = []\n",
    "    std_hf = []\n",
    "    avg_num_qubits_values = list(fidelity_data.keys())\n",
    "    \n",
    "    # Calculate the average fidelity and Hamming fidelity for each unique number of qubits\n",
    "    for num_qubits in avg_num_qubits_values:\n",
    "        avg_fidelity = round(np.average(fidelity_data[num_qubits]),2)\n",
    "        avg_fidelity_means.append(avg_fidelity)\n",
    "        std_fidelity = round(np.std(fidelity_data[num_qubits])/np.sqrt(len(fidelity_data)), 3)\n",
    "        std_f.append(std_fidelity)\n",
    "        avg_Hf_fidelity = round(np.mean(Hf_fidelity_data[num_qubits]),2)\n",
    "        avg_Hf_fidelity_means.append(avg_Hf_fidelity)\n",
    "        std_Hfidelity = round(np.std(Hf_fidelity_data[num_qubits])/np.sqrt(len(Hf_fidelity_data)), 3)\n",
    "        std_hf.append(std_Hfidelity)\n",
    "    \n",
    "    return avg_fidelity_means,avg_Hf_fidelity_means,std_f,std_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635b5ba-59ec-45a2-a1f3-c94b0b553317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_gates = []\n",
    "def list_of_standardgates():\n",
    "    import qiskit.circuit.library as lib\n",
    "    from qiskit.circuit import Gate\n",
    "    import inspect\n",
    "    \n",
    "    # List all the attributes of the library module\n",
    "    gate_list = dir(lib)\n",
    "    \n",
    "    # Filter out non-gate classes (like functions, variables, etc.)\n",
    "    gates = [gate for gate in gate_list if isinstance(getattr(lib, gate), type) and issubclass(getattr(lib, gate), Gate)]\n",
    "\n",
    "    # Get method names from QuantumCircuit\n",
    "    circuit_methods = inspect.getmembers(QuantumCircuit, inspect.isfunction)\n",
    "    method_names = [name for name, _ in circuit_methods]\n",
    "    \n",
    "    # Map gate class names to method names\n",
    "    gate_to_method = {}\n",
    "    for gate in gates:\n",
    "        gate_class = getattr(lib, gate)\n",
    "        class_name = gate_class.__name__.replace('Gate', '').lower()  # Normalize class name\n",
    "        for method in method_names:\n",
    "            if method == class_name or method == class_name.replace('cr', 'c-r'):\n",
    "                gate_to_method[gate] = method\n",
    "                break\n",
    "    \n",
    "    # Add common operations that are not strictly gates\n",
    "    additional_operations = {\n",
    "        'Measure': 'measure',\n",
    "        'Barrier': 'barrier',\n",
    "    }\n",
    "    gate_to_method.update(additional_operations)\n",
    "    \n",
    "    for k,v in gate_to_method.items():\n",
    "        list_of_gates.append(v)\n",
    "\n",
    "\n",
    "def update_counts(gates,custom_gates):\n",
    "    operations = {}\n",
    "    for key, value in gates.items():\n",
    "        operations[key] = value\n",
    "    for key, value in custom_gates.items():\n",
    "        if key in operations:\n",
    "            operations[key] += value\n",
    "        else:\n",
    "            operations[key] = value       \n",
    "    return operations\n",
    "\n",
    "\n",
    "def get_gate_counts(gates,custom_gate_defs):\n",
    "    result = gates.copy()\n",
    "    # Iterate over the gate counts in the quantum circuit\n",
    "    for gate, count in gates.items():\n",
    "        if gate in custom_gate_defs:\n",
    "            custom_gate_ops = custom_gate_defs[gate]\n",
    "            # Multiply custom gate operations by the count of the custom gate in the circuit\n",
    "            for _ in range(count):\n",
    "                result = update_counts(result, custom_gate_ops)\n",
    "            # Remove the custom gate entry as we have expanded it\n",
    "            del result[gate]\n",
    "    return result\n",
    "\n",
    "dict_of_qc = dict() \n",
    "custom_gates_defs = dict()\n",
    "\n",
    "# Function to count operations recursively\n",
    "def count_operations(qc):\n",
    "    dict_of_qc.clear()\n",
    "    circuit_traverser(qc)\n",
    "    operations = dict()\n",
    "    operations = dict_of_qc[qc.name]\n",
    "    del dict_of_qc[qc.name]\n",
    "    # print(\"operations :\",operations)\n",
    "    # print(\"dict_of_qc :\",dict_of_qc)\n",
    "    for keys in operations.keys():\n",
    "        if keys not in list_of_gates:\n",
    "            for k,v in dict_of_qc.items():\n",
    "                if k in operations.keys():\n",
    "                    custom_gates_defs[k] = v\n",
    "                    operations=get_gate_counts(operations,custom_gates_defs)\n",
    "                    custom_gates_defs.clear()\n",
    "    return operations\n",
    "\n",
    "def circuit_traverser(qc):\n",
    "    dict_of_qc[qc.name]=dict(qc.count_ops())\n",
    "    for i in qc.data:\n",
    "        if str(i.operation.name) not in list_of_gates:\n",
    "            qc_1 = i.operation.definition\n",
    "            circuit_traverser(qc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8f9fb-095c-40b6-9fe6-084b16dcffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "def get_memory():\n",
    "    \n",
    "    usage = resource.getrusage(resource.RUSAGE_SELF)\n",
    "    max_mem = usage.ru_maxrss/1024 #in MB\n",
    "    return max_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bff255-890c-46d2-af0f-9cbda75ab229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_excel_with_data(filename, data_to_excel, noise_inclusion=False):\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        from openpyxl import load_workbook, Workbook\n",
    "        from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "        from openpyxl.styles import Alignment, PatternFill\n",
    "    except ImportError:\n",
    "        import pip\n",
    "        pip.main(['install', 'openpyxl','pandas'])\n",
    "        import pandas as pd\n",
    "        from openpyxl import load_workbook, Workbook\n",
    "        from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "        from openpyxl.styles import Alignment, PatternFill\n",
    "\n",
    "    config = data_to_excel['configuration']\n",
    "    del data_to_excel['configuration']\n",
    "    gate_counts_plots = data_to_excel[\"gate_counts_plots\"]\n",
    "    del data_to_excel[\"gate_counts_plots\"]\n",
    "    min_qubits=config['min_qbits']\n",
    "    max_qubits=config['max_qbits']\n",
    "    skip_qubits=config['skp_qubits']\n",
    "    num_ckts = config['num_ckts']\n",
    "    qv = config['QV_']\n",
    "    simulator_type= config['Type_of_Simulator']\n",
    "    benchmark_name = config['benchmark_name']\n",
    "    Processor = config['Processor']\n",
    "    Cores = config['cores']\n",
    "    last_updated = data_to_excel['last_updated']\n",
    "    del data_to_excel['last_updated']\n",
    "    #print(data_to_excel)\n",
    "    df = pd.DataFrame(data_to_excel)\n",
    "    \n",
    "    # Load the workbook if it exists, otherwise create a new one\n",
    "    try:\n",
    "        workbook = load_workbook(filename)\n",
    "        if simulator_type in workbook.sheetnames:\n",
    "            worksheet = workbook[simulator_type]\n",
    "        else:\n",
    "            worksheet = workbook.create_sheet(simulator_type)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        workbook = Workbook()\n",
    "        worksheet = workbook.active\n",
    "        worksheet.title = simulator_type\n",
    "\n",
    "    # Add an empty row for separation\n",
    "    worksheet.append([''] * len(df.columns))\n",
    "     \n",
    "    title_row = [f'Qiskit: Algorithm = {benchmark_name} Simulator = {simulator_type}']\n",
    "    worksheet.append(title_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the title row\n",
    "    title_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "    worksheet.merge_cells(title_cell_range)\n",
    "\n",
    "    HW_row = [f'CPU: {Processor} with {cores} cores']\n",
    "    worksheet.append(HW_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the title row\n",
    "    HW_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "    worksheet.merge_cells(HW_cell_range)\n",
    "\n",
    "    if noise_inclusion:\n",
    "        noise_row = [f\"Executing with Noise\"]\n",
    "        worksheet.append(noise_row + [''] * (len(df.columns) - 1))\n",
    "        # Merge cells for the title row\n",
    "        noise_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "        worksheet.merge_cells(noise_cell_range)\n",
    "            \n",
    "    # Add the configuration row spanning all columns\n",
    "    config_row = [f'Configuration: Min_Qubits = {min_qubits} Max_Qubits = {max_qubits} Skip_Qubits = {skip_qubits} num_circuits = {num_ckts[0]}  QV_ = {qv} Last_Updated = {last_updated}']\n",
    "    worksheet.append(config_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the configuration row\n",
    "    config_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "    worksheet.merge_cells(config_cell_range)\n",
    "\n",
    "    # Center align all cells in the worksheet\n",
    "    for row in worksheet.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "    # Append the DataFrame to the worksheet\n",
    "    for r in dataframe_to_rows(df, index=False):\n",
    "        worksheet.append(r)\n",
    "\n",
    "    # Add an empty row for separation\n",
    "    worksheet.append([''] * len(df.columns))\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe65fc-e9ef-4205-ad53-ab85c08f3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_info():\n",
    "    try:\n",
    "        import cpuinfo\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        # Install the package if not found\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"py-cpuinfo\"])\n",
    "        import cpuinfo\n",
    "    \n",
    "    processor = cpuinfo.get_cpu_info()['brand_raw']\n",
    "    cores = cpuinfo.get_cpu_info()['count']\n",
    "    \n",
    "    return processor, cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333787e7-c488-461c-99b1-81bf849c6caf",
   "metadata": {},
   "source": [
    "# Analyzer Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b131406-768c-40b5-86d4-a3738c8abf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer(num_counting_qubits,num_state_qubits,mu,f_of_X):\n",
    "    # generate exact value for the expectation value given our function and dist\n",
    "    target_dist = p_distribution(num_state_qubits, mu)\n",
    "    f = functools.partial(f_of_X, num_state_qubits=num_state_qubits)\n",
    "    if method == 1:\n",
    "        exact = mc_utils.estimated_value(target_dist, f)\n",
    "    elif method == 2:\n",
    "        exact = 0.5 # hard coded exact value from uniform dist and square function\n",
    "\n",
    "    # calculate the expected output histogram\n",
    "    correct_dist = a_to_bitstring(exact, num_counting_qubits)\n",
    "    # generate thermal_dist with amplitudes instead, to be comparable to correct_dist\n",
    "    thermal_dist = uniform_dist(num_counting_qubits) \n",
    "\n",
    "    # # convert counts, expectation, and thermal_dist to app form for visibility\n",
    "    # # app form of correct distribution is measuring the input a 100% of the time\n",
    "    # # convert bit_counts into expectation values counts according to Quantum Risk Analysis paper\n",
    "    # app_counts = expectation_from_bits(counts, num_counting_qubits, num_shots, method)\n",
    "    # app_correct_dist = mc_utils.mc_dist(num_counting_qubits, exact, c_star, method)\n",
    "    # app_thermal_dist = expectation_from_bits(thermal_dist, num_counting_qubits, num_shots, method)\n",
    "    \n",
    "    return correct_dist,thermal_dist\n",
    "\n",
    "def a_to_bitstring(a, num_counting_qubits):\n",
    "    m = num_counting_qubits\n",
    "\n",
    "    # solution 1\n",
    "    num1 = round(np.arcsin(np.sqrt(a)) / np.pi * 2**m)\n",
    "    num2 = round( (np.pi - np.arcsin(np.sqrt(a))) / np.pi * 2**m)\n",
    "    if num1 != num2 and num2 < 2**m and num1 < 2**m:\n",
    "        counts = {format(num1, \"0\"+str(m)+\"b\"): 0.5, format(num2, \"0\"+str(m)+\"b\"): 0.5}\n",
    "    else:\n",
    "        counts = {format(num1, \"0\"+str(m)+\"b\"): 1}\n",
    "    return counts\n",
    "\n",
    "def expectation_from_bits(bits, num_qubits, num_shots, method):\n",
    "    amplitudes = {}\n",
    "    for b in bits.keys():\n",
    "        precision = int(num_qubits / (np.log2(10))) + 2\n",
    "\n",
    "        r = bits[b]\n",
    "        a_meas = pow(np.sin(np.pi*int(b,2)/pow(2,num_qubits)),2)\n",
    "        if method == 1:\n",
    "            a = ((a_meas - 0.5)/c_star) + 0.5\n",
    "        if method == 2:\n",
    "            a = a_meas\n",
    "        a = round(a, precision)\n",
    "        \n",
    "        if a not in amplitudes.keys():\n",
    "            amplitudes[a] = 0\n",
    "        amplitudes[a] += r\n",
    "    \n",
    "    return amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6a687-6cef-487e-9876-fa2a1a644b76",
   "metadata": {},
   "source": [
    "# RUN Function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68d3ef-277e-4a07-8161-ca8ec31ff609",
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 1:\n",
    "    MIN_STATE_QUBITS = 2\n",
    "elif method == 2:\n",
    "    MIN_STATE_QUBITS = 1\n",
    "\n",
    "def run (min_qubits=min_qubits, max_qubits=max_qubits, skip_qubits=skip_qubits, \n",
    "         max_circuits=max_circuits, num_shots=num_shots, epsilon=epsilon, degree=degree,\n",
    "        num_state_qubits = MIN_STATE_QUBITS, method=2 #(default)\n",
    "        ):\n",
    "\n",
    "    num_qubits_of_ckt = []\n",
    "    creation_times = []\n",
    "    elapsed_times = []\n",
    "    quantum_times = []\n",
    "    circuit_depths = []\n",
    "    transpiled_depths = []\n",
    "    fidelity_data = {}\n",
    "    Hf_fidelity_data = {}\n",
    "    numckts = []\n",
    "    mem_usage = []\n",
    "    algorithmic_1Q_gate_counts = []\n",
    "    algorithmic_2Q_gate_counts = []\n",
    "    transpiled_1Q_gate_counts = []\n",
    "    transpiled_2Q_gate_counts = []\n",
    "    xi = []\n",
    "    tr_xi = []\n",
    "    \n",
    "    print(f\"{benchmark_name} Benchmark Program - {platform}\")\n",
    "    #defining all the standard gates supported by qiskit in a list\n",
    "    if gate_counts_plots == True:\n",
    "        list_of_standardgates()\n",
    "\n",
    "    skip_qubits = max(1, skip_qubits)\n",
    "    print(f\"min, max qubits = {min_qubits} {max_qubits}\")\n",
    "\n",
    "    global c_star\n",
    "    c_star = (2*epsilon)**(1/(degree+1))\n",
    "    \n",
    "    global max_ckts\n",
    "    max_ckts = max_circuits\n",
    "\n",
    "    global min_qbits,max_qbits,skp_qubits\n",
    "\n",
    "    min_qbits = min_qubits\n",
    "    max_qbits = max_qubits\n",
    "    skp_qubits = skip_qubits\n",
    "\n",
    "    print(f\"min, max qubits = {min_qubits} {max_qubits}\")\n",
    "    \n",
    "    # Execute Benchmark Program N times for multiple circuit sizes\n",
    "    for num_qubits in range(min_qubits, max_qubits + 1, skip_qubits):\n",
    "        \n",
    "        fidelity_data[num_qubits] = []\n",
    "        Hf_fidelity_data[num_qubits] = []\n",
    "        \n",
    "        # reset random seed \n",
    "        np.random.seed(0)\n",
    "\n",
    "        input_size = num_qubits - 1 # TODO: keep using inputsize? only used in num_circuits\n",
    "        \n",
    "        # as circuit width grows, the number of counting qubits is increased\n",
    "        num_counting_qubits = num_qubits - num_state_qubits - 1\n",
    "\n",
    "        # determine number of circuits to execute for this group\n",
    "        num_circuits = min(2 ** (input_size), max_circuits)\n",
    "\n",
    "        print(f\"Executing [{num_circuits}] circuits with num_qubits = {num_qubits}\")\n",
    "        numckts.append(num_circuits)\n",
    "\n",
    "        # determine range of circuits to loop over for method 1\n",
    "        if 2**(input_size) <= max_circuits:\n",
    "            mu_range = [i/2**(input_size) for i in range(num_circuits)]\n",
    "        else:\n",
    "            mu_range = [i/2**(input_size) for i in np.random.choice(2**(input_size), num_circuits, False)]\n",
    "            \n",
    "        for mu in mu_range:\n",
    "            print(\"*********************************************\")\n",
    "            \n",
    "            print(f\"qc of {num_qubits} qubits for mu value {mu}\")\n",
    "\n",
    "            target_dist = p_distribution(num_state_qubits, mu)\n",
    "            f_to_estimate = functools.partial(f_of_X, num_state_qubits=num_state_qubits)\n",
    "\n",
    "            #creation of Quantum Circuit.\n",
    "            ts = time.time()\n",
    "            qc = MonteCarloSampling(target_dist, f_to_estimate, \n",
    "                                    num_state_qubits, num_counting_qubits, epsilon, degree, method=method)\n",
    "            #creation time\n",
    "            creation_time = (time.time() - ts)*1000\n",
    "            creation_times.append(creation_time)\n",
    "            #print(qc)\n",
    "            print(f\"creation time = {creation_time} ms\")\n",
    "            num_qubits_of_ckt.append(qc.num_qubits)\n",
    "            \n",
    "            # Calculate gate count for the algorithmic circuit (excluding barriers and measurements)\n",
    "            \n",
    "            if gate_counts_plots == True:\n",
    "                operations = count_operations(qc)\n",
    "                n1q = 0; n2q = 0\n",
    "                if operations != None:\n",
    "                    for key, value in operations.items():\n",
    "                        if key == \"measure\": continue\n",
    "                        if key == \"barrier\": continue\n",
    "                        if key.startswith(\"c\") or key.startswith(\"mc\"):\n",
    "                            n2q += value\n",
    "                        else:\n",
    "                            n1q += value\n",
    "                xi_value = n2q/(n1q+n2q)\n",
    "                xi.append(xi_value)            \n",
    "                algorithmic_1Q_gate_counts.append(n1q)\n",
    "                algorithmic_2Q_gate_counts.append(n2q)\n",
    "            \n",
    "            # collapse the sub-circuit levels used in this benchmark (for qiskit)\n",
    "            qc=qc.decompose().decompose().decompose().decompose()\n",
    "            #print(qc)\n",
    "            \n",
    "            # Calculate circuit depth\n",
    "            depth = calculate_circuit_depth(qc)\n",
    "            circuit_depths.append(depth)\n",
    "            \n",
    "            # Calculate transpiled circuit depth\n",
    "            transpiled_depth,qc = calculate_transpiled_depth(qc,basis_selector)\n",
    "            transpiled_depths.append(transpiled_depth)\n",
    "            #print(qc)\n",
    "            \n",
    "            print(f\"Algorithmic Depth = {depth} and Normalized Depth = {transpiled_depth}\")\n",
    "            \n",
    "            if gate_counts_plots == True:\n",
    "                # Calculate gate count for the transpiled circuit (excluding barriers and measurements)\n",
    "                tr_ops = qc.count_ops()\n",
    "                #print(\"tr_ops = \",tr_ops)\n",
    "                tr_n1q = 0; tr_n2q = 0\n",
    "                if tr_ops != None:\n",
    "                    for key, value in tr_ops.items():\n",
    "                        if key == \"measure\": continue\n",
    "                        if key == \"barrier\": continue\n",
    "                        if key.startswith(\"c\"): tr_n2q += value\n",
    "                        else: tr_n1q += value\n",
    "                tr_xi_value =tr_n2q/(tr_n1q+tr_n2q) \n",
    "                tr_xi.append(tr_xi_value)            \n",
    "                transpiled_1Q_gate_counts.append(tr_n1q)\n",
    "                transpiled_2Q_gate_counts.append(tr_n2q)\n",
    "    \n",
    "                print(f\"Algorithmic 1Q gates = {n1q} ,Algorithmic 2Q gates = {n2q}, xi = {xi_value}\")\n",
    "                print(f\"Normalized 1Q gates = {tr_n1q} ,Normalized 2Q gates = {tr_n2q}, tr_xi = {tr_xi_value}\")\n",
    "            \n",
    "            \n",
    "            #execution\n",
    "            if Type_of_Simulator == \"built_in\":\n",
    "                #To check if Noise is required\n",
    "                if Noise_Inclusion == True:\n",
    "                    noise_model = noise_parameters\n",
    "                else:\n",
    "                    noise_model = None\n",
    "                ts = time.time()\n",
    "                job = execute(qc, backend, shots=num_shots, noise_model=noise_model)\n",
    "            elif Type_of_Simulator == \"FAKE\" or Type_of_Simulator == \"FAKEV2\" :\n",
    "                ts = time.time()\n",
    "                job =  backend.run(qc,shots=num_shots, noise_model=noise_parameters) \n",
    "                \n",
    "            #retrieving the result \n",
    "            result = job.result()\n",
    "            #print(result)\n",
    "            \n",
    "            #calculating elapsed time\n",
    "            elapsed_time = (time.time() - ts)*1000\n",
    "            elapsed_times.append(elapsed_time)\n",
    "            \n",
    "            \n",
    "            # Calculate quantum processing time \n",
    "            quantum_time = (result.time_taken)*1000\n",
    "            quantum_times.append(quantum_time)\n",
    "\n",
    "            print(f\"Elapsed time = {elapsed_time} ms and Quantum Time = {quantum_time} ms\")\n",
    "            \n",
    "            #counts in result object \n",
    "            counts = result.get_counts()\n",
    "            \n",
    "\n",
    "            #Correct distribution to compare with counts\n",
    "            correct_dist,thermal_dist = analyzer(num_counting_qubits,num_state_qubits,mu,f_of_X)\n",
    "            print(\"Correct_dist :\",correct_dist)\n",
    "            print(\"Thermal_dist :\",thermal_dist)\n",
    "            \n",
    "            #fidelity calculation comparision of counts and correct_dist \n",
    "            fidelity_dict = polarization_fidelity(counts, correct_dist, thermal_dist)\n",
    "            ###########################################################################\n",
    "            # NOTE: in this benchmark, we are testing how well the amplitude estimation routine\n",
    "            #       works according to theory, and we do not measure the difference between\n",
    "            #       the reported answer and the correct answer; the below code just helps\n",
    "            #       demonstrate that we do approximate the expectation value accurately.\n",
    "        \n",
    "            # the max in the counts is what the algorithm would report as the correct answer\n",
    "            a, _ = mc_utils.value_and_max_prob_from_dist(counts)\n",
    "\n",
    "            fidelity_data[num_qubits].append(fidelity_dict['fidelity'])\n",
    "            Hf_fidelity_data[num_qubits].append(fidelity_dict['hf_fidelity'])\n",
    "            print(\"Fidelity = \",fidelity_dict)\n",
    "            #maximum memory utilization (if required)\n",
    "            if Memory_utilization_plot == True:\n",
    "                max_mem = get_memory()\n",
    "                print(f\"Maximum Memory Utilized: {max_mem} MB\")\n",
    "                mem_usage.append(max_mem)\n",
    "                \n",
    "            print(\"*********************************************\")\n",
    "    \n",
    "    # print a sample circuit\n",
    "    print(\"Sample Circuit:\"); print(QC_ if QC_ != None else \"  ... too large!\")\n",
    "    print(\"\\nControlled Quantum Operator 'cQ' =\"); print(cQ_ if cQ_ != None else \" ... too large!\")\n",
    "    print(\"\\nQuantum Operator 'Q' =\"); print(Q_ if Q_ != None else \" ... too large!\")\n",
    "    print(\"\\nAmplitude Generator 'A' =\"); print(A_ if A_ != None else \" ... too large!\")\n",
    "    print(\"\\nDistribution Generator 'R' =\"); print(R_ if R_ != None else \" ... too large!\")\n",
    "    print(\"\\nFunction Generator 'F' =\"); print(F_ if F_ != None else \" ... too large!\")\n",
    "    print(\"\\nInverse QFT Circuit =\"); print(QFTI_ if QFTI_ != None else \"  ... too large!\")\n",
    "    \n",
    "    return (num_qubits_of_ckt,creation_times, elapsed_times, quantum_times, circuit_depths, transpiled_depths, xi, tr_xi,\n",
    "            fidelity_data, Hf_fidelity_data, numckts , algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts,\n",
    "    transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4f824-f566-4c63-a1cb-92597e00143e",
   "metadata": {},
   "source": [
    "# Triggering RUN function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120db37-8c8e-497d-a1e9-1c78fa30e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the benchmark program, accumulate metrics, and calculate circuit depths\n",
    "(num_qubits_of_ckt, creation_times, elapsed_times, quantum_times, circuit_depths,transpiled_depths,xi, tr_xi, fidelity_data, Hf_fidelity_data, numckts,  \n",
    "algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts, transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage) = run()\n",
    "\n",
    "# Define the range of qubits for the x-axis\n",
    "num_qubits_range = range(min_qbits, max_qbits+1,skp_qubits)\n",
    "print(\"num_qubits_range =\",num_qubits_range)\n",
    "\n",
    "#Information of Execution Hardware\n",
    "Processor,cores = get_cpu_info()\n",
    "print(f\"****** Completed Execution on processor {Processor} with {cores} cores ******\")\n",
    "# Calculate average creation time, elapsed time, quantum processing time, and circuit depth for each number of qubits\n",
    "avg_creation_times = []\n",
    "std_creation_times= []\n",
    "avg_elapsed_times = []\n",
    "std_elapsed_times= []\n",
    "avg_quantum_times = []\n",
    "std_quantum_times= []\n",
    "avg_circuit_depths = []\n",
    "avg_transpiled_depths = []\n",
    "avg_1Q_algorithmic_gate_counts = []\n",
    "avg_2Q_algorithmic_gate_counts = []\n",
    "avg_1Q_Transpiled_gate_counts = []\n",
    "avg_2Q_Transpiled_gate_counts = []\n",
    "avg_xi=[]\n",
    "avg_tr_xi=[]\n",
    "max_memory = []\n",
    "Qubits = []\n",
    "\n",
    "start = 0\n",
    "for num in numckts:\n",
    "    avg_creation_times.append(round(np.mean(creation_times[start:start+num]),3))\n",
    "    std_creation_times.append(round(np.std(creation_times[start:start+num])/np.sqrt(len(creation_times)), 3))\n",
    "    avg_elapsed_times.append(round(np.mean(elapsed_times[start:start+num]),3))\n",
    "    std_elapsed_times.append(round(np.std(elapsed_times[start:start+num])/np.sqrt(len(elapsed_times)), 3))\n",
    "    avg_quantum_times.append(round(np.mean(quantum_times[start:start+num]),3))\n",
    "    std_quantum_times.append(round(np.std(quantum_times[start:start+num])/np.sqrt(len(quantum_times)), 3))\n",
    "    avg_circuit_depths.append(round(np.mean(circuit_depths[start:start+num]),3))\n",
    "    avg_transpiled_depths.append(round(np.mean(transpiled_depths[start:start+num]),3))\n",
    "    if gate_counts_plots == True:\n",
    "        avg_1Q_algorithmic_gate_counts.append(round(np.mean(algorithmic_1Q_gate_counts[start:start+num]),2))\n",
    "        avg_2Q_algorithmic_gate_counts.append(round(np.mean(algorithmic_2Q_gate_counts[start:start+num]),2))\n",
    "        avg_xi.append(round(np.mean(xi[start:start+num]),2))\n",
    "        avg_1Q_Transpiled_gate_counts.append(round(np.mean(transpiled_1Q_gate_counts[start:start+num]),2))\n",
    "        avg_2Q_Transpiled_gate_counts.append(round(np.mean(transpiled_2Q_gate_counts[start:start+num]),2))\n",
    "        avg_tr_xi.append(round(np.mean(tr_xi[start:start+num]),2))\n",
    "    if Memory_utilization_plot == True:max_memory.append(round(np.max(mem_usage[start:start+num]),2))\n",
    "    Qubits.append(int(np.mean(num_qubits_of_ckt[start:start+num])))\n",
    "    start += num\n",
    "\n",
    "\n",
    "# Calculate the fidelity data\n",
    "avg_f, avg_Hf, std_f, std_hf = plot_fidelity_data(fidelity_data, Hf_fidelity_data, \"Fidelity Comparison\")\n",
    "\n",
    "if Store_Data:\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    # Prepare the data dictionary\n",
    "    data = {\n",
    "        \"configuration\":{\n",
    "        \"min_qbits\":min_qbits,\n",
    "        \"max_qbits\":max_qbits,\n",
    "        \"skp_qubits\":skp_qubits,\n",
    "        \"num_ckts\":numckts,\n",
    "        \"Type_of_Simulator\":platform,\n",
    "        \"benchmark_name\":benchmark_name,\n",
    "        \"QV_\":QV_,\n",
    "        \"Processor\":Processor,\n",
    "        \"cores\":cores},\n",
    "        'Number of Qubits': Qubits,\n",
    "        \"avg_creation_times (ms)\": avg_creation_times,\n",
    "        \"std_creation_times (ms)\": std_creation_times,\n",
    "        \"avg_elapsed_times (ms)\": avg_elapsed_times,\n",
    "        \"std_elapsed_times (ms)\":std_elapsed_times,\n",
    "        \"avg_quantum_times (ms)\": avg_quantum_times,\n",
    "        \"std_quantum_times (ms)\":std_quantum_times,\n",
    "        \"avg_circuit_depths\": avg_circuit_depths,\n",
    "        \"avg_transpiled_depths\": avg_transpiled_depths,\n",
    "        \"Average_Rescaled_fidelity\":avg_f,\n",
    "        \"Average_Hellinger_fidelity\":avg_Hf,\n",
    "        \"std_Rescaled_Fidelity\":std_f,\n",
    "        \"std_hellinger_fidelity\":std_hf\n",
    "    }\n",
    "\n",
    "    if gate_counts_plots:\n",
    "        data[\"gate_counts_plots\"] =  gate_counts_plots\n",
    "        data[\"avg_1Q_algorithmic_gate_counts\"] =  avg_1Q_algorithmic_gate_counts\n",
    "        data[\"avg_2Q_algorithmic_gate_counts\"] =  avg_2Q_algorithmic_gate_counts\n",
    "        data[\"avg_xi (n2q/n1q+n2q)\"]=avg_xi\n",
    "        data[\"avg_1Q_Transpiled_gate_counts\"]= avg_1Q_Transpiled_gate_counts\n",
    "        data[\"avg_2Q_Transpiled_gate_counts\"]= avg_2Q_Transpiled_gate_counts\n",
    "        data[\"avg_tr_xi (tr_n2q/tr_n1q+tr_n2q)\"]=avg_tr_xi\n",
    "\n",
    "    if Memory_utilization_plot:\n",
    "        data[\"max_memory (MB)\"]= max_memory\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Add the timestamp to the data\n",
    "    data['last_updated'] = current_time\n",
    "    \n",
    "    # Define the file name\n",
    "    file_name = '__data.json'\n",
    "    \n",
    "    # Write the data to the file\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    \n",
    "    print(f\"***** Data has been saved to {file_name} ******\")\n",
    "\n",
    "    if save_to_excel: \n",
    "        #from Data_Plotter import update_excel_with_data\n",
    "        update_excel_with_data(f\"{benchmark_name} Benchmark-Results.xlsx\",data,Noise_Inclusion)\n",
    "        print(\"***** Data has been updated to Benchmark-Results.xlsx *****\")\n",
    "\n",
    "\n",
    "# Plot histograms for average creation time, average elapsed time, average quantum processing time, and average circuit depth versus the number of qubits\n",
    "\n",
    "# Add labels to the bars\n",
    "def autolabel(rects,ax,str='{:.3f}',text_color=\"black\"):\n",
    "        max_y_value=ax.get_ylim()[1]  # Get the maximum value on the y-axis\n",
    "        threshold=0.3*max_y_value   # Define threshold as 30% of max y-axis value\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            if height < threshold:\n",
    "                rotation = 90\n",
    "                va = 'bottom'  # Place text above the bar\n",
    "                xytext = (0, 3)  # Offset slightly above the bar\n",
    "            else:\n",
    "                rotation = 90\n",
    "                va = 'center'  # Place text inside the bar\n",
    "                xytext = (0, 0)  # No offset\n",
    "            ax.annotate(str.format(height),  # Formatting to two decimal places\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height/6),\n",
    "                        xytext=xytext,\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va=va, color=text_color, rotation=rotation)\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "# Determine the number of subplots and their arrangement\n",
    "if Memory_utilization_plot and gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7) = plt.subplots(7, 1, figsize=(18, 30))\n",
    "    # Plotting for both memory utilization and gate counts\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6, ax7 are available\n",
    "elif Memory_utilization_plot:\n",
    "    fig, (ax1, ax2, ax3, ax6, ax7) = plt.subplots(5, 1, figsize=(18, 30))\n",
    "    # Plotting for memory utilization only\n",
    "    # ax1, ax2, ax3, ax6, ax7 are available\n",
    "elif gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(18, 30))\n",
    "    # Plotting for gate counts only\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6 are available\n",
    "else:\n",
    "    fig, (ax1, ax2, ax3, ax6) = plt.subplots(4, 1, figsize=(18, 30))\n",
    "    # Default plotting\n",
    "    # ax1, ax2, ax3, ax6 are available\n",
    "\n",
    "fig.suptitle(f\"General Benchmarks : {platform} - {benchmark_name} - {Processor}\", fontsize=16)\n",
    "\n",
    "\n",
    "ax1.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "x = ax1.bar(num_qubits_range, avg_creation_times, yerr=std_creation_times, capsize=15, color='deepskyblue')\n",
    "autolabel(ax1.patches, ax1)\n",
    "ax1.set_xlabel('Number of Qubits')\n",
    "ax1.set_ylabel('Average Creation Time (ms)')\n",
    "ax1.set_title('Average Creation Time vs Number of Qubits',fontsize=14)\n",
    "\n",
    "\n",
    "ax2.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "\n",
    "\n",
    "Elapsed= ax2.bar(np.array(num_qubits_range) - bar_width / 2, avg_elapsed_times,yerr=std_elapsed_times, capsize=15, width=bar_width, color='cyan', label='Elapsed Time')\n",
    "Quantum= ax2.bar(np.array(num_qubits_range) + bar_width / 2, avg_quantum_times,yerr=std_quantum_times, capsize=15,width=bar_width, color='deepskyblue',label ='Quantum Time')\n",
    "autolabel(Elapsed,ax2,str='{:.1f}')\n",
    "autolabel(Quantum,ax2,str='{:.1f}')\n",
    "ax2.set_xlabel('Number of Qubits')\n",
    "ax2.set_ylabel('Average Time (ms)')\n",
    "ax2.set_title('Average Time vs Number of Qubits')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Normalized = ax3.bar(np.array(num_qubits_range) - bar_width / 2, avg_transpiled_depths, color='cyan', label='Normalized Depth', width=bar_width)  # Adjust width here\n",
    "Algorithmic = ax3.bar(np.array(num_qubits_range) + bar_width / 2,avg_circuit_depths, color='deepskyblue', label='Algorithmic Depth', width=bar_width)  # Adjust width here\n",
    "autolabel(Normalized,ax3,str='{:.2f}')\n",
    "autolabel(Algorithmic,ax3,str='{:.2f}')\n",
    "ax3.set_xlabel('Number of Qubits')\n",
    "ax3.set_ylabel('Average Circuit Depth')\n",
    "ax3.set_title('Average Circuit Depth vs Number of Qubits')\n",
    "ax3.legend()\n",
    "\n",
    "if gate_counts_plots == True:\n",
    "    ax4.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_1Q_counts = ax4.bar(np.array(num_qubits_range) - bar_width / 2, avg_1Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_1Q_counts = ax4.bar(np.array(num_qubits_range) + bar_width / 2, avg_1Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_1Q_counts,ax4,str='{}')\n",
    "    autolabel(Algorithmic_1Q_counts,ax4,str='{}')\n",
    "    ax4.set_xlabel('Number of Qubits')\n",
    "    ax4.set_ylabel('Average 1-Qubit Gate Counts')\n",
    "    ax4.set_title('Average 1-Qubit Gate Counts vs Number of Qubits')\n",
    "    ax4.legend()\n",
    "    \n",
    "    ax5.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_2Q_counts = ax5.bar(np.array(num_qubits_range) - bar_width / 2, avg_2Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_2Q_counts = ax5.bar(np.array(num_qubits_range) + bar_width / 2, avg_2Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_2Q_counts,ax5,str='{}')\n",
    "    autolabel(Algorithmic_2Q_counts,ax5,str='{}')\n",
    "    ax5.set_xlabel('Number of Qubits')\n",
    "    ax5.set_ylabel('Average 2-Qubit Gate Counts')\n",
    "    ax5.set_title('Average 2-Qubit Gate Counts vs Number of Qubits')\n",
    "    ax5.legend()\n",
    "\n",
    "\n",
    "ax6.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Hellinger = ax6.bar(np.array(num_qubits_range) - bar_width / 2, avg_Hf,yerr=std_hf, capsize=15, width=bar_width, label='Hellinger Fidelity',color='cyan')  # Adjust width here\n",
    "Normalized = ax6.bar(np.array(num_qubits_range) + bar_width / 2, avg_f,yerr=std_f, capsize=15, width=bar_width, label='Normalized Fidelity', color='deepskyblue')  # Adjust width here\n",
    "autolabel(Hellinger,ax6,str='{:.2f}')\n",
    "autolabel(Normalized,ax6,str='{:.2f}')\n",
    "ax6.set_xlabel('Number of Qubits')\n",
    "ax6.set_ylabel('Average Value')\n",
    "ax6.set_title(\"Fidelity Comparison\")\n",
    "ax6.legend()\n",
    "\n",
    "if Memory_utilization_plot == True:\n",
    "    ax7.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    x = ax7.bar(num_qubits_range, max_memory, color='turquoise', width=bar_width, label=\"Memory Utilizations\")\n",
    "    autolabel(ax7.patches, ax7)\n",
    "    ax7.set_xlabel('Number of Qubits')\n",
    "    ax7.set_ylabel('Maximum Memory Utilized (MB)')\n",
    "    ax7.set_title('Memory Utilized vs Number of Qubits',fontsize=14)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "if saveplots == True:\n",
    "    plt.savefig(\"ParameterPlotsSample.jpg\")\n",
    "plt.show()\n",
    "\n",
    "num_qubits_range = Qubits\n",
    "\n",
    "# Quantum Volume Plot\n",
    "Suptitle = f\"Volumetric Positioning - {platform}\"\n",
    "appname=benchmark_name\n",
    "if QV_ == None:\n",
    "    QV=2048\n",
    "else:\n",
    "    QV=QV_\n",
    "depth_base =2\n",
    "\n",
    "ax = plot_volumetric_background(max_qubits=max_qbits, QV=QV,depth_base=depth_base, suptitle=Suptitle, colorbar_label=\"Avg Result Fidelity\")\n",
    "\n",
    "w_data = num_qubits_range\n",
    "# determine width for circuit\n",
    "w_max = 0\n",
    "for i in range(len(w_data)):\n",
    "    y = float(w_data[i])\n",
    "    w_max = max(w_max, y)\n",
    "\n",
    "d_tr_data = avg_transpiled_depths\n",
    "f_data = avg_f\n",
    "\n",
    "plot_volumetric_data(ax, w_data, d_tr_data, f_data, depth_base, fill=True,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, w_max=w_max)\n",
    "anno_volumetric_data(ax, depth_base,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, fill=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
