{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb892a-1753-4ca4-b867-d2b7f19dcc10",
   "metadata": {},
   "source": [
    "# Custom Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc63908-52eb-41c3-9f1a-545fce488cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign these values as per your requirements.\n",
    "global min_qubits,max_qubits,skip_qubits,max_circuits,num_shots,Noise_Inclusion\n",
    "\n",
    "min_qubits=3\n",
    "max_qubits=8\n",
    "skip_qubits=1\n",
    "num_shots=1000\n",
    "Noise_Inclusion = False\n",
    "saveplots = False\n",
    "\n",
    "Memory_utilization_plot = True\n",
    "gate_counts_plots = True\n",
    "Store_Data = True\n",
    "save_to_excel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060362a1-64fa-4ad6-ad17-ec0b825634ee",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1169dd7-e2b7-4a40-ba84-3c3cd2d7edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "from qiskit import QuantumCircuit, BasicAer\n",
    "from qiskit import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "benchmark_name = \"Deutsch-Jozsa\"\n",
    "\n",
    "\n",
    "# Selection of basis gate set for transpilation\n",
    "# Note: selector 1 is a hardware agnostic gate set\n",
    "basis_selector = 1\n",
    "basis_gates_array = [\n",
    "    [],\n",
    "    ['rx', 'ry', 'rz', 'cx'],       # a common basis set, default\n",
    "    ['cx', 'rz', 'sx', 'x'],        # IBM default basis set\n",
    "    ['rx', 'ry', 'rxx'],            # IonQ default basis set\n",
    "    ['h', 'p', 'cx'],               # another common basis set\n",
    "    ['u', 'cx']                     # general unitaries basis gates\n",
    "]\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3b451-e323-4482-8ef3-626632e87b56",
   "metadata": {},
   "source": [
    "# Declaring Backend :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126acf4-047e-47b8-94c9-2fc843377369",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = BasicAer.get_backend('dm_simulator') #Using dm_simulator as backend for our execution\n",
    "QV_ = None\n",
    "platform = backend.name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ee7c3-6b88-45bd-8fff-bcb0a44e9d0f",
   "metadata": {},
   "source": [
    "# Algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f9c63-954a-43fa-bb91-cef13a053c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved circuits for display\n",
    "QC_ = None\n",
    "C_ORACLE_ = None\n",
    "B_ORACLE_ = None\n",
    "\n",
    "def constant_oracle (input_size, num_qubits):\n",
    "    \n",
    "    #Initialize first n qubits and single ancilla qubit\n",
    "    qc = QuantumCircuit(num_qubits, name=f\"Uf\")\n",
    "\n",
    "    output = np.random.randint(2)\n",
    "    \n",
    "    if output == 1:\n",
    "        qc.x(input_size)\n",
    "\n",
    "    global C_ORACLE_\n",
    "    if C_ORACLE_ == None or num_qubits <= 6:\n",
    "        if num_qubits < 9: C_ORACLE_ = qc\n",
    "            \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5eb9c-be0a-4975-9f9d-0eecbd3f65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_oracle (input_size, num_qubits):\n",
    "    #Initialize first n qubits and single ancilla qubit\n",
    "    qc = QuantumCircuit(num_qubits, name=f\"Uf\")\n",
    "\n",
    "    b_str = \"101010101010101010101010101010101\"              # permit input_string up to 20 chars\n",
    "    for qubit in range(input_size):\n",
    "        if b_str[qubit] == '1':\n",
    "            qc.x(qubit)\n",
    "\n",
    "    qc.barrier()\n",
    "\n",
    "    for qubit in range(input_size):\n",
    "        qc.cx(qubit, input_size)\n",
    "\n",
    "    qc.barrier()\n",
    "\n",
    "    for qubit in range(input_size):\n",
    "        if b_str[qubit] == '1':\n",
    "            qc.x(qubit)\n",
    "\n",
    "    global B_ORACLE_\n",
    "    if B_ORACLE_ == None or num_qubits <= 6:\n",
    "        if num_qubits < 9: B_ORACLE_ = qc\n",
    "            \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5d14e-553b-4549-bb52-bab4860109a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeutschJozsa (num_qubits, type):\n",
    "    \n",
    "    # Size of input is one less than available qubits\n",
    "    input_size = num_qubits - 1\n",
    "\n",
    "    # allocate qubits\n",
    "    qr = QuantumRegister(num_qubits); cr = ClassicalRegister(input_size);\n",
    "    qc = QuantumCircuit(qr, cr, name=f\"dj-{num_qubits}-{type}\")\n",
    "\n",
    "    for qubit in range(input_size):\n",
    "        qc.h(qubit)\n",
    "    qc.x(input_size)\n",
    "    qc.h(input_size)\n",
    "    \n",
    "    qc.barrier()\n",
    "    \n",
    "    # Add a constant or balanced oracle function\n",
    "    if type == 0: Uf = constant_oracle(input_size, num_qubits)\n",
    "    else: Uf = balanced_oracle(input_size, num_qubits)\n",
    "    qc.append(Uf, qr)\n",
    "\n",
    "    qc.barrier()\n",
    "    \n",
    "    for qubit in range(num_qubits):\n",
    "        qc.h(qubit)\n",
    "    \n",
    "    # uncompute ancilla qubit, not necessary for algorithm\n",
    "    qc.x(input_size)\n",
    "    \n",
    "    qc.barrier()\n",
    "    \n",
    "    for i in range(input_size):\n",
    "        qc.measure(i, i)\n",
    "    \n",
    "    # save smaller circuit and oracle subcircuit example for display\n",
    "    global QC_\n",
    "    if QC_ == None or num_qubits <= 6:\n",
    "        if num_qubits < 9: QC_ = qc\n",
    "\n",
    "    # return a handle to the circuit\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbc5d3-98fa-46ef-80c3-06c4a7a97be0",
   "metadata": {},
   "source": [
    "# Noise Parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2c64e-c22c-4773-8a47-41964407fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise parameters\n",
    "options = { } #if Noise is None\n",
    "\n",
    "options_noisy = { #if Noise is not None\n",
    "    'plot': False,\n",
    "    \"thermal_factor\": 0.9,\n",
    "    'show_partition': False,\n",
    "    \"decoherence_factor\": 0.9,\n",
    "    \"depolarization_factor\": 0.9,\n",
    "    \"bell_depolarization_factor\": 1,\n",
    "    \"decay_factor\": 0.75,\n",
    "    \"rotation_error\": {'rx':[1.0, 0.0], 'ry':[1.0, 0.0], 'rz':[1.0, 0.0]},\n",
    "    \"tsp_model_error\": [1.0, 0.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8506b56-e48a-448a-9a80-63fa86ba1029",
   "metadata": {},
   "source": [
    "# Fidelity Calculations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267a29f-ebca-4ceb-9c1b-7dab35fe013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniform distribution function commonly used\n",
    "def rescale_fidelity(fidelity, floor_fidelity, new_floor_fidelity):\n",
    "    \"\"\"\n",
    "    Linearly rescales our fidelities to allow comparisons of fidelities across benchmarks\n",
    "    \n",
    "    fidelity: raw fidelity to rescale\n",
    "    floor_fidelity: threshold fidelity which is equivalent to random guessing\n",
    "    new_floor_fidelity: what we rescale the floor_fidelity to \n",
    "\n",
    "    Ex, with floor_fidelity = 0.25, new_floor_fidelity = 0.0:\n",
    "        1 -> 1;\n",
    "        0.25 -> 0;\n",
    "        0.5 -> 0.3333;\n",
    "    \"\"\"\n",
    "    rescaled_fidelity = (1-new_floor_fidelity)/(1-floor_fidelity) * (fidelity - 1) + 1\n",
    "    \n",
    "    # ensure fidelity is within bounds (0, 1)\n",
    "    if rescaled_fidelity < 0:\n",
    "        rescaled_fidelity = 0.0\n",
    "    if rescaled_fidelity > 1:\n",
    "        rescaled_fidelity = 1.0\n",
    "    \n",
    "    return rescaled_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9266f5c-9c2f-4313-a012-a8be66e58bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_dist(num_state_qubits):\n",
    "    dist = {}\n",
    "    for i in range(2**num_state_qubits):\n",
    "        key = bin(i)[2:].zfill(num_state_qubits)\n",
    "        dist[key] = 1/(2**num_state_qubits)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fad0c7-6b52-416d-9bae-252b693df350",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis methods to be expanded and eventually compiled into a separate analysis.py file\n",
    "import math, functools\n",
    "\n",
    "def hellinger_fidelity_with_expected(p, q):\n",
    "    \"\"\" p: result distribution, may be passed as a counts distribution\n",
    "        q: the expected distribution to be compared against\n",
    "\n",
    "    References:\n",
    "        `Hellinger Distance @ wikipedia <https://en.wikipedia.org/wiki/Hellinger_distance>`_\n",
    "        Qiskit Hellinger Fidelity Function\n",
    "    \"\"\"\n",
    "    p_sum = sum(p.values())\n",
    "    q_sum = sum(q.values())\n",
    "\n",
    "    if q_sum == 0:\n",
    "        print(\"ERROR: polarization_fidelity(), expected distribution is invalid, all counts equal to 0\")\n",
    "        return 0\n",
    "\n",
    "    p_normed = {}\n",
    "    for key, val in p.items():\n",
    "        p_normed[key] = val/p_sum\n",
    "        # if p_sum != 0:\n",
    "        #     p_normed[key] = val/p_sum\n",
    "        # else:\n",
    "        #     p_normed[key] = 0\n",
    "\n",
    "    q_normed = {}\n",
    "    for key, val in q.items():\n",
    "        q_normed[key] = val/q_sum\n",
    "\n",
    "    total = 0\n",
    "    for key, val in p_normed.items():\n",
    "        if key in q_normed.keys():\n",
    "            total += (np.sqrt(val) - np.sqrt(q_normed[key]))**2\n",
    "            del q_normed[key]\n",
    "        else:\n",
    "            total += val\n",
    "    total += sum(q_normed.values())\n",
    "    \n",
    "    # in some situations (error mitigation) this can go negative, use abs value\n",
    "    if total < 0:\n",
    "        print(f\"WARNING: using absolute value in fidelity calculation\")\n",
    "        total = abs(total)\n",
    "        \n",
    "    dist = np.sqrt(total)/np.sqrt(2)\n",
    "    fidelity = (1-dist**2)**2\n",
    "\n",
    "    return fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84c6f2-6d6b-44d6-9998-17df560ae18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarization_fidelity(counts, correct_dist, thermal_dist=None):\n",
    "    \"\"\"\n",
    "    Combines Hellinger fidelity and polarization rescaling into fidelity calculation\n",
    "    used in every benchmark\n",
    "\n",
    "    counts: the measurement outcomes after `num_shots` algorithm runs\n",
    "    correct_dist: the distribution we expect to get for the algorithm running perfectly\n",
    "    thermal_dist: optional distribution to pass in distribution from a uniform\n",
    "                  superposition over all states. If `None`: generated as \n",
    "                  `uniform_dist` with the same qubits as in `counts`\n",
    "                  \n",
    "    returns both polarization fidelity and the hellinger fidelity\n",
    "\n",
    "    Polarization from: `https://arxiv.org/abs/2008.11294v1`\n",
    "    \"\"\"\n",
    "    num_measured_qubits = len(list(correct_dist.keys())[0])\n",
    "    #print(num_measured_qubits)\n",
    "    \n",
    "    counts = {k.zfill(num_measured_qubits): v for k, v in counts.items()}\n",
    "    \n",
    "    # calculate hellinger fidelity between measured expectation values and correct distribution\n",
    "    hf_fidelity = hellinger_fidelity_with_expected(counts,correct_dist)\n",
    "    \n",
    "    # to limit cpu and memory utilization, skip noise correction if more than 16 measured qubits\n",
    "    if num_measured_qubits > 16:\n",
    "        return { 'fidelity':hf_fidelity, 'hf_fidelity':hf_fidelity }\n",
    "\n",
    "    # if not provided, generate thermal dist based on number of qubits\n",
    "    if thermal_dist == None:\n",
    "        thermal_dist = uniform_dist(num_measured_qubits)\n",
    "\n",
    "    # set our fidelity rescaling value as the hellinger fidelity for a depolarized state\n",
    "    floor_fidelity = hellinger_fidelity_with_expected(thermal_dist, correct_dist)\n",
    "\n",
    "    # rescale fidelity result so uniform superposition (random guessing) returns fidelity\n",
    "    # rescaled to 0 to provide a better measure of success of the algorithm (polarization)\n",
    "    new_floor_fidelity = 0\n",
    "    fidelity = rescale_fidelity(hf_fidelity, floor_fidelity, new_floor_fidelity)\n",
    "\n",
    "    return { 'fidelity':fidelity, 'hf_fidelity':hf_fidelity }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7d14a-92ee-46f4-bff2-0ce6de620c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions of Volumetric Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f39ea1-f924-4b81-9ad0-5d8b785912a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "############### Color Map functions\n",
    " \n",
    "# Create a selection of colormaps from which to choose; default to custom_spectral\n",
    "cmap_spectral = plt.get_cmap('Spectral')\n",
    "cmap_greys = plt.get_cmap('Greys')\n",
    "cmap_blues = plt.get_cmap('Blues')\n",
    "cmap_custom_spectral = None\n",
    "\n",
    "# the default colormap is the spectral map\n",
    "cmap = cmap_spectral\n",
    "cmap_orig = cmap_spectral\n",
    "\n",
    "# current cmap normalization function (default None)\n",
    "cmap_norm = None\n",
    "\n",
    "default_fade_low_fidelity_level = 0.16\n",
    "default_fade_rate = 0.7\n",
    "\n",
    "\n",
    "# Specify a normalization function here (default None)\n",
    "def set_custom_cmap_norm(vmin, vmax):\n",
    "\n",
    "    global cmap_norm\n",
    "    \n",
    "    if vmin == vmax or (vmin == 0.0 and vmax == 1.0):\n",
    "        print(\"... setting cmap norm to None\")\n",
    "        cmap_norm = None\n",
    "    else:\n",
    "        print(f\"... setting cmap norm to [{vmin}, {vmax}]\")\n",
    "        cmap_norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "# Remake the custom spectral colormap with user settings\n",
    "def set_custom_cmap_style(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "            \n",
    "    #print(\"... set custom map style\")\n",
    "    global cmap, cmap_custom_spectral, cmap_orig\n",
    "    cmap_custom_spectral = create_custom_spectral_cmap(\n",
    "                fade_low_fidelity_level=fade_low_fidelity_level, fade_rate=fade_rate)\n",
    "    cmap = cmap_custom_spectral\n",
    "    cmap_orig = cmap_custom_spectral\n",
    "\n",
    "\n",
    "# Create the custom spectral colormap from the base spectral\n",
    "def create_custom_spectral_cmap(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "\n",
    "    # determine the breakpoint from the fade level\n",
    "    num_colors = 100\n",
    "    breakpoint = round(fade_low_fidelity_level * num_colors)\n",
    "    \n",
    "    # get color list for spectral map\n",
    "    spectral_colors = [cmap_spectral(v/num_colors) for v in range(num_colors)]\n",
    "\n",
    "    #print(fade_rate)\n",
    "    \n",
    "    # create a list of colors to replace those below the breakpoint\n",
    "    # and fill with \"faded\" color entries (in reverse)\n",
    "    low_colors = [0] * breakpoint\n",
    "    #for i in reversed(range(breakpoint)):\n",
    "    for i in range(breakpoint):\n",
    "    \n",
    "        # x is index of low colors, normalized 0 -> 1\n",
    "        x = i / breakpoint\n",
    "    \n",
    "        # get color at this index\n",
    "        bc = spectral_colors[i]\n",
    "        r0 = bc[0]\n",
    "        g0 = bc[1]\n",
    "        b0 = bc[2]\n",
    "        z0 = bc[3]\n",
    "        \n",
    "        r_delta = 0.92 - r0\n",
    "        \n",
    "        #print(f\"{x} {bc} {r_delta}\")\n",
    "         \n",
    "        # compute saturation and greyness ratio\n",
    "        sat_ratio = 1 - x\n",
    "        \n",
    "        #grey_ratio = 1 - x\n",
    "        '''  attempt at a reflective gradient   \n",
    "        if i >= breakpoint/2:\n",
    "            xf = 2*(x - 0.5)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (yf + 0.5)\n",
    "        else:\n",
    "            xf = 2*(0.5 - x)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (0.5 - yf)\n",
    "        '''   \n",
    "        grey_ratio = 1 - math.pow(x, 1/fade_rate)\n",
    "        \n",
    "        #print(f\"  {xf} {yf} \")\n",
    "        #print(f\"  {sat_ratio} {grey_ratio}\")\n",
    "\n",
    "        r = r0 + r_delta * sat_ratio\n",
    "        \n",
    "        g_delta = r - g0\n",
    "        b_delta = r - b0\n",
    "        g = g0 + g_delta * grey_ratio\n",
    "        b = b0 + b_delta * grey_ratio \n",
    "            \n",
    "        #print(f\"{r} {g} {b}\\n\")    \n",
    "        low_colors[i] = (r,g,b,z0)\n",
    "        \n",
    "    #print(low_colors)\n",
    "\n",
    "    # combine the faded low colors with the regular spectral cmap to make a custom version\n",
    "    cmap_custom_spectral = ListedColormap(low_colors + spectral_colors[breakpoint:])\n",
    "\n",
    "    #spectral_colors = [cmap_custom_spectral(v/10) for v in range(10)]\n",
    "    #for i in range(10): print(spectral_colors[i])\n",
    "    #print(\"\")\n",
    "    \n",
    "    return cmap_custom_spectral\n",
    "\n",
    "# Make the custom spectral color map the default on module init\n",
    "set_custom_cmap_style()\n",
    "\n",
    "# Arrange the stored annotations optimally and add to plot \n",
    "def anno_volumetric_data(ax, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True):\n",
    "    \n",
    "    # sort all arrays by the x point of the text (anno_offs)\n",
    "    global x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos\n",
    "    all_annos = sorted(zip(x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos))\n",
    "    x_anno_offs = [a for a,b,c,d,e in all_annos]\n",
    "    y_anno_offs = [b for a,b,c,d,e in all_annos]\n",
    "    anno_labels = [c for a,b,c,d,e in all_annos]\n",
    "    x_annos = [d for a,b,c,d,e in all_annos]\n",
    "    y_annos = [e for a,b,c,d,e in all_annos]\n",
    "    \n",
    "    #print(f\"{x_anno_offs}\")\n",
    "    #print(f\"{y_anno_offs}\")\n",
    "    #print(f\"{anno_labels}\")\n",
    "    \n",
    "    for i in range(len(anno_labels)):\n",
    "        x_anno = x_annos[i]\n",
    "        y_anno = y_annos[i]\n",
    "        x_anno_off = x_anno_offs[i]\n",
    "        y_anno_off = y_anno_offs[i]\n",
    "        label = anno_labels[i]\n",
    "        \n",
    "        if i > 0:\n",
    "            x_delta = abs(x_anno_off - x_anno_offs[i - 1])\n",
    "            y_delta = abs(y_anno_off - y_anno_offs[i - 1])\n",
    "            \n",
    "            if y_delta < 0.7 and x_delta < 2:\n",
    "                y_anno_off = y_anno_offs[i] = y_anno_offs[i - 1] - 0.6\n",
    "                #x_anno_off = x_anno_offs[i] = x_anno_offs[i - 1] + 0.1\n",
    "                    \n",
    "        ax.annotate(label,\n",
    "            xy=(x_anno+0.0, y_anno+0.1),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.0,\n",
    "                width=0.5, headwidth=4, headlength=5, edgecolor=(0.8,0.8,0.8)),\n",
    "            xytext=(x_anno_off + labelpos[0], y_anno_off + labelpos[1]),\n",
    "            rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='baseline',\n",
    "            color=(0.2,0.2,0.2),\n",
    "            clip_on=True)\n",
    "    if saveplots == True:\n",
    "        plt.savefig(\"VolumetricPlotSample.jpg\")\n",
    "\n",
    "# Plot one group of data for volumetric presentation    \n",
    "def plot_volumetric_data(ax, w_data, d_data, f_data, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True, w_max=18, do_label=False, do_border=True,\n",
    "        x_size=1.0, y_size=1.0, zorder=1, offset_flag=False,\n",
    "        max_depth=0, suppress_low_fidelity=False):\n",
    "\n",
    "    # since data may come back out of order, save point at max y for annotation\n",
    "    i_anno = 0\n",
    "    x_anno = 0 \n",
    "    y_anno = 0\n",
    "    \n",
    "    # plot data rectangles\n",
    "    low_fidelity_count = True\n",
    "    \n",
    "    last_y = -1\n",
    "    k = 0\n",
    "\n",
    "    # determine y-axis dimension for one pixel to use for offset of bars that start at 0\n",
    "    (_, dy) = get_pixel_dims(ax)\n",
    "    \n",
    "    # do this loop in reverse to handle the case where earlier cells are overlapped by later cells\n",
    "    for i in reversed(range(len(d_data))):\n",
    "        x = depth_index(d_data[i], depth_base)\n",
    "        y = float(w_data[i])\n",
    "        f = f_data[i]\n",
    "        \n",
    "        # each time we star a new row, reset the offset counter\n",
    "        # DEVNOTE: this is highly specialized for the QA area plots, where there are 8 bars\n",
    "        # that represent time starting from 0 secs.  We offset by one pixel each and center the group\n",
    "        if y != last_y:\n",
    "            last_y = y;\n",
    "            k = 3              # hardcoded for 8 cells, offset by 3\n",
    "        \n",
    "        #print(f\"{i = } {x = } {y = }\")\n",
    "        \n",
    "        if max_depth > 0 and d_data[i] > max_depth:\n",
    "            #print(f\"... excessive depth (2), skipped; w={y} d={d_data[i]}\")\n",
    "            break;\n",
    "            \n",
    "        # reject cells with low fidelity\n",
    "        if suppress_low_fidelity and f < suppress_low_fidelity_level:\n",
    "            if low_fidelity_count: break\n",
    "            else: low_fidelity_count = True\n",
    "        \n",
    "        # the only time this is False is when doing merged gradation plots\n",
    "        if do_border == True:\n",
    "        \n",
    "            # this case is for an array of x_sizes, i.e. each box has different width\n",
    "            if isinstance(x_size, list):\n",
    "                \n",
    "                # draw each of the cells, with no offset\n",
    "                if not offset_flag:\n",
    "                    ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size[i], y_size=y_size, zorder=zorder))\n",
    "                    \n",
    "                # use an offset for y value, AND account for x and width to draw starting at 0\n",
    "                else:\n",
    "                    ax.add_patch(box_at((x/2 + x_size[i]/4), y + k*dy, f, type=type, fill=fill, x_size=x+ x_size[i]/2, y_size=y_size, zorder=zorder))\n",
    "                \n",
    "            # this case is for only a single cell\n",
    "            else:\n",
    "                ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size, y_size=y_size))\n",
    "\n",
    "        # save the annotation point with the largest y value\n",
    "        if y >= y_anno:\n",
    "            x_anno = x\n",
    "            y_anno = y\n",
    "            i_anno = i\n",
    "        \n",
    "        # move the next bar down (if using offset)\n",
    "        k -= 1\n",
    "    \n",
    "    # if no data rectangles plotted, no need for a label\n",
    "    if x_anno == 0 or y_anno == 0:\n",
    "        return\n",
    "        \n",
    "    x_annos.append(x_anno)\n",
    "    y_annos.append(y_anno)\n",
    "    \n",
    "    anno_dist = math.sqrt( (y_anno - 1)**2 + (x_anno - 1)**2 )\n",
    "    \n",
    "    # adjust radius of annotation circle based on maximum width of apps\n",
    "    anno_max = 10\n",
    "    if w_max > 10:\n",
    "        anno_max = 14\n",
    "    if w_max > 14:\n",
    "        anno_max = 18\n",
    "        \n",
    "    scale = anno_max / anno_dist\n",
    "\n",
    "    # offset of text from end of arrow\n",
    "    if scale > 1:\n",
    "        x_anno_off = scale * x_anno - x_anno - 0.5\n",
    "        y_anno_off = scale * y_anno - y_anno\n",
    "    else:\n",
    "        x_anno_off = 0.7\n",
    "        y_anno_off = 0.5\n",
    "        \n",
    "    x_anno_off += x_anno\n",
    "    y_anno_off += y_anno\n",
    "    \n",
    "    # print(f\"... {xx} {yy} {anno_dist}\")\n",
    "    x_anno_offs.append(x_anno_off)\n",
    "    y_anno_offs.append(y_anno_off)\n",
    "    \n",
    "    anno_labels.append(label)\n",
    "    \n",
    "    if do_label:\n",
    "        ax.annotate(label, xy=(x_anno+labelpos[0], y_anno+labelpos[1]), rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='bottom', color=(0.2,0.2,0.2))\n",
    "\n",
    "x_annos = []\n",
    "y_annos = []\n",
    "x_anno_offs = []\n",
    "y_anno_offs = []\n",
    "anno_labels = []\n",
    "\n",
    "# init arrays to hold annotation points for label spreading\n",
    "def vplot_anno_init ():\n",
    "\n",
    "    global x_annos, y_annos, x_anno_offs, y_anno_offs, anno_labels\n",
    "    \n",
    "    x_annos = []\n",
    "    y_annos = []\n",
    "    x_anno_offs = []\n",
    "    y_anno_offs = []\n",
    "    anno_labels = []\n",
    "\n",
    "# Number of ticks on volumetric depth axis\n",
    "max_depth_log = 22\n",
    "\n",
    "# average transpile factor between base QV depth and our depth based on results from QV notebook\n",
    "QV_transpile_factor = 12.7 \n",
    "\n",
    "# format a number using K,M,B,T for large numbers, optionally rounding to 'digits' decimal places if num > 1\n",
    "# (sign handling may be incorrect)\n",
    "def format_number(num, digits=0):\n",
    "    if isinstance(num, str): num = float(num)\n",
    "    num = float('{:.3g}'.format(abs(num)))\n",
    "    sign = ''\n",
    "    metric = {'T': 1000000000000, 'B': 1000000000, 'M': 1000000, 'K': 1000, '': 1}\n",
    "    for index in metric:\n",
    "        num_check = num / metric[index]\n",
    "        if num_check >= 1:\n",
    "            num = round(num_check, digits)\n",
    "            sign = index\n",
    "            break\n",
    "    numstr = f\"{str(num)}\"\n",
    "    if '.' in numstr:\n",
    "        numstr = numstr.rstrip('0').rstrip('.')\n",
    "    return f\"{numstr}{sign}\"\n",
    "\n",
    "# Return the color associated with the spcific value, using color map norm\n",
    "def get_color(value):\n",
    "    \n",
    "    # if there is a normalize function installed, scale the data\n",
    "    if cmap_norm:\n",
    "        value = float(cmap_norm(value))\n",
    "        \n",
    "    if cmap == cmap_spectral:\n",
    "        value = 0.05 + value*0.9\n",
    "    elif cmap == cmap_blues:\n",
    "        value = 0.00 + value*1.0\n",
    "    else:\n",
    "        value = 0.0 + value*0.95\n",
    "        \n",
    "    return cmap(value)\n",
    "\n",
    "# Return the x and y equivalent to a single pixel for the given plot axis\n",
    "def get_pixel_dims(ax):\n",
    "\n",
    "    # transform 0 -> 1 to pixel dimensions\n",
    "    pixdims = ax.transData.transform([(0,1),(1,0)])-ax.transData.transform((0,0))\n",
    "    xpix = pixdims[1][0]\n",
    "    ypix = pixdims[0][1]\n",
    "    \n",
    "    #determine x- and y-axis dimension for one pixel \n",
    "    dx = (1 / xpix)\n",
    "    dy = (1 / ypix)\n",
    "    \n",
    "    return (dx, dy)\n",
    "\n",
    "############### Helper functions\n",
    " \n",
    "# return the base index for a circuit depth value\n",
    "# take the log in the depth base, and add 1\n",
    "def depth_index(d, depth_base):\n",
    "    if depth_base <= 1:\n",
    "        return d\n",
    "    if d == 0:\n",
    "        return 0\n",
    "    return math.log(d, depth_base) + 1\n",
    "\n",
    "# draw a box at x,y with various attributes   \n",
    "def box_at(x, y, value, type=1, fill=True, x_size=1.0, y_size=1.0, alpha=1.0, zorder=1):\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Rectangle((x - (x_size/2), y - (y_size/2)), x_size, y_size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5*y_size,\n",
    "             zorder=zorder)\n",
    "\n",
    "# draw a circle at x,y with various attributes \n",
    "def circle_at(x, y, value, type=1, fill=True):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Circle((x, y), size/2,\n",
    "             alpha = 0.7,                       # DEVNOTE: changed to 0.7 from 0.5, to handle only one cell\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5)\n",
    "             \n",
    "def box4_at(x, y, value, type=1, fill=True, alpha=1.0):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.3,0.3,0.3)\n",
    "    ec = fc\n",
    "    \n",
    "    return Rectangle((x - size/8, y - size/2), size/4, size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.1)\n",
    "\n",
    "# Draw a Quantum Volume rectangle with specified width and depth, and grey-scale value \n",
    "def qv_box_at(x, y, qv_width, qv_depth, value, depth_base):\n",
    "    #print(f\"{qv_width} {qv_depth} {depth_index(qv_depth, depth_base)}\")\n",
    "    return Rectangle((x - 0.5, y - 0.5), depth_index(qv_depth, depth_base), qv_width,\n",
    "             edgecolor = (value,value,value),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=1)\n",
    "\n",
    "def bkg_box_at(x, y, value=0.9):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "             \n",
    "def bkg_empty_box_at(x, y):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (1.0,1.0,1.0),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "\n",
    "# Plot the background for the volumetric analysis    \n",
    "def plot_volumetric_background(max_qubits=11, QV=32, depth_base=2, suptitle=None, avail_qubits=0, colorbar_label=\"Avg Result Fidelity\"):\n",
    "\n",
    "    if suptitle == None:\n",
    "        suptitle = f\"Volumetric Positioning\\nCircuit Dimensions and Fidelity Overlaid on Quantum Volume = {QV}\"\n",
    "\n",
    "    QV0 = QV\n",
    "    qv_estimate = False\n",
    "    est_str = \"\"\n",
    "    if QV == 0:                 # QV = 0 indicates \"do not draw QV background or label\"\n",
    "        QV = 2048\n",
    "        \n",
    "    elif QV < 0:                # QV < 0 indicates \"add est. to label\"\n",
    "        QV = -QV\n",
    "        qv_estimate = True\n",
    "        est_str = \" (est.)\"\n",
    "        \n",
    "    if avail_qubits > 0 and max_qubits > avail_qubits:\n",
    "        max_qubits = avail_qubits\n",
    "        \n",
    "    max_width = 13\n",
    "    if max_qubits > 11: max_width = 18\n",
    "    if max_qubits > 14: max_width = 20\n",
    "    if max_qubits > 16: max_width = 24\n",
    "    if max_qubits > 24: max_width = 33\n",
    "    #print(f\"... {avail_qubits} {max_qubits} {max_width}\")\n",
    "    \n",
    "    plot_width = 6.8\n",
    "    plot_height = 0.5 + plot_width * (max_width / max_depth_log)\n",
    "    #print(f\"... {plot_width} {plot_height}\")\n",
    "    \n",
    "    # define matplotlib figure and axis; use constrained layout to fit colorbar to right\n",
    "    fig, ax = plt.subplots(figsize=(plot_width, plot_height), constrained_layout=True)\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    plt.xlim(0, max_depth_log)\n",
    "    plt.ylim(0, max_width)\n",
    "\n",
    "    # circuit depth axis (x axis)\n",
    "    xbasis = [x for x in range(1,max_depth_log)]\n",
    "    xround = [depth_base**(x-1) for x in xbasis]\n",
    "    xlabels = [format_number(x) for x in xround]\n",
    "    ax.set_xlabel('Circuit Depth')\n",
    "    ax.set_xticks(xbasis)  \n",
    "    plt.xticks(xbasis, xlabels, color='black', rotation=45, ha='right', va='top', rotation_mode=\"anchor\")\n",
    "    \n",
    "    # other label options\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-60, ha='left')\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-45, ha='left', va='center', rotation_mode=\"anchor\")\n",
    "\n",
    "    # circuit width axis (y axis)\n",
    "    ybasis = [y for y in range(1,max_width)]\n",
    "    yround = [1,2,3,4,5,6,7,8,10,12,15]     # not used now\n",
    "    ylabels = [str(y) for y in yround]      # not used now \n",
    "    #ax.set_ylabel('Circuit Width (Number of Qubits)')\n",
    "    ax.set_ylabel('Circuit Width')\n",
    "    ax.set_yticks(ybasis)\n",
    "\n",
    "    #create simple line plot (not used right now)\n",
    "    #ax.plot([0, 10],[0, 10])\n",
    "    \n",
    "    log2QV = math.log2(QV)\n",
    "    QV_width = log2QV\n",
    "    QV_depth = log2QV * QV_transpile_factor\n",
    "    \n",
    "    # show a quantum volume rectangle of QV = 64 e.g. (6 x 6)\n",
    "    if QV0 != 0:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.87, depth_base))\n",
    "    else:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.91, depth_base))\n",
    "    \n",
    "    # the untranspiled version is commented out - we do not show this by default\n",
    "    # also show a quantum volume rectangle un-transpiled\n",
    "    # ax.add_patch(qv_box_at(1, 1, QV_width, QV_width, 0.80, depth_base))\n",
    "\n",
    "    # show 2D array of volumetric cells based on this QV_transpiled\n",
    "    # DEVNOTE: we use +1 only to make the visuals work; s/b without\n",
    "    # Also, the second arg of the min( below seems incorrect, needs correction\n",
    "    maxprod = (QV_width + 1) * (QV_depth + 1)\n",
    "    for w in range(1, min(max_width, round(QV) + 1)):\n",
    "        \n",
    "        # don't show VB squares if width greater than known available qubits\n",
    "        if avail_qubits != 0 and w > avail_qubits:\n",
    "            continue\n",
    "        \n",
    "        i_success = 0\n",
    "        for d in xround:\n",
    "        \n",
    "            # polarization factor for low circuit widths\n",
    "            maxtest = maxprod / ( 1 - 1 / (2**w) )\n",
    "            \n",
    "            # if circuit would fail here, don't draw box\n",
    "            if d > maxtest: continue\n",
    "            if w * d > maxtest: continue\n",
    "            \n",
    "            # guess for how to capture how hardware decays with width, not entirely correct\n",
    "\n",
    "            # # reduce maxtext by a factor of number of qubits > QV_width\n",
    "            # # just an approximation to account for qubit distances\n",
    "            # if w > QV_width:\n",
    "            #     over = w - QV_width \n",
    "            #     maxtest = maxtest / (1 + (over/QV_width))\n",
    "\n",
    "            # draw a box at this width and depth\n",
    "            id = depth_index(d, depth_base) \n",
    "            \n",
    "            # show vb rectangles; if not showing QV, make all hollow (or less dark)\n",
    "            if QV0 == 0:\n",
    "                #ax.add_patch(bkg_empty_box_at(id, w))\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.95))\n",
    "            \n",
    "            else:\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.9))\n",
    "            \n",
    "            # save index of last successful depth\n",
    "            i_success += 1\n",
    "        \n",
    "        # plot empty rectangle after others       \n",
    "        d = xround[i_success]\n",
    "        id = depth_index(d, depth_base) \n",
    "        ax.add_patch(bkg_empty_box_at(id, w))\n",
    "        \n",
    "    \n",
    "    # Add annotation showing quantum volume\n",
    "    if QV0 != 0:\n",
    "        t = ax.text(max_depth_log - 2.0, 1.5, f\"QV{est_str}={QV}\", size=12,\n",
    "                horizontalalignment='right', verticalalignment='center', color=(0.2,0.2,0.2),\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=(.9,.9,.9), ec=\"grey\", lw=1))\n",
    "                \n",
    "    # add colorbar to right of plot\n",
    "    plt.colorbar(cm.ScalarMappable(cmap=cmap), cax=None, ax=ax,\n",
    "            shrink=0.6, label=colorbar_label, panchor=(0.0, 0.7))\n",
    "            \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c7b52-ddf0-4331-bded-4cf824ccbe83",
   "metadata": {},
   "source": [
    "# Benchmarking Essentials and Fidelity Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ffdf2-b8d2-404a-aff2-0775e40c1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate circuit depth\n",
    "def calculate_circuit_depth(qc):\n",
    "    # Calculate the depth of the circuit\n",
    "    depth = qc.depth()\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2ae02-3b68-42aa-a168-d12f5e7ccf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transpiled_depth(qc,basis_selector):\n",
    "    # use either the backend or one of the basis gate sets\n",
    "    if basis_selector == 0:\n",
    "        qc = transpile(qc, backend) \n",
    "    else:\n",
    "        basis_gates = basis_gates_array[basis_selector]\n",
    "        qc = transpile(qc, basis_gates=basis_gates, seed_transpiler=0)\n",
    "    transpiled_depth = qc.depth()\n",
    "    return transpiled_depth,qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0490105-27e8-443d-9d83-6f6ef17b1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fidelity_data(fidelity_data, Hf_fidelity_data, title):\n",
    "    avg_fidelity_means = []\n",
    "    avg_Hf_fidelity_means = []\n",
    "    std_f = []\n",
    "    std_hf = []\n",
    "    avg_num_qubits_values = list(fidelity_data.keys())\n",
    "    \n",
    "    # Calculate the average fidelity and Hamming fidelity for each unique number of qubits\n",
    "    for num_qubits in avg_num_qubits_values:\n",
    "        avg_fidelity = round(np.average(fidelity_data[num_qubits]),2)\n",
    "        avg_fidelity_means.append(avg_fidelity)\n",
    "        std_fidelity = round(np.std(fidelity_data[num_qubits])/np.sqrt(len(fidelity_data)), 3)\n",
    "        std_f.append(std_fidelity)\n",
    "        avg_Hf_fidelity = round(np.mean(Hf_fidelity_data[num_qubits]),2)\n",
    "        avg_Hf_fidelity_means.append(avg_Hf_fidelity)\n",
    "        std_Hfidelity = round(np.std(Hf_fidelity_data[num_qubits])/np.sqrt(len(Hf_fidelity_data)), 3)\n",
    "        std_hf.append(std_Hfidelity)\n",
    "    \n",
    "    return avg_fidelity_means,avg_Hf_fidelity_means,std_f,std_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9b037-c56b-46f8-810f-7b83675b44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_gates = []\n",
    "def list_of_standardgates():\n",
    "    import qiskit.circuit.library as lib\n",
    "    from qiskit.circuit import Gate\n",
    "    import inspect\n",
    "    \n",
    "    # List all the attributes of the library module\n",
    "    gate_list = dir(lib)\n",
    "    \n",
    "    # Filter out non-gate classes (like functions, variables, etc.)\n",
    "    gates = [gate for gate in gate_list if isinstance(getattr(lib, gate), type) and issubclass(getattr(lib, gate), Gate)]\n",
    "\n",
    "    # Get method names from QuantumCircuit\n",
    "    circuit_methods = inspect.getmembers(QuantumCircuit, inspect.isfunction)\n",
    "    method_names = [name for name, _ in circuit_methods]\n",
    "    \n",
    "    # Map gate class names to method names\n",
    "    gate_to_method = {}\n",
    "    for gate in gates:\n",
    "        gate_class = getattr(lib, gate)\n",
    "        class_name = gate_class.__name__.replace('Gate', '').lower()  # Normalize class name\n",
    "        for method in method_names:\n",
    "            if method == class_name or method == class_name.replace('cr', 'c-r'):\n",
    "                gate_to_method[gate] = method\n",
    "                break\n",
    "    \n",
    "    # Add common operations that are not strictly gates\n",
    "    additional_operations = {\n",
    "        'Measure': 'measure',\n",
    "        'Barrier': 'barrier',\n",
    "    }\n",
    "    gate_to_method.update(additional_operations)\n",
    "    \n",
    "    for k,v in gate_to_method.items():\n",
    "        list_of_gates.append(v)\n",
    "\n",
    "\n",
    "def update_counts(gates,custom_gates):\n",
    "    operations = {}\n",
    "    for key, value in gates.items():\n",
    "        operations[key] = value\n",
    "    for key, value in custom_gates.items():\n",
    "        if key in operations:\n",
    "            operations[key] += value\n",
    "        else:\n",
    "            operations[key] = value       \n",
    "    return operations\n",
    "\n",
    "\n",
    "def get_gate_counts(gates,custom_gate_defs):\n",
    "    result = gates.copy()\n",
    "    # Iterate over the gate counts in the quantum circuit\n",
    "    for gate, count in gates.items():\n",
    "        if gate in custom_gate_defs:\n",
    "            custom_gate_ops = custom_gate_defs[gate]\n",
    "            # Multiply custom gate operations by the count of the custom gate in the circuit\n",
    "            for _ in range(count):\n",
    "                result = update_counts(result, custom_gate_ops)\n",
    "            # Remove the custom gate entry as we have expanded it\n",
    "            del result[gate]\n",
    "    return result\n",
    "\n",
    "\n",
    "dict_of_qc = dict() \n",
    "custom_gates_defs = dict()\n",
    "\n",
    "# Function to count operations recursively\n",
    "def count_operations(qc):\n",
    "    dict_of_qc.clear()\n",
    "    #print(\"dict of qc before :\",dict_of_qc)\n",
    "    circuit_traverser(qc)\n",
    "    #print(\"dict of qc after :\",dict_of_qc)\n",
    "    operations = dict()\n",
    "    operations = dict_of_qc[qc.name]\n",
    "    del dict_of_qc[qc.name]\n",
    "    # print(\"operations :\",operations)\n",
    "    # print(\"dict_of_qc :\",dict_of_qc)\n",
    "    for keys in operations.keys():\n",
    "        if keys not in list_of_gates:\n",
    "            for k,v in dict_of_qc.items():\n",
    "                if k in operations.keys():\n",
    "                    custom_gates_defs[k] = v\n",
    "                    operations=get_gate_counts(operations,custom_gates_defs)\n",
    "                    custom_gates_defs.clear()\n",
    "    return operations\n",
    "\n",
    "def circuit_traverser(qc):\n",
    "    dict_of_qc[qc.name]=dict(qc.count_ops())\n",
    "    for i in qc.data:\n",
    "        if str(i[0].name) not in list_of_gates:\n",
    "            qc_1 = i[0].definition\n",
    "            circuit_traverser(qc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede6470-47df-413f-9795-a590d47d79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory():\n",
    "    import resource\n",
    "    usage = resource.getrusage(resource.RUSAGE_SELF)\n",
    "    max_mem = usage.ru_maxrss/1024 #in MB\n",
    "    return max_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615de29-2bea-4a78-a7ad-b193dc7c3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_excel_with_data(filename, data_to_excel, noise_inclusion=False):\n",
    "    import pandas as pd\n",
    "    from openpyxl import load_workbook, Workbook\n",
    "    from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "    from openpyxl.styles import Alignment, PatternFill\n",
    "\n",
    "    config = data_to_excel['configuration']\n",
    "    del data_to_excel['configuration']\n",
    "    min_qubits=config['min_qbits']\n",
    "    max_qubits=config['max_qbits']\n",
    "    skip_qubits=config['skp_qubits']\n",
    "    num_ckts = config['num_ckts']\n",
    "    qv = config['QV_']\n",
    "    simulator_type= config['Type_of_Simulator']\n",
    "    benchmark_name = config['benchmark_name']\n",
    "    Processor = config['Processor']\n",
    "    Cores = config['cores']\n",
    "    last_updated = data_to_excel['last_updated']\n",
    "    del data_to_excel['last_updated']\n",
    "    #print(data_to_excel)\n",
    "    df = pd.DataFrame(data_to_excel)\n",
    "    \n",
    "    # Load the workbook if it exists, otherwise create a new one\n",
    "    try:\n",
    "        workbook = load_workbook(filename)\n",
    "        if simulator_type in workbook.sheetnames:\n",
    "            worksheet = workbook[simulator_type]\n",
    "        else:\n",
    "            worksheet = workbook.create_sheet(simulator_type)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        workbook = Workbook()\n",
    "        worksheet = workbook.active\n",
    "        worksheet.title = simulator_type\n",
    "\n",
    "    # Add an empty row for separation\n",
    "    worksheet.append([''] * len(df.columns))\n",
    "     \n",
    "    title_row = [f'Qiskit: Algorithm = {benchmark_name} Simulator = {simulator_type}']\n",
    "    worksheet.append(title_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the title row\n",
    "    title_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "    worksheet.merge_cells(title_cell_range)\n",
    "\n",
    "    HW_row = [f'CPU: {Processor} with {cores} cores']\n",
    "    worksheet.append(HW_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the title row\n",
    "    HW_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "    worksheet.merge_cells(HW_cell_range)\n",
    "\n",
    "    if noise_inclusion:\n",
    "        noise_row = [f\"Executing with Noise\"]\n",
    "        worksheet.append(noise_row + [''] * (len(df.columns) - 1))\n",
    "        # Merge cells for the title row\n",
    "        noise_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "        worksheet.merge_cells(noise_cell_range)\n",
    "            \n",
    "    # Add the configuration row spanning all columns\n",
    "    config_row = [f'Configuration: Min_Qubits = {min_qubits} Max_Qubits = {max_qubits} Skip_Qubits = {skip_qubits} num_circuits = {num_ckts[0]}  QV_ = {qv} Last_Updated = {last_updated}']\n",
    "    worksheet.append(config_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the configuration row\n",
    "    config_cell_range = f'A{worksheet.max_row}:S{worksheet.max_row}'\n",
    "    worksheet.merge_cells(config_cell_range)\n",
    "\n",
    "    # Center align all cells in the worksheet\n",
    "    for row in worksheet.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "    # Append the DataFrame to the worksheet\n",
    "    for r in dataframe_to_rows(df, index=False):\n",
    "        worksheet.append(r)\n",
    "\n",
    "    # Add an empty row for separation\n",
    "    worksheet.append([''] * len(df.columns))\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d18b8-43ce-4185-bde2-14db0157d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_info():\n",
    "    import cpuinfo\n",
    "    processor = cpuinfo.get_cpu_info()['brand_raw']\n",
    "    cores = cpuinfo.get_cpu_info()['count']    \n",
    "    \n",
    "    return processor,cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a855d-01e3-440f-9d9c-9487e42daa5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Analyzer Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea744ed-fe29-40d9-8e0a-ddffe4dd791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type(input_size, circuit_type):\n",
    "    input_size = input_size - 1\n",
    "    if circuit_type == 0:\n",
    "        key = '0' * (input_size)\n",
    "    else:\n",
    "        #key = '1' * input_size\n",
    "        key = '1'*(input_size)\n",
    "    correct_dist = {key: 1.0}\n",
    "    return correct_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39b754-8226-4e2a-ad5f-7eb05330ec2a",
   "metadata": {},
   "source": [
    "# RUN Function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b0d25-644b-42bc-b362-7d0fe51cfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_circuits=2\n",
    "def run (min_qubits=min_qubits, max_qubits=max_qubits, skip_qubits=skip_qubits, \n",
    "         max_circuits=max_circuits, num_shots=num_shots):\n",
    "    num_qubits_of_ckt = []\n",
    "    creation_times = []\n",
    "    elapsed_times = []\n",
    "    quantum_times = []\n",
    "    circuit_depths = []\n",
    "    transpiled_depths = []\n",
    "    fidelity_data = {}\n",
    "    Hf_fidelity_data = {}\n",
    "    numckts = []\n",
    "    mem_usage = []\n",
    "    algorithmic_1Q_gate_counts = []\n",
    "    algorithmic_2Q_gate_counts = []\n",
    "    transpiled_1Q_gate_counts = []\n",
    "    transpiled_2Q_gate_counts = []\n",
    "    xi = []\n",
    "    tr_xi = []\n",
    "    \n",
    "    print(f\"{benchmark_name} Benchmark Program - {platform}\")\n",
    "\n",
    "    #defining all the standard gates supported by qiskit in a list\n",
    "    if gate_counts_plots == True:\n",
    "        list_of_standardgates()\n",
    "\n",
    "    # validate parameters (smallest circuit is 3 qubits)\n",
    "    max_qubits = max(3, max_qubits)\n",
    "    min_qubits = min(max(3, min_qubits), max_qubits)\n",
    "    skip_qubits = max(1, skip_qubits)\n",
    "\n",
    "    global max_ckts\n",
    "    max_ckts = max_circuits\n",
    "\n",
    "    global min_qbits,max_qbits,skp_qubits\n",
    "\n",
    "    min_qbits = min_qubits\n",
    "    max_qbits = max_qubits\n",
    "    skp_qubits = skip_qubits\n",
    "\n",
    "    print(f\"min, max qubits = {min_qubits} {max_qubits}\")\n",
    "\n",
    "    # Execute Benchmark Program N times for multiple circuit sizes\n",
    "    for num_qubits in range(min_qubits, max_qubits + 1, skip_qubits):\n",
    "        fidelity_data[num_qubits] = []\n",
    "        Hf_fidelity_data[num_qubits] = []\n",
    "        num_circuits = min(2, max_circuits)\n",
    "        numckts.append(num_circuits)\n",
    "        for type in range(num_circuits):\n",
    "            print(\"*********************************************\")\n",
    "            print(f\"qc of {num_qubits} qubits of type {type}\")\n",
    "\n",
    "            #creation of Quantum Circuit.\n",
    "            ts = time.time()\n",
    "            qc = DeutschJozsa(num_qubits, type).reverse_bits()    \n",
    "            #creation time\n",
    "            creation_time = (time.time() - ts)*1000\n",
    "            creation_times.append(creation_time)\n",
    "            #print(qc)\n",
    "            print(f\"creation time = {creation_time} ms\")\n",
    "            num_qubits_of_ckt.append(qc.num_qubits)\n",
    "            \n",
    "            # Calculate gate count for the algorithmic circuit (excluding barriers and measurements)\n",
    "            \n",
    "            if gate_counts_plots == True:\n",
    "                operations = count_operations(qc)\n",
    "                #print(operations)\n",
    "                n1q = 0; n2q = 0\n",
    "                if operations != None:\n",
    "                    for key, value in operations.items():\n",
    "                        if key == \"measure\": continue\n",
    "                        if key == \"barrier\": continue\n",
    "                        if key.startswith(\"c\") or key.startswith(\"mc\"):\n",
    "                            n2q += value\n",
    "                        else:\n",
    "                            n1q += value\n",
    "\n",
    "                xi_value = n2q/(n1q+n2q)\n",
    "                xi.append(xi_value)\n",
    "                algorithmic_1Q_gate_counts.append(n1q)\n",
    "                algorithmic_2Q_gate_counts.append(n2q)\n",
    "            \n",
    "            # collapse the sub-circuit levels used in this benchmark (for qiskit)\n",
    "            qc=qc.decompose()\n",
    "            #print(qc)\n",
    "            \n",
    "            # Calculate circuit depth\n",
    "            depth = calculate_circuit_depth(qc)\n",
    "            circuit_depths.append(depth)\n",
    "\n",
    "            # Calculate transpiled circuit depth\n",
    "            transpiled_depth,qc = calculate_transpiled_depth(qc,basis_selector)\n",
    "            transpiled_depths.append(transpiled_depth)\n",
    "            #print(qc)\n",
    "\n",
    "            print(f\"Algorithmic Depth = {depth} and Normalized Depth = {transpiled_depth}\")\n",
    "\n",
    "            if gate_counts_plots == True:\n",
    "                # Calculate gate count for the transpiled circuit (excluding barriers and measurements)\n",
    "                tr_ops = qc.count_ops()\n",
    "                #print(\"tr_ops = \",tr_ops)\n",
    "                tr_n1q = 0; tr_n2q = 0\n",
    "                if tr_ops != None:\n",
    "                    for key, value in tr_ops.items():\n",
    "                        if key == \"measure\": continue\n",
    "                        if key == \"barrier\": continue\n",
    "                        if key.startswith(\"c\"): tr_n2q += value\n",
    "                        else: tr_n1q += value\n",
    "                tr_xi_value =tr_n2q/(tr_n1q+tr_n2q) \n",
    "                tr_xi.append(tr_xi_value)            \n",
    "                transpiled_1Q_gate_counts.append(tr_n1q)\n",
    "                transpiled_2Q_gate_counts.append(tr_n2q)\n",
    "    \n",
    "                print(f\"Algorithmic 1Q gates = {n1q} ,Algorithmic 2Q gates = {n2q}, xi = {xi_value}\")\n",
    "                print(f\"Normalized 1Q gates = {tr_n1q} ,Normalized 2Q gates = {tr_n2q}, tr_xi = {tr_xi_value}\")\n",
    "            \n",
    "            #execution\n",
    "            ts = time.time()\n",
    "            if Noise_Inclusion == True:\n",
    "                job = execute(qc, backend, shots=num_shots, **options_noisy)\n",
    "            else:\n",
    "                job = execute(qc, backend, shots=num_shots, **options)\n",
    "            \n",
    "            #retrieving the result \n",
    "            result = job.result()\n",
    "            #print(result)\n",
    "            \n",
    "            #calculating elapsed time\n",
    "            elapsed_time = (time.time() - ts)*1000\n",
    "            elapsed_times.append(elapsed_time)\n",
    "            \n",
    "            # Calculate quantum processing time \n",
    "            quantum_time = (result.results[0].running_time_taken)*1000\n",
    "            quantum_times.append(quantum_time)\n",
    "\n",
    "            print(f\"Elapsed time = {elapsed_time} ms and Quantum Time = {quantum_time } ms\")\n",
    "\n",
    "            #counts in result object \n",
    "            counts = result.results[0].data.partial_probability\n",
    "            #print(\"Counts = \",counts)\n",
    "\n",
    "            for key in counts.keys():\n",
    "               counts[key] = int(counts[key] * num_shots)\n",
    "\n",
    "            #Correct distribution to compare with counts\n",
    "            correct_dist = determine_type(num_qubits, type)\n",
    "            \n",
    "            #fidelity calculation comparision of counts and correct_dist \n",
    "            fidelity_dict = polarization_fidelity(counts, correct_dist)\n",
    "            fidelity_data[num_qubits].append(fidelity_dict['fidelity'])\n",
    "            Hf_fidelity_data[num_qubits].append(fidelity_dict['hf_fidelity'])\n",
    "            print(\"Fidelity:\",fidelity_dict)\n",
    "            \n",
    "            #maximum memory utilization (if required)\n",
    "            if Memory_utilization_plot == True:\n",
    "                max_mem = get_memory()\n",
    "                print(f\"Maximum Memory Utilized: {max_mem} MB\")\n",
    "                mem_usage.append(max_mem)\n",
    "\n",
    "            print(\"*********************************************\")\n",
    "    \n",
    "    # print a sample circuit\n",
    "    print(\"Sample Circuit:\"); print(QC_ if QC_ != None else \"  ... too large!\")\n",
    "    print(\"\\nConstant Oracle 'Uf' =\"); print(C_ORACLE_ if C_ORACLE_ != None else \" ... too large or not used!\")\n",
    "    print(\"\\nBalanced Oracle 'Uf' =\"); print(B_ORACLE_ if B_ORACLE_ != None else \" ... too large or not used!\")\n",
    "    \n",
    "    return (num_qubits_of_ckt,creation_times, elapsed_times, quantum_times, circuit_depths, transpiled_depths, xi, tr_xi,\n",
    "            fidelity_data, Hf_fidelity_data, numckts , algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts,\n",
    "    transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74a319-b5c7-4d24-a75e-def3e1f0bcc0",
   "metadata": {},
   "source": [
    "# Triggering RUN function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1e5eb-6be5-455e-9951-e13d0afea3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the benchmark program, accumulate metrics, and calculate circuit depths\n",
    "(num_qubits_of_ckt, creation_times, elapsed_times, quantum_times, circuit_depths,transpiled_depths,xi, tr_xi, fidelity_data, Hf_fidelity_data, numckts,  \n",
    "algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts, transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage) = run()\n",
    "\n",
    "# Define the range of qubits for the x-axis\n",
    "num_qubits_range = range(min_qbits, max_qbits+1,skp_qubits)\n",
    "print(\"num_qubits_range =\",num_qubits_range)\n",
    "\n",
    "#Information of Execution Hardware\n",
    "Processor,cores = get_cpu_info()\n",
    "print(f\"****** Completed Execution on processor {Processor} with {cores} cores ******\")\n",
    "# Calculate average creation time, elapsed time, quantum processing time, and circuit depth for each number of qubits\n",
    "avg_creation_times = []\n",
    "std_creation_times= []\n",
    "avg_elapsed_times = []\n",
    "std_elapsed_times= []\n",
    "avg_quantum_times = []\n",
    "std_quantum_times= []\n",
    "avg_circuit_depths = []\n",
    "avg_transpiled_depths = []\n",
    "avg_1Q_algorithmic_gate_counts = []\n",
    "avg_2Q_algorithmic_gate_counts = []\n",
    "avg_1Q_Transpiled_gate_counts = []\n",
    "avg_2Q_Transpiled_gate_counts = []\n",
    "avg_xi=[]\n",
    "avg_tr_xi=[]\n",
    "max_memory = []\n",
    "Qubits = []\n",
    "\n",
    "start = 0\n",
    "for num in numckts:\n",
    "    avg_creation_times.append(round(np.mean(creation_times[start:start+num]),3))\n",
    "    std_creation_times.append(round(np.std(creation_times[start:start+num])/np.sqrt(len(creation_times)), 3))\n",
    "    avg_elapsed_times.append(round(np.mean(elapsed_times[start:start+num]),3))\n",
    "    std_elapsed_times.append(round(np.std(elapsed_times[start:start+num])/np.sqrt(len(elapsed_times)), 3))\n",
    "    avg_quantum_times.append(round(np.mean(quantum_times[start:start+num]),3))\n",
    "    std_quantum_times.append(round(np.std(quantum_times[start:start+num])/np.sqrt(len(quantum_times)), 3))\n",
    "    avg_circuit_depths.append(round(np.mean(circuit_depths[start:start+num]),3))\n",
    "    avg_transpiled_depths.append(round(np.mean(transpiled_depths[start:start+num]),3))\n",
    "    if gate_counts_plots == True:\n",
    "        avg_1Q_algorithmic_gate_counts.append(round(np.mean(algorithmic_1Q_gate_counts[start:start+num]),2))\n",
    "        avg_2Q_algorithmic_gate_counts.append(round(np.mean(algorithmic_2Q_gate_counts[start:start+num]),2))\n",
    "        avg_xi.append(round(np.mean(xi[start:start+num]),2))\n",
    "        avg_1Q_Transpiled_gate_counts.append(round(np.mean(transpiled_1Q_gate_counts[start:start+num]),2))\n",
    "        avg_2Q_Transpiled_gate_counts.append(round(np.mean(transpiled_2Q_gate_counts[start:start+num]),2))\n",
    "        avg_tr_xi.append(round(np.mean(tr_xi[start:start+num]),2))\n",
    "    if Memory_utilization_plot == True:max_memory.append(round(np.max(mem_usage[start:start+num]),2))\n",
    "    Qubits.append(int(np.mean(num_qubits_of_ckt[start:start+num])))\n",
    "    start += num\n",
    "\n",
    "\n",
    "# Calculate the fidelity data\n",
    "avg_f, avg_Hf, std_f, std_hf = plot_fidelity_data(fidelity_data, Hf_fidelity_data, \"Fidelity Comparison\")\n",
    "\n",
    "if Store_Data:\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    # Prepare the data dictionary\n",
    "    data = {\n",
    "        \"configuration\":{\n",
    "        \"min_qbits\":min_qbits,\n",
    "        \"max_qbits\":max_qbits,\n",
    "        \"skp_qubits\":skp_qubits,\n",
    "        \"num_ckts\":numckts,\n",
    "        \"Type_of_Simulator\":platform,\n",
    "        \"benchmark_name\":benchmark_name,\n",
    "        \"QV_\":QV_,\n",
    "        \"Processor\":Processor,\n",
    "        \"cores\":cores},\n",
    "        'Number of Qubits': Qubits,\n",
    "        \"avg_creation_times (ms)\": avg_creation_times,\n",
    "        \"std_creation_times (ms)\": std_creation_times,\n",
    "        \"avg_elapsed_times (ms)\": avg_elapsed_times,\n",
    "        \"std_elapsed_times (ms)\":std_elapsed_times,\n",
    "        \"avg_quantum_times (ms)\": avg_quantum_times,\n",
    "        \"std_quantum_times (ms)\":std_quantum_times,\n",
    "        \"avg_circuit_depths\": avg_circuit_depths,\n",
    "        \"avg_transpiled_depths\": avg_transpiled_depths,\n",
    "        \"Average_Rescaled_fidelity\":avg_f,\n",
    "        \"Average_Hellinger_fidelity\":avg_Hf,\n",
    "        \"std_Rescaled_Fidelity\":std_f,\n",
    "        \"std_hellinger_fidelity\":std_hf\n",
    "    }\n",
    "\n",
    "    if gate_counts_plots:\n",
    "        data[\"avg_1Q_algorithmic_gate_counts\"] =  avg_1Q_algorithmic_gate_counts\n",
    "        data[\"avg_2Q_algorithmic_gate_counts\"] =  avg_2Q_algorithmic_gate_counts\n",
    "        data[\"avg_xi (n2q/n1q+n2q)\"]=avg_xi\n",
    "        data[\"avg_1Q_Transpiled_gate_counts\"]= avg_1Q_Transpiled_gate_counts\n",
    "        data[\"avg_2Q_Transpiled_gate_counts\"]= avg_2Q_Transpiled_gate_counts\n",
    "        data[\"avg_tr_xi (tr_n2q/tr_n1q+tr_n2q)\"]=avg_tr_xi\n",
    "\n",
    "    if Memory_utilization_plot:\n",
    "        data[\"max_memory (MB)\"]: max_memory\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Add the timestamp to the data\n",
    "    data['last_updated'] = current_time\n",
    "    \n",
    "    # Define the file name\n",
    "    file_name = '__data.json'\n",
    "    \n",
    "    # Write the data to the file\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    \n",
    "    print(f\"***** Data has been saved to {file_name} ******\")\n",
    "\n",
    "    if save_to_excel: \n",
    "        #from Data_Plotter import update_excel_with_data\n",
    "        update_excel_with_data(f\"{benchmark_name} Benchmark-Results.xlsx\",data,Noise_Inclusion)\n",
    "        print(\"***** Data has been updated to Benchmark-Results.xlsx *****\")\n",
    "\n",
    "\n",
    "# Plot histograms for average creation time, average elapsed time, average quantum processing time, and average circuit depth versus the number of qubits\n",
    "\n",
    "# Add labels to the bars\n",
    "def autolabel(rects,ax,str='{:.3f}',text_color=\"black\"):\n",
    "        max_y_value=ax.get_ylim()[1]  # Get the maximum value on the y-axis\n",
    "        threshold=0.3*max_y_value   # Define threshold as 30% of max y-axis value\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            if height < threshold:\n",
    "                rotation = 90\n",
    "                va = 'bottom'  # Place text above the bar\n",
    "                xytext = (0, 3)  # Offset slightly above the bar\n",
    "            else:\n",
    "                rotation = 90\n",
    "                va = 'center'  # Place text inside the bar\n",
    "                xytext = (0, 0)  # No offset\n",
    "            ax.annotate(str.format(height),  # Formatting to two decimal places\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height/6),\n",
    "                        xytext=xytext,\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va=va, color=text_color, rotation=rotation)\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "# Determine the number of subplots and their arrangement\n",
    "if Memory_utilization_plot and gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7) = plt.subplots(7, 1, figsize=(18, 30))\n",
    "    # Plotting for both memory utilization and gate counts\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6, ax7 are available\n",
    "elif Memory_utilization_plot:\n",
    "    fig, (ax1, ax2, ax3, ax6, ax7) = plt.subplots(5, 1, figsize=(18, 30))\n",
    "    # Plotting for memory utilization only\n",
    "    # ax1, ax2, ax3, ax6, ax7 are available\n",
    "elif gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(18, 30))\n",
    "    # Plotting for gate counts only\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6 are available\n",
    "else:\n",
    "    fig, (ax1, ax2, ax3, ax6) = plt.subplots(4, 1, figsize=(18, 30))\n",
    "    # Default plotting\n",
    "    # ax1, ax2, ax3, ax6 are available\n",
    "\n",
    "fig.suptitle(f\"General Benchmarks : {platform} - {benchmark_name} - {Processor}\", fontsize=16)\n",
    "\n",
    "\n",
    "ax1.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "x = ax1.bar(num_qubits_range, avg_creation_times, yerr=std_creation_times, capsize=15, color='deepskyblue')\n",
    "autolabel(ax1.patches, ax1)\n",
    "ax1.set_xlabel('Number of Qubits')\n",
    "ax1.set_ylabel('Average Creation Time (ms)')\n",
    "ax1.set_title('Average Creation Time vs Number of Qubits',fontsize=14)\n",
    "\n",
    "\n",
    "ax2.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "\n",
    "\n",
    "Elapsed= ax2.bar(np.array(num_qubits_range) - bar_width / 2, avg_elapsed_times,yerr=std_elapsed_times, capsize=15, width=bar_width, color='cyan', label='Elapsed Time')\n",
    "Quantum= ax2.bar(np.array(num_qubits_range) + bar_width / 2, avg_quantum_times,yerr=std_quantum_times, capsize=15,width=bar_width, color='deepskyblue',label ='Quantum Time')\n",
    "autolabel(Elapsed,ax2,str='{:.1f}')\n",
    "autolabel(Quantum,ax2,str='{:.1f}')\n",
    "ax2.set_xlabel('Number of Qubits')\n",
    "ax2.set_ylabel('Average Time (ms)')\n",
    "ax2.set_title('Average Time vs Number of Qubits')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Normalized = ax3.bar(np.array(num_qubits_range) - bar_width / 2, avg_transpiled_depths, color='cyan', label='Normalized Depth', width=bar_width)  # Adjust width here\n",
    "Algorithmic = ax3.bar(np.array(num_qubits_range) + bar_width / 2,avg_circuit_depths, color='deepskyblue', label='Algorithmic Depth', width=bar_width)  # Adjust width here\n",
    "autolabel(Normalized,ax3,str='{:.2f}')\n",
    "autolabel(Algorithmic,ax3,str='{:.2f}')\n",
    "ax3.set_xlabel('Number of Qubits')\n",
    "ax3.set_ylabel('Average Circuit Depth')\n",
    "ax3.set_title('Average Circuit Depth vs Number of Qubits')\n",
    "ax3.legend()\n",
    "\n",
    "if gate_counts_plots == True:\n",
    "    ax4.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_1Q_counts = ax4.bar(np.array(num_qubits_range) - bar_width / 2, avg_1Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_1Q_counts = ax4.bar(np.array(num_qubits_range) + bar_width / 2, avg_1Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_1Q_counts,ax4,str='{}')\n",
    "    autolabel(Algorithmic_1Q_counts,ax4,str='{}')\n",
    "    ax4.set_xlabel('Number of Qubits')\n",
    "    ax4.set_ylabel('Average 1-Qubit Gate Counts')\n",
    "    ax4.set_title('Average 1-Qubit Gate Counts vs Number of Qubits')\n",
    "    ax4.legend()\n",
    "    \n",
    "    ax5.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_2Q_counts = ax5.bar(np.array(num_qubits_range) - bar_width / 2, avg_2Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_2Q_counts = ax5.bar(np.array(num_qubits_range) + bar_width / 2, avg_2Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_2Q_counts,ax5,str='{}')\n",
    "    autolabel(Algorithmic_2Q_counts,ax5,str='{}')\n",
    "    ax5.set_xlabel('Number of Qubits')\n",
    "    ax5.set_ylabel('Average 2-Qubit Gate Counts')\n",
    "    ax5.set_title('Average 2-Qubit Gate Counts vs Number of Qubits')\n",
    "    ax5.legend()\n",
    "\n",
    "\n",
    "ax6.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Hellinger = ax6.bar(np.array(num_qubits_range) - bar_width / 2, avg_Hf,yerr=std_hf, capsize=15, width=bar_width, label='Hellinger Fidelity',color='cyan')  # Adjust width here\n",
    "Normalized = ax6.bar(np.array(num_qubits_range) + bar_width / 2, avg_f,yerr=std_f, capsize=15, width=bar_width, label='Normalized Fidelity', color='deepskyblue')  # Adjust width here\n",
    "autolabel(Hellinger,ax6,str='{:.2f}')\n",
    "autolabel(Normalized,ax6,str='{:.2f}')\n",
    "ax6.set_xlabel('Number of Qubits')\n",
    "ax6.set_ylabel('Average Value')\n",
    "ax6.set_title(\"Fidelity Comparison\")\n",
    "ax6.legend()\n",
    "\n",
    "if Memory_utilization_plot == True:\n",
    "    ax7.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    x = ax7.bar(num_qubits_range, max_memory, color='turquoise', width=bar_width, label=\"Memory Utilizations\")\n",
    "    autolabel(ax7.patches, ax7)\n",
    "    ax7.set_xlabel('Number of Qubits')\n",
    "    ax7.set_ylabel('Maximum Memory Utilized (MB)')\n",
    "    ax7.set_title('Memory Utilized vs Number of Qubits',fontsize=14)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "if saveplots == True:\n",
    "    plt.savefig(\"ParameterPlotsSample.jpg\")\n",
    "plt.show()\n",
    "\n",
    "num_qubits_range = Qubits\n",
    "\n",
    "# Quantum Volume Plot\n",
    "Suptitle = f\"Volumetric Positioning - {platform}\"\n",
    "appname=benchmark_name\n",
    "if QV_ == None:\n",
    "    QV=2048\n",
    "else:\n",
    "    QV=QV_\n",
    "depth_base =2\n",
    "\n",
    "ax = plot_volumetric_background(max_qubits=max_qbits, QV=QV,depth_base=depth_base, suptitle=Suptitle, colorbar_label=\"Avg Result Fidelity\")\n",
    "\n",
    "w_data = num_qubits_range\n",
    "# determine width for circuit\n",
    "w_max = 0\n",
    "for i in range(len(w_data)):\n",
    "    y = float(w_data[i])\n",
    "    w_max = max(w_max, y)\n",
    "\n",
    "d_tr_data = avg_transpiled_depths\n",
    "f_data = avg_f\n",
    "\n",
    "plot_volumetric_data(ax, w_data, d_tr_data, f_data, depth_base, fill=True,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, w_max=w_max)\n",
    "anno_volumetric_data(ax, depth_base,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, fill=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
