{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb892a-1753-4ca4-b867-d2b7f19dcc10",
   "metadata": {},
   "source": [
    "# Custom Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc63908-52eb-41c3-9f1a-545fce488cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign these values as per your requirements.\n",
    "global min_qubits,max_qubits,skip_qubits,max_circuits,num_shots,Noise_Inclusion\n",
    "\n",
    "min_qubits=3\n",
    "max_qubits=9\n",
    "skip_qubits=2\n",
    "num_shots=1000\n",
    "saveplots = False\n",
    "\n",
    "backend_id = 'braket_dm' #['braket_ahs', 'braket_dm', 'braket_sv', 'default'] braket_ahs implementation yet to be done.\n",
    "Noise_Inclusion = False #only applicable for braket_dm \n",
    "Memory_utilization_plot = True\n",
    "gate_counts_plots = True\n",
    "Store_Data = True\n",
    "save_to_excel = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060362a1-64fa-4ad6-ad17-ec0b825634ee",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1169dd7-e2b7-4a40-ba84-3c3cd2d7edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from braket.circuits import Circuit,Gate     # AWS imports: Import Braket SDK modules\n",
    "import time,json,os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from braket.devices import LocalSimulator\n",
    "\n",
    "# saved circuits for display\n",
    "QC_ = None\n",
    "Uf_ = None\n",
    "\n",
    "benchmark_name = \"Hamiltonian\"\n",
    "\n",
    "verbose = False\n",
    "qcs = [None, None, None]    # saved subcircuits for printing (not used yet in braket)\n",
    "\n",
    "# save main circuit to display\n",
    "QC_ = None\n",
    "\n",
    "# for validating the implementation of XXYYZZ operation\n",
    "_use_XX_YY_ZZ_gates = False\n",
    "\n",
    "# import precalculated data to compare against\n",
    "filename = os.path.join(\"precalculated_data.json\")\n",
    "with open(filename, 'r') as file:\n",
    "    data = file.read()\n",
    "precalculated_data = json.loads(data)\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3b451-e323-4482-8ef3-626632e87b56",
   "metadata": {},
   "source": [
    "# Declaring Backend :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9c2d2-0439-4967-982c-1d40a2fb7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "global device\n",
    "\n",
    "if backend_id == None or backend_id == \"\":\n",
    "    device = LocalSimulator() #Statevector Simulator\n",
    "    device_Name =  device.name\n",
    "    print(f\"Using {device_Name} device for execution\")\n",
    "elif backend_id in LocalSimulator().registered_backends():\n",
    "    if backend_id in ['braket_dm', 'braket_sv', 'default']:#default -> statevector, sv-> Statevector dm-> density matrix\n",
    "        device = LocalSimulator(backend=backend_id)\n",
    "        device_Name = device.name\n",
    "        print(f\"Using {device_Name} device for execution\")\n",
    "    elif backend_id == 'braket_ahs': # ahs -> Analog Hamiltonian Simulation\n",
    "        device = LocalSimulator(backend=backend_id)\n",
    "        device_Name = device.name\n",
    "        print(f\"Using {device_Name} device for execution\")\n",
    "        print(f\"Implementation for {device_Name} device is yet to be done.\")\n",
    "        device = LocalSimulator(backend='default')\n",
    "        device_Name = device.name\n",
    "        print(f\"By default executing with {device_Name} backend.\")\n",
    "else:\n",
    "    print(\"Enter  a valid Backend\")\n",
    "platform = device_Name\n",
    "QV_=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ee7c3-6b88-45bd-8fff-bcb0a44e9d0f",
   "metadata": {},
   "source": [
    "# Algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791060af-9178-4257-a11e-d25066ce6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HamiltonianSimulation(n_spins, K, t, w, h_x, h_z):\n",
    "    '''\n",
    "    Construct a Braket circuit for Hamiltonian Simulation\n",
    "    :param n_spins:The number of spins to simulate\n",
    "    :param K: The Trotterization order\n",
    "    :param t: duration of simulation\n",
    "    :return: return a braket circuit for this Hamiltonian\n",
    "    '''\n",
    "    \n",
    "    # allocate circuit\n",
    "    qc = Circuit()\n",
    "    tau = t / K\n",
    "\n",
    "    # start with initial state of 1010101...\n",
    "    for k in range(0, n_spins, 2):\n",
    "        qc.x(k)\n",
    "\n",
    "    # loop over each trotter step, adding gates to the circuit defining the hamiltonian\n",
    "    for k in range(K):\n",
    "    \n",
    "        # the Pauli spin vector product\n",
    "        [qc.rx(i, 2 * tau * w * h_x[i]) for i in range(n_spins)]\n",
    "        [qc.rz(i, 2 * tau * w * h_z[i]) for i in range(n_spins)]\n",
    "\n",
    "        # Basic implementation of exp(i * t * (XX + YY + ZZ))\n",
    "        if _use_XX_YY_ZZ_gates:\n",
    "\n",
    "            # XX operator on each pair of qubits in linear chain\n",
    "            for j in range(2):\n",
    "                for i in range(j%2, n_spins - 1, 2):\n",
    "                    qcs[0] = qc_xx = xx_gate(qc, tau, [i, (i + 1) % n_spins])\n",
    "                    #qc.append(qc_xx.to_instruction(), [i, (i + 1) % n_spins])\n",
    "\n",
    "            # YY operator on each pair of qubits in linear chain\n",
    "            for j in range(2):\n",
    "                for i in range(j%2, n_spins - 1, 2):\n",
    "                    qcs[1] = qc_yy = yy_gate(qc, tau, [i, (i + 1) % n_spins])\n",
    "                    #qc.append(qc_yy.to_instruction(), [i, (i + 1) % n_spins])\n",
    "\n",
    "            # ZZ operation on each pair of qubits in linear chain\n",
    "            for j in range(2):\n",
    "                for i in range(j%2, n_spins - 1, 2):\n",
    "                    qcs[2] = qc_zz = zz_gate(qc, tau, [i, (i + 1) % n_spins])\n",
    "                    #qc.append(qc_zz.to_instruction(), [i, (i + 1) % n_spins])\n",
    "\n",
    "        # Use an optimal XXYYZZ combined operator\n",
    "        # See equation 1 and Figure 6 in https://arxiv.org/pdf/quant-ph/0308006.pdf\n",
    "        else:\n",
    "\n",
    "            # optimized XX + YY + ZZ operator on each pair of qubits in linear chain\n",
    "            for j in range(2):\n",
    "                for i in range(j % 2, n_spins  - 1, 2):\n",
    "                    qcs[0] = qc_xxyyzz = xxyyzz_opt_gate(qc, tau, [i, (i + 1) % n_spins])\n",
    "                    #qc.append(qc_xxyyzz.to_instruction(), [i, (i + 1) % n_spins])\n",
    "\n",
    "    # save smaller circuit example for display\n",
    "    global QC_    \n",
    "    if QC_ == None or n_spins <= 6:\n",
    "        if n_spins < 9: QC_ = qc\n",
    "\n",
    "    return qc\n",
    "\n",
    "############### XX, YY, ZZ Gate Implementations\n",
    "\n",
    "# Simple XX gate on q0 and q1 with angle 'tau'\n",
    "def xx_gate(qc, tau, qr):\n",
    "    qc.h(qr[0])\n",
    "    qc.h(qr[1])\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    qc.rz(qr[1], pi*tau)\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    qc.h(qr[0])\n",
    "    qc.h(qr[1])\n",
    "    return qc\n",
    "\n",
    "# Simple YY gate on q0 and q1 with angle 'tau'    \n",
    "def yy_gate(qc, tau, qr):\n",
    "    qc.s(qr[0])\n",
    "    qc.s(qr[1])\n",
    "    qc.h(qr[0])\n",
    "    qc.h(qr[1])\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    qc.rz(qr[1], pi*tau)\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    qc.h(qr[0])\n",
    "    qc.h(qr[1])\n",
    "    qc.si(qr[0])\n",
    "    qc.si(qr[1])\n",
    "    return qc\n",
    "\n",
    "# Simple ZZ gate on q0 and q1 with angle 'tau'\n",
    "def zz_gate(qc, tau, qr):\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    qc.rz(qr[1], pi*tau)\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    return qc\n",
    "\n",
    "# Optimal combined XXYYZZ gate (with double coupling) on q0 and q1 with angle 'tau'\n",
    "def xxyyzz_opt_gate(qc, tau, qr):\n",
    "    alpha = tau; beta = tau; gamma = tau\n",
    "    pi=np.pi\n",
    "    qc.rz(qr[1], pi/2)\n",
    "    qc.cnot(qr[1], qr[0])\n",
    "    qc.rz(qr[0], pi*gamma - pi/2)\n",
    "    qc.ry(qr[1], pi/2 - pi*alpha)\n",
    "    qc.cnot(qr[0], qr[1])\n",
    "    qc.ry(qr[1], pi*beta - pi/2)\n",
    "    qc.cnot(qr[1], qr[0])\n",
    "    qc.rz(qr[0], -pi/2)\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbc5d3-98fa-46ef-80c3-06c4a7a97be0",
   "metadata": {},
   "source": [
    "# Noise Parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2c64e-c22c-4773-8a47-41964407fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backend_id == 'braket_dm':\n",
    "    from braket.circuits import noises\n",
    "    # define a Bitfilp Noise channel\n",
    "    BitFlipNoise = noises.BitFlip(probability=0.01)\n",
    "    # define a phase flip noise channel\n",
    "    PhaseFlipNoise = noises.PhaseFlip(probability=0.1)\n",
    "    # define a single-qubit depolarizing noise channel\n",
    "    DepolarizingNoise = noises.Depolarizing(probability=0.1)\n",
    "    # define a two-qubit depolarizing noise channel\n",
    "    DepolarizingNoise2Q = noises.TwoQubitDepolarizing(probability=0.1)\n",
    "    # define a two-qubit dephasing noise channel\n",
    "    DephasingNoise2Q = noises.TwoQubitDephasing(probability=0.1)\n",
    "    # define an amplitude damping noise channel\n",
    "    AmplitudeDampingNoise = noises.AmplitudeDamping(gamma=0.1)\n",
    "    \n",
    "    # define a generalized amplitude damping noise, where gamma is the amplitude damping rate, and\n",
    "    # probability is the probability of the system being excited by the environment.\n",
    "    GenAmplitudeDampingNoise = noises.GeneralizedAmplitudeDamping(gamma=0.1, probability=0.1)\n",
    "    # define a phase damping noise channel\n",
    "    PhaseDampingNoise = noises.PhaseDamping(gamma=0.1)\n",
    "    # define a Pauli noise channel\n",
    "    PauliChannelNoise = noises.PauliChannel(probX=0.1, probY=0.2, probZ=0.3)\n",
    "\n",
    "    noise_parameters = [BitFlipNoise,PhaseFlipNoise,DepolarizingNoise,DepolarizingNoise2Q,DephasingNoise2Q,AmplitudeDampingNoise,GenAmplitudeDampingNoise,PauliChannelNoise]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8506b56-e48a-448a-9a80-63fa86ba1029",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fidelity Calculations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267a29f-ebca-4ceb-9c1b-7dab35fe013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniform distribution function commonly used\n",
    "def rescale_fidelity(fidelity, floor_fidelity, new_floor_fidelity):\n",
    "    \"\"\"\n",
    "    Linearly rescales our fidelities to allow comparisons of fidelities across benchmarks\n",
    "    \n",
    "    fidelity: raw fidelity to rescale\n",
    "    floor_fidelity: threshold fidelity which is equivalent to random guessing\n",
    "    new_floor_fidelity: what we rescale the floor_fidelity to \n",
    "\n",
    "    Ex, with floor_fidelity = 0.25, new_floor_fidelity = 0.0:\n",
    "        1 -> 1;\n",
    "        0.25 -> 0;\n",
    "        0.5 -> 0.3333;\n",
    "    \"\"\"\n",
    "    rescaled_fidelity = (1-new_floor_fidelity)/(1-floor_fidelity) * (fidelity - 1) + 1\n",
    "    \n",
    "    # ensure fidelity is within bounds (0, 1)\n",
    "    if rescaled_fidelity < 0:\n",
    "        rescaled_fidelity = 0.0\n",
    "    if rescaled_fidelity > 1:\n",
    "        rescaled_fidelity = 1.0\n",
    "    \n",
    "    return rescaled_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9266f5c-9c2f-4313-a012-a8be66e58bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_dist(num_state_qubits):\n",
    "    dist = {}\n",
    "    for i in range(2**num_state_qubits):\n",
    "        key = bin(i)[2:].zfill(num_state_qubits)\n",
    "        dist[key] = 1/(2**num_state_qubits)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fad0c7-6b52-416d-9bae-252b693df350",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis methods to be expanded and eventually compiled into a separate analysis.py file\n",
    "import math, functools\n",
    "\n",
    "def hellinger_fidelity_with_expected(p, q):\n",
    "    \"\"\" p: result distribution, may be passed as a counts distribution\n",
    "        q: the expected distribution to be compared against\n",
    "\n",
    "    References:\n",
    "        `Hellinger Distance @ wikipedia <https://en.wikipedia.org/wiki/Hellinger_distance>`_\n",
    "        Qiskit Hellinger Fidelity Function\n",
    "    \"\"\"\n",
    "    p_sum = sum(p.values())\n",
    "    q_sum = sum(q.values())\n",
    "\n",
    "    if q_sum == 0:\n",
    "        print(\"ERROR: polarization_fidelity(), expected distribution is invalid, all counts equal to 0\")\n",
    "        return 0\n",
    "\n",
    "    p_normed = {}\n",
    "    for key, val in p.items():\n",
    "        p_normed[key] = val/p_sum\n",
    "        # if p_sum != 0:\n",
    "        #     p_normed[key] = val/p_sum\n",
    "        # else:\n",
    "        #     p_normed[key] = 0\n",
    "\n",
    "    q_normed = {}\n",
    "    for key, val in q.items():\n",
    "        q_normed[key] = val/q_sum\n",
    "\n",
    "    total = 0\n",
    "    for key, val in p_normed.items():\n",
    "        if key in q_normed.keys():\n",
    "            total += (np.sqrt(val) - np.sqrt(q_normed[key]))**2\n",
    "            del q_normed[key]\n",
    "        else:\n",
    "            total += val\n",
    "    total += sum(q_normed.values())\n",
    "    \n",
    "    # in some situations (error mitigation) this can go negative, use abs value\n",
    "    if total < 0:\n",
    "        print(f\"WARNING: using absolute value in fidelity calculation\")\n",
    "        total = abs(total)\n",
    "        \n",
    "    dist = np.sqrt(total)/np.sqrt(2)\n",
    "    fidelity = (1-dist**2)**2\n",
    "\n",
    "    return fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84c6f2-6d6b-44d6-9998-17df560ae18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarization_fidelity(counts, correct_dist, thermal_dist=None):\n",
    "    \"\"\"\n",
    "    Combines Hellinger fidelity and polarization rescaling into fidelity calculation\n",
    "    used in every benchmark\n",
    "\n",
    "    counts: the measurement outcomes after `num_shots` algorithm runs\n",
    "    correct_dist: the distribution we expect to get for the algorithm running perfectly\n",
    "    thermal_dist: optional distribution to pass in distribution from a uniform\n",
    "                  superposition over all states. If `None`: generated as \n",
    "                  `uniform_dist` with the same qubits as in `counts`\n",
    "                  \n",
    "    returns both polarization fidelity and the hellinger fidelity\n",
    "\n",
    "    Polarization from: `https://arxiv.org/abs/2008.11294v1`\n",
    "    \"\"\"\n",
    "    num_measured_qubits = len(list(correct_dist.keys())[0])\n",
    "    #print(num_measured_qubits)\n",
    "    \n",
    "    counts = {k.zfill(num_measured_qubits): v for k, v in counts.items()}\n",
    "    \n",
    "    # calculate hellinger fidelity between measured expectation values and correct distribution\n",
    "    hf_fidelity = hellinger_fidelity_with_expected(counts,correct_dist)\n",
    "    \n",
    "    # to limit cpu and memory utilization, skip noise correction if more than 16 measured qubits\n",
    "    if num_measured_qubits > 16:\n",
    "        return { 'fidelity':hf_fidelity, 'hf_fidelity':hf_fidelity }\n",
    "\n",
    "    # if not provided, generate thermal dist based on number of qubits\n",
    "    if thermal_dist == None:\n",
    "        thermal_dist = uniform_dist(num_measured_qubits)\n",
    "\n",
    "    # set our fidelity rescaling value as the hellinger fidelity for a depolarized state\n",
    "    floor_fidelity = hellinger_fidelity_with_expected(thermal_dist, correct_dist)\n",
    "\n",
    "    # rescale fidelity result so uniform superposition (random guessing) returns fidelity\n",
    "    # rescaled to 0 to provide a better measure of success of the algorithm (polarization)\n",
    "    new_floor_fidelity = 0\n",
    "    fidelity = rescale_fidelity(hf_fidelity, floor_fidelity, new_floor_fidelity)\n",
    "\n",
    "    return { 'fidelity':fidelity, 'hf_fidelity':hf_fidelity }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e52a5-c4d6-4bba-a9ef-b811084a58cc",
   "metadata": {},
   "source": [
    "### Mathematical formulae:\n",
    "\n",
    "**hf_fidelity :** \n",
    "$$ F_s(P_{ideal},P_{output}) = \\biggr[\\sum_{x}\\sqrt{P_{output}(x)P_{ideal}(x)}\\biggr]^2$$\n",
    "\n",
    "**floor_fidelity :**\n",
    "$$F_s(P_{ideal},P_{uniform})$$\n",
    "\n",
    "$$\\implies F_{raw}(P_{ideal},P_{output}) = \\frac{F_s(P_{ideal},P_{output}) - F_s(P_{ideal},P_{uniform})}{1-F_s(P_{ideal},P_{uniform})}$$\n",
    "\n",
    "**fidelity (or Normalized or Rescaled fidelity) :**\n",
    "$$F(P_{ideal},P_{output}) = max\\biggr\\{F_{raw}(P_{ideal},P_{output}),0\\biggr\\}$$\n",
    "\n",
    "\n",
    "### Example:\n",
    "\n",
    "The equations provided in the paper outline a process for calculating normalized fidelities in the context of quantum computing benchmarks. Here's a detailed explanation of each equation and its significance:\n",
    "\n",
    "### Equation (1): State Fidelity\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( \\sum_x \\sqrt{P_{\\text{output}}(x)} \\sqrt{P_{\\text{ideal}}(x)} \\right)^2 $$\n",
    "\n",
    "This equation calculates the state fidelity, $ F_s $, which measures the similarity between the ideal probability distribution $ P_{\\text{ideal}} $ and the output probability distribution $ P_{\\text{output}} $. The square root of the product of probabilities for each state $ x $ is summed, and the result is squared to get the fidelity.\n",
    "\n",
    "### Equation (2): Normalized Fidelity\n",
    "$$ F(P_{\\text{ideal}}, P_{\\text{output}}) = \\max(F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}), 0) $$\n",
    "\n",
    "This equation defines the normalized fidelity, $ F $, which ensures that the fidelity is non-negative. It takes the raw fidelity $ F_{\\text{raw}} $ and applies a max function to ensure the result is at least 0.\n",
    "\n",
    "### Equation (3): Raw Fidelity\n",
    "$$ F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}) = \\frac{F_s (P_{\\text{ideal}}, P_{\\text{output}}) - F_s (P_{\\text{ideal}}, P_{\\text{uni}})}{1 - F_s (P_{\\text{ideal}}, P_{\\text{uni}})} $$\n",
    "\n",
    "The raw fidelity $ F_{\\text{raw}} $ adjusts the state fidelity by comparing it to a uniform distribution $ P_{\\text{uni}} $. This adjustment accounts for the baseline performance of random guessing.\n",
    "\n",
    "- $ P_{\\text{uni}} $: A uniform probability distribution where all states are equally probable.\n",
    "\n",
    "### Explanation with Example\n",
    "\n",
    "Let's consider a simple example with 2 qubits.\n",
    "\n",
    "#### 1. State Fidelity Calculation\n",
    "- **Ideal distribution ($ P_{\\text{ideal}} $)**: \\{ \"00\": 0.25, \"01\": 0.25, \"10\": 0.25, \"11\": 0.25 \\}\n",
    "- **Output distribution ($ P_{\\text{output}} $)**: \\{ \"00\": 0.5, \"01\": 0.25, \"10\": 0.25, \"11\": 0.0 \\}\n",
    "\n",
    "First, compute $ F_s (P_{\\text{ideal}}, P_{\\text{output}}) $:\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( \\sqrt{0.5} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.0} \\cdot \\sqrt{0.25} \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( 0.3536 + 0.25 + 0.25 + 0 \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = \\left( 0.8536 \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{output}}) = 0.7286 $$\n",
    "\n",
    "#### 2. Uniform Distribution Fidelity\n",
    "- **Uniform distribution ($ P_{\\text{uni}} $)**: \\{ \"00\": 0.25, \"01\": 0.25, \"10\": 0.25, \"11\": 0.25 \\}\n",
    "\n",
    "Compute $ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) $:\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) = \\left( \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} + \\sqrt{0.25} \\cdot \\sqrt{0.25} \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) = \\left( 0.25 + 0.25 + 0.25 + 0.25 \\right)^2 $$\n",
    "$$ F_s (P_{\\text{ideal}}, P_{\\text{uni}}) = 1.0 $$\n",
    "\n",
    "#### 3. Raw Fidelity Calculation\n",
    "$$ F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}) = \\frac{0.7286 - 1.0}{1 - 1.0} $$\n",
    "$$ F_{\\text{raw}}(P_{\\text{ideal}}, P_{\\text{output}}) = \\frac{-0.2714}{0} $$\n",
    "Since dividing by zero is undefined, we need to handle this case. If the uniform distribution fidelity is 1, raw fidelity is set to -1.\n",
    "\n",
    "#### 4. Normalized Fidelity Calculation\n",
    "$$ F(P_{\\text{ideal}}, P_{\\text{output}}) = \\max(-1, 0) $$\n",
    "$$ F(P_{\\text{ideal}}, P_{\\text{output}}) = 0 $$\n",
    "\n",
    "In this example, the normalized fidelity is 0, indicating that the output distribution is no better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7d14a-92ee-46f4-bff2-0ce6de620c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions of Volumetric Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f39ea1-f924-4b81-9ad0-5d8b785912a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "############### Color Map functions\n",
    " \n",
    "# Create a selection of colormaps from which to choose; default to custom_spectral\n",
    "cmap_spectral = plt.get_cmap('Spectral')\n",
    "cmap_greys = plt.get_cmap('Greys')\n",
    "cmap_blues = plt.get_cmap('Blues')\n",
    "cmap_custom_spectral = None\n",
    "\n",
    "# the default colormap is the spectral map\n",
    "cmap = cmap_spectral\n",
    "cmap_orig = cmap_spectral\n",
    "\n",
    "# current cmap normalization function (default None)\n",
    "cmap_norm = None\n",
    "\n",
    "default_fade_low_fidelity_level = 0.16\n",
    "default_fade_rate = 0.7\n",
    "\n",
    "\n",
    "# Specify a normalization function here (default None)\n",
    "def set_custom_cmap_norm(vmin, vmax):\n",
    "\n",
    "    global cmap_norm\n",
    "    \n",
    "    if vmin == vmax or (vmin == 0.0 and vmax == 1.0):\n",
    "        print(\"... setting cmap norm to None\")\n",
    "        cmap_norm = None\n",
    "    else:\n",
    "        print(f\"... setting cmap norm to [{vmin}, {vmax}]\")\n",
    "        cmap_norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "# Remake the custom spectral colormap with user settings\n",
    "def set_custom_cmap_style(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "            \n",
    "    #print(\"... set custom map style\")\n",
    "    global cmap, cmap_custom_spectral, cmap_orig\n",
    "    cmap_custom_spectral = create_custom_spectral_cmap(\n",
    "                fade_low_fidelity_level=fade_low_fidelity_level, fade_rate=fade_rate)\n",
    "    cmap = cmap_custom_spectral\n",
    "    cmap_orig = cmap_custom_spectral\n",
    "\n",
    "\n",
    "# Create the custom spectral colormap from the base spectral\n",
    "def create_custom_spectral_cmap(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "\n",
    "    # determine the breakpoint from the fade level\n",
    "    num_colors = 100\n",
    "    breakpoint = round(fade_low_fidelity_level * num_colors)\n",
    "    \n",
    "    # get color list for spectral map\n",
    "    spectral_colors = [cmap_spectral(v/num_colors) for v in range(num_colors)]\n",
    "\n",
    "    #print(fade_rate)\n",
    "    \n",
    "    # create a list of colors to replace those below the breakpoint\n",
    "    # and fill with \"faded\" color entries (in reverse)\n",
    "    low_colors = [0] * breakpoint\n",
    "    #for i in reversed(range(breakpoint)):\n",
    "    for i in range(breakpoint):\n",
    "    \n",
    "        # x is index of low colors, normalized 0 -> 1\n",
    "        x = i / breakpoint\n",
    "    \n",
    "        # get color at this index\n",
    "        bc = spectral_colors[i]\n",
    "        r0 = bc[0]\n",
    "        g0 = bc[1]\n",
    "        b0 = bc[2]\n",
    "        z0 = bc[3]\n",
    "        \n",
    "        r_delta = 0.92 - r0\n",
    "        \n",
    "        #print(f\"{x} {bc} {r_delta}\")\n",
    "         \n",
    "        # compute saturation and greyness ratio\n",
    "        sat_ratio = 1 - x\n",
    "        \n",
    "        #grey_ratio = 1 - x\n",
    "        '''  attempt at a reflective gradient   \n",
    "        if i >= breakpoint/2:\n",
    "            xf = 2*(x - 0.5)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (yf + 0.5)\n",
    "        else:\n",
    "            xf = 2*(0.5 - x)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (0.5 - yf)\n",
    "        '''   \n",
    "        grey_ratio = 1 - math.pow(x, 1/fade_rate)\n",
    "        \n",
    "        #print(f\"  {xf} {yf} \")\n",
    "        #print(f\"  {sat_ratio} {grey_ratio}\")\n",
    "\n",
    "        r = r0 + r_delta * sat_ratio\n",
    "        \n",
    "        g_delta = r - g0\n",
    "        b_delta = r - b0\n",
    "        g = g0 + g_delta * grey_ratio\n",
    "        b = b0 + b_delta * grey_ratio \n",
    "            \n",
    "        #print(f\"{r} {g} {b}\\n\")    \n",
    "        low_colors[i] = (r,g,b,z0)\n",
    "        \n",
    "    #print(low_colors)\n",
    "\n",
    "    # combine the faded low colors with the regular spectral cmap to make a custom version\n",
    "    cmap_custom_spectral = ListedColormap(low_colors + spectral_colors[breakpoint:])\n",
    "\n",
    "    #spectral_colors = [cmap_custom_spectral(v/10) for v in range(10)]\n",
    "    #for i in range(10): print(spectral_colors[i])\n",
    "    #print(\"\")\n",
    "    \n",
    "    return cmap_custom_spectral\n",
    "\n",
    "# Make the custom spectral color map the default on module init\n",
    "set_custom_cmap_style()\n",
    "\n",
    "# Arrange the stored annotations optimally and add to plot \n",
    "def anno_volumetric_data(ax, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True):\n",
    "    \n",
    "    # sort all arrays by the x point of the text (anno_offs)\n",
    "    global x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos\n",
    "    all_annos = sorted(zip(x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos))\n",
    "    x_anno_offs = [a for a,b,c,d,e in all_annos]\n",
    "    y_anno_offs = [b for a,b,c,d,e in all_annos]\n",
    "    anno_labels = [c for a,b,c,d,e in all_annos]\n",
    "    x_annos = [d for a,b,c,d,e in all_annos]\n",
    "    y_annos = [e for a,b,c,d,e in all_annos]\n",
    "    \n",
    "    #print(f\"{x_anno_offs}\")\n",
    "    #print(f\"{y_anno_offs}\")\n",
    "    #print(f\"{anno_labels}\")\n",
    "    \n",
    "    for i in range(len(anno_labels)):\n",
    "        x_anno = x_annos[i]\n",
    "        y_anno = y_annos[i]\n",
    "        x_anno_off = x_anno_offs[i]\n",
    "        y_anno_off = y_anno_offs[i]\n",
    "        label = anno_labels[i]\n",
    "        \n",
    "        if i > 0:\n",
    "            x_delta = abs(x_anno_off - x_anno_offs[i - 1])\n",
    "            y_delta = abs(y_anno_off - y_anno_offs[i - 1])\n",
    "            \n",
    "            if y_delta < 0.7 and x_delta < 2:\n",
    "                y_anno_off = y_anno_offs[i] = y_anno_offs[i - 1] - 0.6\n",
    "                #x_anno_off = x_anno_offs[i] = x_anno_offs[i - 1] + 0.1\n",
    "                    \n",
    "        ax.annotate(label,\n",
    "            xy=(x_anno+0.0, y_anno+0.1),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.0,\n",
    "                width=0.5, headwidth=4, headlength=5, edgecolor=(0.8,0.8,0.8)),\n",
    "            xytext=(x_anno_off + labelpos[0], y_anno_off + labelpos[1]),\n",
    "            rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='baseline',\n",
    "            color=(0.2,0.2,0.2),\n",
    "            clip_on=True)\n",
    "    if saveplots == True:\n",
    "        plt.savefig(\"VolumetricPlotSample.jpg\")\n",
    "\n",
    "# Plot one group of data for volumetric presentation    \n",
    "def plot_volumetric_data(ax, w_data, d_data, f_data, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True, w_max=18, do_label=False, do_border=True,\n",
    "        x_size=1.0, y_size=1.0, zorder=1, offset_flag=False,\n",
    "        max_depth=0, suppress_low_fidelity=False):\n",
    "\n",
    "    # since data may come back out of order, save point at max y for annotation\n",
    "    i_anno = 0\n",
    "    x_anno = 0 \n",
    "    y_anno = 0\n",
    "    \n",
    "    # plot data rectangles\n",
    "    low_fidelity_count = True\n",
    "    \n",
    "    last_y = -1\n",
    "    k = 0\n",
    "\n",
    "    # determine y-axis dimension for one pixel to use for offset of bars that start at 0\n",
    "    (_, dy) = get_pixel_dims(ax)\n",
    "    \n",
    "    # do this loop in reverse to handle the case where earlier cells are overlapped by later cells\n",
    "    for i in reversed(range(len(d_data))):\n",
    "        x = depth_index(d_data[i], depth_base)\n",
    "        y = float(w_data[i])\n",
    "        f = f_data[i]\n",
    "        \n",
    "        # each time we star a new row, reset the offset counter\n",
    "        # DEVNOTE: this is highly specialized for the QA area plots, where there are 8 bars\n",
    "        # that represent time starting from 0 secs.  We offset by one pixel each and center the group\n",
    "        if y != last_y:\n",
    "            last_y = y;\n",
    "            k = 3              # hardcoded for 8 cells, offset by 3\n",
    "        \n",
    "        #print(f\"{i = } {x = } {y = }\")\n",
    "        \n",
    "        if max_depth > 0 and d_data[i] > max_depth:\n",
    "            #print(f\"... excessive depth (2), skipped; w={y} d={d_data[i]}\")\n",
    "            break;\n",
    "            \n",
    "        # reject cells with low fidelity\n",
    "        if suppress_low_fidelity and f < suppress_low_fidelity_level:\n",
    "            if low_fidelity_count: break\n",
    "            else: low_fidelity_count = True\n",
    "        \n",
    "        # the only time this is False is when doing merged gradation plots\n",
    "        if do_border == True:\n",
    "        \n",
    "            # this case is for an array of x_sizes, i.e. each box has different width\n",
    "            if isinstance(x_size, list):\n",
    "                \n",
    "                # draw each of the cells, with no offset\n",
    "                if not offset_flag:\n",
    "                    ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size[i], y_size=y_size, zorder=zorder))\n",
    "                    \n",
    "                # use an offset for y value, AND account for x and width to draw starting at 0\n",
    "                else:\n",
    "                    ax.add_patch(box_at((x/2 + x_size[i]/4), y + k*dy, f, type=type, fill=fill, x_size=x+ x_size[i]/2, y_size=y_size, zorder=zorder))\n",
    "                \n",
    "            # this case is for only a single cell\n",
    "            else:\n",
    "                ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size, y_size=y_size))\n",
    "\n",
    "        # save the annotation point with the largest y value\n",
    "        if y >= y_anno:\n",
    "            x_anno = x\n",
    "            y_anno = y\n",
    "            i_anno = i\n",
    "        \n",
    "        # move the next bar down (if using offset)\n",
    "        k -= 1\n",
    "    \n",
    "    # if no data rectangles plotted, no need for a label\n",
    "    if x_anno == 0 or y_anno == 0:\n",
    "        return\n",
    "        \n",
    "    x_annos.append(x_anno)\n",
    "    y_annos.append(y_anno)\n",
    "    \n",
    "    anno_dist = math.sqrt( (y_anno - 1)**2 + (x_anno - 1)**2 )\n",
    "    \n",
    "    # adjust radius of annotation circle based on maximum width of apps\n",
    "    anno_max = 10\n",
    "    if w_max > 10:\n",
    "        anno_max = 14\n",
    "    if w_max > 14:\n",
    "        anno_max = 18\n",
    "        \n",
    "    scale = anno_max / anno_dist\n",
    "\n",
    "    # offset of text from end of arrow\n",
    "    if scale > 1:\n",
    "        x_anno_off = scale * x_anno - x_anno - 0.5\n",
    "        y_anno_off = scale * y_anno - y_anno\n",
    "    else:\n",
    "        x_anno_off = 0.7\n",
    "        y_anno_off = 0.5\n",
    "        \n",
    "    x_anno_off += x_anno\n",
    "    y_anno_off += y_anno\n",
    "    \n",
    "    # print(f\"... {xx} {yy} {anno_dist}\")\n",
    "    x_anno_offs.append(x_anno_off)\n",
    "    y_anno_offs.append(y_anno_off)\n",
    "    \n",
    "    anno_labels.append(label)\n",
    "    \n",
    "    if do_label:\n",
    "        ax.annotate(label, xy=(x_anno+labelpos[0], y_anno+labelpos[1]), rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='bottom', color=(0.2,0.2,0.2))\n",
    "\n",
    "x_annos = []\n",
    "y_annos = []\n",
    "x_anno_offs = []\n",
    "y_anno_offs = []\n",
    "anno_labels = []\n",
    "\n",
    "# init arrays to hold annotation points for label spreading\n",
    "def vplot_anno_init ():\n",
    "\n",
    "    global x_annos, y_annos, x_anno_offs, y_anno_offs, anno_labels\n",
    "    \n",
    "    x_annos = []\n",
    "    y_annos = []\n",
    "    x_anno_offs = []\n",
    "    y_anno_offs = []\n",
    "    anno_labels = []\n",
    "\n",
    "# Number of ticks on volumetric depth axis\n",
    "max_depth_log = 22\n",
    "\n",
    "# average transpile factor between base QV depth and our depth based on results from QV notebook\n",
    "QV_transpile_factor = 12.7 \n",
    "\n",
    "# format a number using K,M,B,T for large numbers, optionally rounding to 'digits' decimal places if num > 1\n",
    "# (sign handling may be incorrect)\n",
    "def format_number(num, digits=0):\n",
    "    if isinstance(num, str): num = float(num)\n",
    "    num = float('{:.3g}'.format(abs(num)))\n",
    "    sign = ''\n",
    "    metric = {'T': 1000000000000, 'B': 1000000000, 'M': 1000000, 'K': 1000, '': 1}\n",
    "    for index in metric:\n",
    "        num_check = num / metric[index]\n",
    "        if num_check >= 1:\n",
    "            num = round(num_check, digits)\n",
    "            sign = index\n",
    "            break\n",
    "    numstr = f\"{str(num)}\"\n",
    "    if '.' in numstr:\n",
    "        numstr = numstr.rstrip('0').rstrip('.')\n",
    "    return f\"{numstr}{sign}\"\n",
    "\n",
    "# Return the color associated with the spcific value, using color map norm\n",
    "def get_color(value):\n",
    "    \n",
    "    # if there is a normalize function installed, scale the data\n",
    "    if cmap_norm:\n",
    "        value = float(cmap_norm(value))\n",
    "        \n",
    "    if cmap == cmap_spectral:\n",
    "        value = 0.05 + value*0.9\n",
    "    elif cmap == cmap_blues:\n",
    "        value = 0.00 + value*1.0\n",
    "    else:\n",
    "        value = 0.0 + value*0.95\n",
    "        \n",
    "    return cmap(value)\n",
    "\n",
    "# Return the x and y equivalent to a single pixel for the given plot axis\n",
    "def get_pixel_dims(ax):\n",
    "\n",
    "    # transform 0 -> 1 to pixel dimensions\n",
    "    pixdims = ax.transData.transform([(0,1),(1,0)])-ax.transData.transform((0,0))\n",
    "    xpix = pixdims[1][0]\n",
    "    ypix = pixdims[0][1]\n",
    "    \n",
    "    #determine x- and y-axis dimension for one pixel \n",
    "    dx = (1 / xpix)\n",
    "    dy = (1 / ypix)\n",
    "    \n",
    "    return (dx, dy)\n",
    "\n",
    "############### Helper functions\n",
    " \n",
    "# return the base index for a circuit depth value\n",
    "# take the log in the depth base, and add 1\n",
    "def depth_index(d, depth_base):\n",
    "    if depth_base <= 1:\n",
    "        return d\n",
    "    if d == 0:\n",
    "        return 0\n",
    "    return math.log(d, depth_base) + 1\n",
    "\n",
    "# draw a box at x,y with various attributes   \n",
    "def box_at(x, y, value, type=1, fill=True, x_size=1.0, y_size=1.0, alpha=1.0, zorder=1):\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Rectangle((x - (x_size/2), y - (y_size/2)), x_size, y_size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5*y_size,\n",
    "             zorder=zorder)\n",
    "\n",
    "# draw a circle at x,y with various attributes \n",
    "def circle_at(x, y, value, type=1, fill=True):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Circle((x, y), size/2,\n",
    "             alpha = 0.7,                       # DEVNOTE: changed to 0.7 from 0.5, to handle only one cell\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5)\n",
    "             \n",
    "def box4_at(x, y, value, type=1, fill=True, alpha=1.0):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.3,0.3,0.3)\n",
    "    ec = fc\n",
    "    \n",
    "    return Rectangle((x - size/8, y - size/2), size/4, size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.1)\n",
    "\n",
    "# Draw a Quantum Volume rectangle with specified width and depth, and grey-scale value \n",
    "def qv_box_at(x, y, qv_width, qv_depth, value, depth_base):\n",
    "    #print(f\"{qv_width} {qv_depth} {depth_index(qv_depth, depth_base)}\")\n",
    "    return Rectangle((x - 0.5, y - 0.5), depth_index(qv_depth, depth_base), qv_width,\n",
    "             edgecolor = (value,value,value),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=1)\n",
    "\n",
    "def bkg_box_at(x, y, value=0.9):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "             \n",
    "def bkg_empty_box_at(x, y):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (1.0,1.0,1.0),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "\n",
    "# Plot the background for the volumetric analysis    \n",
    "def plot_volumetric_background(max_qubits=11, QV=32, depth_base=2, suptitle=None, avail_qubits=0, colorbar_label=\"Avg Result Fidelity\"):\n",
    "\n",
    "    if suptitle == None:\n",
    "        suptitle = f\"Volumetric Positioning\\nCircuit Dimensions and Fidelity Overlaid on Quantum Volume = {QV}\"\n",
    "\n",
    "    QV0 = QV\n",
    "    qv_estimate = False\n",
    "    est_str = \"\"\n",
    "    if QV == 0:                 # QV = 0 indicates \"do not draw QV background or label\"\n",
    "        QV = 2048\n",
    "        \n",
    "    elif QV < 0:                # QV < 0 indicates \"add est. to label\"\n",
    "        QV = -QV\n",
    "        qv_estimate = True\n",
    "        est_str = \" (est.)\"\n",
    "        \n",
    "    if avail_qubits > 0 and max_qubits > avail_qubits:\n",
    "        max_qubits = avail_qubits\n",
    "        \n",
    "    max_width = 13\n",
    "    if max_qubits > 11: max_width = 18\n",
    "    if max_qubits > 14: max_width = 20\n",
    "    if max_qubits > 16: max_width = 24\n",
    "    if max_qubits > 24: max_width = 33\n",
    "    #print(f\"... {avail_qubits} {max_qubits} {max_width}\")\n",
    "    \n",
    "    plot_width = 6.8\n",
    "    plot_height = 0.5 + plot_width * (max_width / max_depth_log)\n",
    "    #print(f\"... {plot_width} {plot_height}\")\n",
    "    \n",
    "    # define matplotlib figure and axis; use constrained layout to fit colorbar to right\n",
    "    fig, ax = plt.subplots(figsize=(plot_width, plot_height), constrained_layout=True)\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    plt.xlim(0, max_depth_log)\n",
    "    plt.ylim(0, max_width)\n",
    "\n",
    "    # circuit depth axis (x axis)\n",
    "    xbasis = [x for x in range(1,max_depth_log)]\n",
    "    xround = [depth_base**(x-1) for x in xbasis]\n",
    "    xlabels = [format_number(x) for x in xround]\n",
    "    ax.set_xlabel('Circuit Depth')\n",
    "    ax.set_xticks(xbasis)  \n",
    "    plt.xticks(xbasis, xlabels, color='black', rotation=45, ha='right', va='top', rotation_mode=\"anchor\")\n",
    "    \n",
    "    # other label options\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-60, ha='left')\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-45, ha='left', va='center', rotation_mode=\"anchor\")\n",
    "\n",
    "    # circuit width axis (y axis)\n",
    "    ybasis = [y for y in range(1,max_width)]\n",
    "    yround = [1,2,3,4,5,6,7,8,10,12,15]     # not used now\n",
    "    ylabels = [str(y) for y in yround]      # not used now \n",
    "    #ax.set_ylabel('Circuit Width (Number of Qubits)')\n",
    "    ax.set_ylabel('Circuit Width')\n",
    "    ax.set_yticks(ybasis)\n",
    "\n",
    "    #create simple line plot (not used right now)\n",
    "    #ax.plot([0, 10],[0, 10])\n",
    "    \n",
    "    log2QV = math.log2(QV)\n",
    "    QV_width = log2QV\n",
    "    QV_depth = log2QV * QV_transpile_factor\n",
    "    \n",
    "    # show a quantum volume rectangle of QV = 64 e.g. (6 x 6)\n",
    "    if QV0 != 0:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.87, depth_base))\n",
    "    else:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.91, depth_base))\n",
    "    \n",
    "    # the untranspiled version is commented out - we do not show this by default\n",
    "    # also show a quantum volume rectangle un-transpiled\n",
    "    # ax.add_patch(qv_box_at(1, 1, QV_width, QV_width, 0.80, depth_base))\n",
    "\n",
    "    # show 2D array of volumetric cells based on this QV_transpiled\n",
    "    # DEVNOTE: we use +1 only to make the visuals work; s/b without\n",
    "    # Also, the second arg of the min( below seems incorrect, needs correction\n",
    "    maxprod = (QV_width + 1) * (QV_depth + 1)\n",
    "    for w in range(1, min(max_width, round(QV) + 1)):\n",
    "        \n",
    "        # don't show VB squares if width greater than known available qubits\n",
    "        if avail_qubits != 0 and w > avail_qubits:\n",
    "            continue\n",
    "        \n",
    "        i_success = 0\n",
    "        for d in xround:\n",
    "        \n",
    "            # polarization factor for low circuit widths\n",
    "            maxtest = maxprod / ( 1 - 1 / (2**w) )\n",
    "            \n",
    "            # if circuit would fail here, don't draw box\n",
    "            if d > maxtest: continue\n",
    "            if w * d > maxtest: continue\n",
    "            \n",
    "            # guess for how to capture how hardware decays with width, not entirely correct\n",
    "\n",
    "            # # reduce maxtext by a factor of number of qubits > QV_width\n",
    "            # # just an approximation to account for qubit distances\n",
    "            # if w > QV_width:\n",
    "            #     over = w - QV_width \n",
    "            #     maxtest = maxtest / (1 + (over/QV_width))\n",
    "\n",
    "            # draw a box at this width and depth\n",
    "            id = depth_index(d, depth_base) \n",
    "            \n",
    "            # show vb rectangles; if not showing QV, make all hollow (or less dark)\n",
    "            if QV0 == 0:\n",
    "                #ax.add_patch(bkg_empty_box_at(id, w))\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.95))\n",
    "            \n",
    "            else:\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.9))\n",
    "            \n",
    "            # save index of last successful depth\n",
    "            i_success += 1\n",
    "        \n",
    "        # plot empty rectangle after others       \n",
    "        d = xround[i_success]\n",
    "        id = depth_index(d, depth_base) \n",
    "        ax.add_patch(bkg_empty_box_at(id, w))\n",
    "        \n",
    "    \n",
    "    # Add annotation showing quantum volume\n",
    "    if QV0 != 0:\n",
    "        t = ax.text(max_depth_log - 2.0, 1.5, f\"QV{est_str}={QV}\", size=12,\n",
    "                horizontalalignment='right', verticalalignment='center', color=(0.2,0.2,0.2),\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=(.9,.9,.9), ec=\"grey\", lw=1))\n",
    "                \n",
    "    # add colorbar to right of plot\n",
    "    plt.colorbar(cm.ScalarMappable(cmap=cmap), cax=None, ax=ax,\n",
    "            shrink=0.6, label=colorbar_label, panchor=(0.0, 0.7))\n",
    "            \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c7b52-ddf0-4331-bded-4cf824ccbe83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Benchmarking Essentials and Fidelity Plots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ffdf2-b8d2-404a-aff2-0775e40c1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate circuit depth\n",
    "def calculate_circuit_depth(qc):\n",
    "    # Calculate the depth of the circuit\n",
    "    depth = qc.depth\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0490105-27e8-443d-9d83-6f6ef17b1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fidelity_data(fidelity_data, Hf_fidelity_data, title):\n",
    "    avg_fidelity_means = []\n",
    "    avg_Hf_fidelity_means = []\n",
    "    std_f = []\n",
    "    std_hf = []\n",
    "    avg_num_qubits_values = list(fidelity_data.keys())\n",
    "    \n",
    "    # Calculate the average fidelity and Hamming fidelity for each unique number of qubits\n",
    "    for num_qubits in avg_num_qubits_values:\n",
    "        avg_fidelity = round(np.average(fidelity_data[num_qubits]),2)\n",
    "        avg_fidelity_means.append(avg_fidelity)\n",
    "        std_fidelity = round(np.std(fidelity_data[num_qubits])/np.sqrt(len(fidelity_data)), 3)\n",
    "        std_f.append(std_fidelity)\n",
    "        avg_Hf_fidelity = round(np.mean(Hf_fidelity_data[num_qubits]),2)\n",
    "        avg_Hf_fidelity_means.append(avg_Hf_fidelity)\n",
    "        std_Hfidelity = round(np.std(Hf_fidelity_data[num_qubits])/np.sqrt(len(Hf_fidelity_data)), 3)\n",
    "        std_hf.append(std_Hfidelity)\n",
    "    \n",
    "    return avg_fidelity_means,avg_Hf_fidelity_means,std_f,std_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede6470-47df-413f-9795-a590d47d79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory():\n",
    "    import resource\n",
    "    usage = resource.getrusage(resource.RUSAGE_SELF)\n",
    "    max_mem = usage.ru_maxrss/1024 #in MB\n",
    "    return max_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fc8cb-3402-4966-b5b8-2e9c0c9bed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count gate occurrences\n",
    "def count_gates(circuit):\n",
    "    gate_counts = {}\n",
    "    for instruction in circuit.instructions:\n",
    "        gate_name = instruction.operator\n",
    "        if gate_name not in gate_counts:\n",
    "            gate_counts[gate_name] = 1\n",
    "        else:\n",
    "            gate_counts[gate_name] += 1\n",
    "    return gate_counts\n",
    "\n",
    "def get_gate_counts(qc):\n",
    "    operations = count_gates(qc)\n",
    "    #print(\"Operations-Before =\",operations)\n",
    "    transformed_operations = {}\n",
    "    for k,v in operations.items():\n",
    "        if isinstance(k,Gate):\n",
    "            num_qbits=k.qubit_count\n",
    "            transformed_operations[k.name] = {'count': v, 'num_qubits': num_qbits}\n",
    "    return transformed_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127682e0-50b3-47bf-ae0a-d0cc65610bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_excel_with_data(filename, data_to_excel, noise_inclusion=False):\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        from openpyxl import load_workbook, Workbook\n",
    "        from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "        from openpyxl.styles import Alignment, PatternFill\n",
    "    except ImportError:\n",
    "        import pip\n",
    "        pip.main(['install', 'openpyxl','pandas'])\n",
    "        import pandas as pd\n",
    "        from openpyxl import load_workbook, Workbook\n",
    "        from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "        from openpyxl.styles import Alignment, PatternFill\n",
    "\n",
    "    config = data_to_excel['configuration']\n",
    "    del data_to_excel['configuration']\n",
    "    gate_counts_plots = data_to_excel[\"gate_counts_plots\"]\n",
    "    del data_to_excel[\"gate_counts_plots\"]\n",
    "    min_qubits=config['min_qbits']\n",
    "    max_qubits=config['max_qbits']\n",
    "    skip_qubits=config['skp_qubits']\n",
    "    num_ckts = config['num_ckts']\n",
    "    qv = config['QV_']\n",
    "    simulator_type= config['Type_of_Simulator']\n",
    "    benchmark_name = config['benchmark_name']\n",
    "    Processor = config['Processor']\n",
    "    Cores = config['cores']\n",
    "    last_updated = data_to_excel['last_updated']\n",
    "    del data_to_excel['last_updated']\n",
    "    #print(data_to_excel)\n",
    "    df = pd.DataFrame(data_to_excel)\n",
    "    \n",
    "    # Load the workbook if it exists, otherwise create a new one\n",
    "    try:\n",
    "        workbook = load_workbook(filename)\n",
    "        if simulator_type in workbook.sheetnames:\n",
    "            worksheet = workbook[simulator_type]\n",
    "        else:\n",
    "            worksheet = workbook.create_sheet(simulator_type)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        workbook = Workbook()\n",
    "        worksheet = workbook.active\n",
    "        worksheet.title = simulator_type\n",
    "\n",
    "    # Add an empty row for separation\n",
    "    worksheet.append([''] * len(df.columns))\n",
    "     \n",
    "    title_row = [f'AWS-Braket: Algorithm = {benchmark_name} Simulator = {simulator_type}']\n",
    "    worksheet.append(title_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the title row\n",
    "    title_cell_range = f'A{worksheet.max_row}:T{worksheet.max_row}'\n",
    "    worksheet.merge_cells(title_cell_range)\n",
    "\n",
    "    HW_row = [f'CPU: {Processor} with {cores} cores']\n",
    "    worksheet.append(HW_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the title row\n",
    "    HW_cell_range = f'A{worksheet.max_row}:T{worksheet.max_row}'\n",
    "    worksheet.merge_cells(HW_cell_range)\n",
    "\n",
    "    if noise_inclusion ==  True and simulator_type=='DensityMatrixSimulator':\n",
    "        noise_row = [f\"Executing with Noise\"]\n",
    "        worksheet.append(noise_row + [''] * (len(df.columns) - 1))\n",
    "        # Merge cells for the title row\n",
    "        noise_cell_range = f'A{worksheet.max_row}:T{worksheet.max_row}'\n",
    "        worksheet.merge_cells(noise_cell_range)\n",
    "            \n",
    "    # Add the configuration row spanning all columns\n",
    "    config_row = [f'Configuration: Min_Qubits = {min_qubits} Max_Qubits = {max_qubits} Skip_Qubits = {skip_qubits} num_circuits = {num_ckts[0]}  QV_ = {qv} Last_Updated = {last_updated}']\n",
    "    worksheet.append(config_row + [''] * (len(df.columns) - 1))\n",
    "    \n",
    "    # Merge cells for the configuration row\n",
    "    config_cell_range = f'A{worksheet.max_row}:T{worksheet.max_row}'\n",
    "    worksheet.merge_cells(config_cell_range)\n",
    "\n",
    "    # Center align all cells in the worksheet\n",
    "    for row in worksheet.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "    # Append the DataFrame to the worksheet\n",
    "    for r in dataframe_to_rows(df, index=False):\n",
    "        worksheet.append(r)\n",
    "\n",
    "    # Add an empty row for separation\n",
    "    worksheet.append([''] * len(df.columns))\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61543f81-2a04-45d5-8d90-d4534b182179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_info():\n",
    "    try:\n",
    "        import cpuinfo\n",
    "    except ImportError:\n",
    "        import pip\n",
    "        pip.main(['install', 'py-cpuinfo'])\n",
    "        import cpuinfo\n",
    "\n",
    "    cpu_info = cpuinfo.get_cpu_info()\n",
    "    processor = cpu_info['brand_raw']\n",
    "    cores = cpu_info['count']\n",
    "    \n",
    "    return processor, cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a855d-01e3-440f-9d9c-9487e42daa5a",
   "metadata": {},
   "source": [
    "# Analyzer Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea744ed-fe29-40d9-8e0a-ddffe4dd791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(num_qubits):\n",
    "    # we have precalculated the correct distribution that a perfect quantum computer will return\n",
    "    # it is stored in the json file we import at the top of the code\n",
    "    correct_dist = precalculated_data[f\"Qubits - {num_qubits}\"]\n",
    "    return correct_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39b754-8226-4e2a-ad5f-7eb05330ec2a",
   "metadata": {},
   "source": [
    "# RUN Function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b0d25-644b-42bc-b362-7d0fe51cfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_circuits=2\n",
    "def run (min_qubits=min_qubits, max_qubits=max_qubits, skip_qubits=skip_qubits, \n",
    "         max_circuits=max_circuits, num_shots=num_shots):\n",
    "\n",
    "    num_qubits_of_ckt = []\n",
    "    creation_times = []\n",
    "    elapsed_times = []\n",
    "    quantum_times = []\n",
    "    circuit_depths = []\n",
    "    transpiled_depths = []\n",
    "    fidelity_data = {}\n",
    "    Hf_fidelity_data = {}\n",
    "    numckts = []\n",
    "    mem_usage = []\n",
    "    algorithmic_1Q_gate_counts = []\n",
    "    algorithmic_2Q_gate_counts = []\n",
    "    transpiled_1Q_gate_counts = []\n",
    "    transpiled_2Q_gate_counts = []\n",
    "    xi = []\n",
    "    tr_xi = []\n",
    "    \n",
    "    \n",
    "    print(f\"{benchmark_name} Benchmark Program - {device_Name}\")\n",
    "\n",
    "    # validate parameters (smallest circuit is 2 qubits)\n",
    "    max_qubits = max(2, max_qubits)\n",
    "    min_qubits = min(max(2, min_qubits), max_qubits)\n",
    "    if min_qubits % 2 == 1: min_qubits += 1   # min_qubits must be even\n",
    "\n",
    "    if _use_XX_YY_ZZ_gates:\n",
    "        print(\"... using unoptimized XX YY ZZ gates\")\n",
    "\n",
    "    global max_ckts\n",
    "    max_ckts = max_circuits\n",
    "\n",
    "    global min_qbits,max_qbits,skp_qubits\n",
    "\n",
    "    min_qbits = min_qubits\n",
    "    max_qbits = max_qubits\n",
    "    skp_qubits = skip_qubits\n",
    "\n",
    "    print(f\"min, max qubits = {min_qubits} {max_qubits}\")\n",
    "\n",
    "    # Execute Benchmark Program N times for multiple circuit sizes\n",
    "    for num_qubits in range(min_qubits, max_qubits + 1, skip_qubits):\n",
    "        fidelity_data[num_qubits] = []\n",
    "        Hf_fidelity_data[num_qubits] = []\n",
    "        \n",
    "        # determine number of circuits to execute for this group\n",
    "        num_circuits = min(1, max_circuits)\n",
    "        print(f\"Executing [{num_circuits}] circuits with num_qubits = {num_qubits}\")\n",
    "        numckts.append(num_circuits)\n",
    "\n",
    "        # parameters of simulation\n",
    "        #### CANNOT BE MODIFIED W/O ALSO MODIFYING PRECALCULATED DATA #########\n",
    "        w = precalculated_data['w']  # strength of disorder\n",
    "        k = precalculated_data['k']  # Trotter error.\n",
    "               # A large Trotter order approximates the Hamiltonian evolution better.\n",
    "               # But a large Trotter order also means the circuit is deeper.\n",
    "               # For ideal or noise-less quantum circuits, k >> 1 gives perfect hamiltonian simulation.\n",
    "        t = precalculated_data['t']  # time of simulation\n",
    "        #######################################################################\n",
    "        \n",
    "        # loop over only 1 circuit\n",
    "        for circuit_id in range(num_circuits):\n",
    "            print(\"*********************************************\")\n",
    "            print(f\"qc of {circuit_id}\")\n",
    "\n",
    "            #creation of Quantum Circuit.\n",
    "            ts = time.time()\n",
    "            h_x = precalculated_data['h_x'][:num_qubits] # precalculated random numbers between [-1, 1]\n",
    "            h_z = precalculated_data['h_z'][:num_qubits]\n",
    "            qc = HamiltonianSimulation(num_qubits, K=k, t=t, w=w, h_x= h_x, h_z=h_z)\n",
    "            #print(qc)\n",
    "            \n",
    "            #creation time\n",
    "            creation_time = (time.time() - ts)*1000\n",
    "            creation_times.append(creation_time)\n",
    "            #print(qc)\n",
    "            print(f\"creation time = {creation_time} ms\")\n",
    "            num_qubits_of_ckt.append(qc.qubit_count)\n",
    "            \n",
    "            #algorithmic Gate Counts (if required)\n",
    "            n1q,n2q = 0,0\n",
    "            if gate_counts_plots == True:\n",
    "                operations = get_gate_counts(qc)\n",
    "                #print(\"Operations-After = \",operations)\n",
    "                for k,v in operations.items():\n",
    "                    temp = v\n",
    "                    if temp[\"num_qubits\"]>1:\n",
    "                        n2q += temp[\"count\"]\n",
    "                    else:\n",
    "                        n1q += temp[\"count\"]\n",
    "                        \n",
    "                xi_value = n2q/(n1q+n2q)\n",
    "                xi.append(xi_value)\n",
    "                algorithmic_1Q_gate_counts.append(n1q)\n",
    "                algorithmic_2Q_gate_counts.append(n2q)\n",
    "                \n",
    "                \n",
    "            # Calculate circuit depth\n",
    "            depth = calculate_circuit_depth(qc)\n",
    "            circuit_depths.append(depth)\n",
    "\n",
    "            #calculate transpiled depth\n",
    "            transpiled_depth = depth\n",
    "            transpiled_depths.append(transpiled_depth)\n",
    "\n",
    "            print(f\"Algorithmic Depth = {depth} and Normalized Depth = {transpiled_depth}\")\n",
    "            \n",
    "            #Transpiled Gate Counts\n",
    "            tr_n1q,tr_n2q = 0,0\n",
    "            if gate_counts_plots == True:\n",
    "                operations = get_gate_counts(qc)\n",
    "                #print(\"Operations-After = \",operations)\n",
    "                for k,v in operations.items():\n",
    "                    temp = v\n",
    "                    if temp[\"num_qubits\"]>1:\n",
    "                        tr_n2q += temp[\"count\"]\n",
    "                    else:\n",
    "                        tr_n1q += temp[\"count\"]\n",
    "                        \n",
    "                tr_xi_value =tr_n2q/(tr_n1q+tr_n2q) \n",
    "                tr_xi.append(tr_xi_value)\n",
    "                transpiled_1Q_gate_counts.append(tr_n1q)\n",
    "                transpiled_2Q_gate_counts.append(tr_n2q)\n",
    "\n",
    "                print(f\"Algorithmic 1Q gates = {n1q} ,Algorithmic 2Q gates = {n2q}, xi = {xi_value}\")\n",
    "                print(f\"Normalized 1Q gates = {tr_n1q} ,Normalized 2Q gates = {tr_n2q}, tr_xi = {tr_xi_value}\")\n",
    "\n",
    "            \n",
    "            if Noise_Inclusion == True and backend_id == 'braket_dm':\n",
    "                print(f\".... Adding Noise for {device_Name} device ....\")\n",
    "                qc= qc.apply_gate_noise(noise_parameters)\n",
    "                \n",
    "            #execution\n",
    "            ts = time.time()\n",
    "            \n",
    "            # immediate completion if Local Simulator\n",
    "            result = device.run(qc, shots = num_shots).result()\n",
    "            #print(result)\n",
    "            \n",
    "            # Calculate quantum processing time \n",
    "            quantum_time = (time.time() - ts)*1000\n",
    "            quantum_times.append(quantum_time)\n",
    "            \n",
    "            #calculating elapsed time\n",
    "            elapsed_time = (time.time() - ts)*1000\n",
    "            elapsed_times.append(elapsed_time)\n",
    "\n",
    "            print(f\" Elapsed time = {elapsed_time} ms , Quantum Time = {quantum_time} ms\") \n",
    "\n",
    "            #counts in result object \n",
    "            # obtain shots from the result metadata\n",
    "            num_shots = result.task_metadata.shots\n",
    "            \n",
    "            # obtain counts from the result object\n",
    "            # for braket, need to reverse the key to match binary order\n",
    "            # for braket, measures all qubits, so we have to remove data qubit measurement\n",
    "            counts_r = result.measurement_counts\n",
    "            counts = {}\n",
    "            for measurement_r in counts_r.keys():\n",
    "                measurement = measurement_r[:-1][::-1] # remove data qubit and reverse order\n",
    "                if measurement in counts:\n",
    "                    counts[measurement] += counts_r[measurement_r]\n",
    "                else:\n",
    "                    counts[measurement] = counts_r[measurement_r]\n",
    "            \n",
    "            #print(\"Counts = \",counts)\n",
    "\n",
    "            #Correct distribution to compare with counts\n",
    "            correct_dist = analyze(num_qubits)\n",
    "            #print(\"Correct_dist =\",correct_dist)\n",
    "            \n",
    "            #fidelity calculation comparision of counts and correct_dist \n",
    "            fidelity_dict = polarization_fidelity(counts, correct_dist)\n",
    "            fidelity_data[num_qubits].append(fidelity_dict['fidelity'])\n",
    "            Hf_fidelity_data[num_qubits].append(fidelity_dict['hf_fidelity'])\n",
    "            print(f\"Fidelity : {fidelity_dict}\")\n",
    "            \n",
    "            #maximum memory utilization (if required)\n",
    "            if Memory_utilization_plot == True:\n",
    "                max_mem = get_memory()\n",
    "                print(f\"Maximum Memory Utilized: {max_mem} MB\")\n",
    "                mem_usage.append(max_mem)\n",
    "\n",
    "            print(\"*********************************************\")\n",
    "    \n",
    "    # print a sample circuit\n",
    "    # print(\"Sample Circuit:\"); print(QC_ if QC_ != None else \"  ... too large!\")\n",
    "    # print(\"\\nQuantum Oracle 'Uf' =\"); print(Uf_ if Uf_ != None else \"  ... too large!\")\n",
    "    \n",
    "    return (num_qubits_of_ckt, creation_times, elapsed_times, quantum_times, circuit_depths,transpiled_depths,xi, tr_xi, fidelity_data, Hf_fidelity_data, numckts,  \n",
    "algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts, transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74a319-b5c7-4d24-a75e-def3e1f0bcc0",
   "metadata": {},
   "source": [
    "# Triggering RUN function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a359f7a-e7f6-4cd7-8fb0-3b689f439efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the benchmark program, accumulate metrics, and calculate circuit depths\n",
    "(num_qubits_of_ckt, creation_times, elapsed_times, quantum_times, circuit_depths,transpiled_depths,xi, tr_xi, fidelity_data, Hf_fidelity_data, numckts,  \n",
    "algorithmic_1Q_gate_counts, algorithmic_2Q_gate_counts, transpiled_1Q_gate_counts, transpiled_2Q_gate_counts,mem_usage) = run()\n",
    "\n",
    "# Define the range of qubits for the x-axis\n",
    "num_qubits_range = range(min_qbits, max_qbits+1,skp_qubits)\n",
    "print(\"num_qubits_range =\",num_qubits_range)\n",
    "\n",
    "#Information of Execution Hardware\n",
    "Processor,cores = get_cpu_info()\n",
    "print(f\"****** Completed Execution on processor {Processor} with {cores} cores ******\")\n",
    "# Calculate average creation time, elapsed time, quantum processing time, and circuit depth for each number of qubits\n",
    "avg_creation_times = []\n",
    "std_creation_times= []\n",
    "avg_elapsed_times = []\n",
    "std_elapsed_times= []\n",
    "avg_quantum_times = []\n",
    "std_quantum_times= []\n",
    "avg_circuit_depths = []\n",
    "avg_transpiled_depths = []\n",
    "avg_1Q_algorithmic_gate_counts = []\n",
    "avg_2Q_algorithmic_gate_counts = []\n",
    "avg_1Q_Transpiled_gate_counts = []\n",
    "avg_2Q_Transpiled_gate_counts = []\n",
    "avg_xi=[]\n",
    "avg_tr_xi=[]\n",
    "max_memory = []\n",
    "Qubits = []\n",
    "\n",
    "start = 0\n",
    "for num in numckts:\n",
    "    avg_creation_times.append(round(np.mean(creation_times[start:start+num]),3))\n",
    "    std_creation_times.append(round(np.std(creation_times[start:start+num])/np.sqrt(len(creation_times)), 3))\n",
    "    avg_elapsed_times.append(round(np.mean(elapsed_times[start:start+num]),3))\n",
    "    std_elapsed_times.append(round(np.std(elapsed_times[start:start+num])/np.sqrt(len(elapsed_times)), 3))\n",
    "    avg_quantum_times.append(round(np.mean(quantum_times[start:start+num]),3))\n",
    "    std_quantum_times.append(round(np.std(quantum_times[start:start+num])/np.sqrt(len(quantum_times)), 3))\n",
    "    avg_circuit_depths.append(round(np.mean(circuit_depths[start:start+num]),3))\n",
    "    avg_transpiled_depths.append(round(np.mean(transpiled_depths[start:start+num]),3))\n",
    "    if gate_counts_plots == True:\n",
    "        avg_1Q_algorithmic_gate_counts.append(round(np.mean(algorithmic_1Q_gate_counts[start:start+num]),2))\n",
    "        avg_2Q_algorithmic_gate_counts.append(round(np.mean(algorithmic_2Q_gate_counts[start:start+num]),2))\n",
    "        avg_xi.append(round(np.mean(xi[start:start+num]),2))\n",
    "        avg_1Q_Transpiled_gate_counts.append(round(np.mean(transpiled_1Q_gate_counts[start:start+num]),2))\n",
    "        avg_2Q_Transpiled_gate_counts.append(round(np.mean(transpiled_2Q_gate_counts[start:start+num]),2))\n",
    "        avg_tr_xi.append(round(np.mean(tr_xi[start:start+num]),2))\n",
    "    if Memory_utilization_plot == True:\n",
    "        max_memory.append(round(np.max(mem_usage[start:start+num]),2))\n",
    "    Qubits.append(int(np.mean(num_qubits_of_ckt[start:start+num])))\n",
    "    start += num\n",
    "\n",
    "\n",
    "# Calculate the fidelity data\n",
    "avg_f, avg_Hf, std_f, std_hf = plot_fidelity_data(fidelity_data, Hf_fidelity_data, \"Fidelity Comparison\")\n",
    "\n",
    "if Store_Data:\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    # Prepare the data dictionary\n",
    "    data = {\n",
    "        \"configuration\":{\n",
    "        \"min_qbits\":min_qbits,\n",
    "        \"max_qbits\":max_qbits,\n",
    "        \"skp_qubits\":skp_qubits,\n",
    "        \"num_ckts\":numckts,\n",
    "        \"Type_of_Simulator\":platform,\n",
    "        \"benchmark_name\":benchmark_name,\n",
    "        \"QV_\":QV_,\n",
    "        \"Processor\":Processor,\n",
    "        \"cores\":cores},\n",
    "        'Number of Qubits': Qubits,\n",
    "        \"avg_creation_times (ms)\": avg_creation_times,\n",
    "        \"std_creation_times (ms)\": std_creation_times,\n",
    "        \"avg_elapsed_times (ms)\": avg_elapsed_times,\n",
    "        \"std_elapsed_times (ms)\":std_elapsed_times,\n",
    "        \"avg_quantum_times (ms)\": avg_quantum_times,\n",
    "        \"std_quantum_times (ms)\":std_quantum_times,\n",
    "        \"avg_circuit_depths\": avg_circuit_depths,\n",
    "        \"avg_transpiled_depths\": avg_transpiled_depths,\n",
    "        \"Average_Rescaled_fidelity\":avg_f,\n",
    "        \"Average_Hellinger_fidelity\":avg_Hf,\n",
    "        \"std_Rescaled_Fidelity\":std_f,\n",
    "        \"std_hellinger_fidelity\":std_hf\n",
    "    }\n",
    "\n",
    "    if gate_counts_plots:\n",
    "        data[\"gate_counts_plots\"] =  gate_counts_plots\n",
    "        data[\"avg_1Q_algorithmic_gate_counts\"] =  avg_1Q_algorithmic_gate_counts\n",
    "        data[\"avg_2Q_algorithmic_gate_counts\"] =  avg_2Q_algorithmic_gate_counts\n",
    "        data[\"avg_xi (n2q/n1q+n2q)\"]=avg_xi\n",
    "        data[\"avg_1Q_Transpiled_gate_counts\"]= avg_1Q_Transpiled_gate_counts\n",
    "        data[\"avg_2Q_Transpiled_gate_counts\"]= avg_2Q_Transpiled_gate_counts\n",
    "        data[\"avg_tr_xi (tr_n2q/tr_n1q+tr_n2q)\"]=avg_tr_xi\n",
    "\n",
    "    if Memory_utilization_plot==True:\n",
    "        data[\"max_memory (MB)\"]= max_memory\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Add the timestamp to the data\n",
    "    data['last_updated'] = current_time\n",
    "    \n",
    "    # Define the file name\n",
    "    file_name = '__data.json'\n",
    "    \n",
    "    # Write the data to the file\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    \n",
    "    print(f\"***** Data has been saved to {file_name} ******\")\n",
    "\n",
    "    if save_to_excel: \n",
    "        #from Data_Plotter import update_excel_with_data\n",
    "        update_excel_with_data(f\"{benchmark_name} Benchmark-Results.xlsx\",data,Noise_Inclusion)\n",
    "        print(\"***** Data has been updated to Benchmark-Results.xlsx *****\")\n",
    "\n",
    "\n",
    "# Plot histograms for average creation time, average elapsed time, average quantum processing time, and average circuit depth versus the number of qubits\n",
    "\n",
    "# Add labels to the bars\n",
    "def autolabel(rects,ax,str='{:.3f}',text_color=\"black\"):\n",
    "        max_y_value=ax.get_ylim()[1]  # Get the maximum value on the y-axis\n",
    "        threshold=0.3*max_y_value   # Define threshold as 30% of max y-axis value\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            if height < threshold:\n",
    "                rotation = 90\n",
    "                va = 'bottom'  # Place text above the bar\n",
    "                xytext = (0, 3)  # Offset slightly above the bar\n",
    "            else:\n",
    "                rotation = 90\n",
    "                va = 'center'  # Place text inside the bar\n",
    "                xytext = (0, 0)  # No offset\n",
    "            ax.annotate(str.format(height),  # Formatting to two decimal places\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height/6),\n",
    "                        xytext=xytext,\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va=va, color=text_color, rotation=rotation)\n",
    "\n",
    "bar_width = 0.3\n",
    "\n",
    "# Determine the number of subplots and their arrangement\n",
    "if Memory_utilization_plot and gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7) = plt.subplots(7, 1, figsize=(18, 30))\n",
    "    # Plotting for both memory utilization and gate counts\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6, ax7 are available\n",
    "elif Memory_utilization_plot:\n",
    "    fig, (ax1, ax2, ax3, ax6, ax7) = plt.subplots(5, 1, figsize=(18, 30))\n",
    "    # Plotting for memory utilization only\n",
    "    # ax1, ax2, ax3, ax6, ax7 are available\n",
    "elif gate_counts_plots:\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(18, 30))\n",
    "    # Plotting for gate counts only\n",
    "    # ax1, ax2, ax3, ax4, ax5, ax6 are available\n",
    "else:\n",
    "    fig, (ax1, ax2, ax3, ax6) = plt.subplots(4, 1, figsize=(18, 30))\n",
    "    # Default plotting\n",
    "    # ax1, ax2, ax3, ax6 are available\n",
    "\n",
    "fig.suptitle(f\"General Benchmarks : {platform} - {benchmark_name} - {Processor}\", fontsize=16)\n",
    "\n",
    "\n",
    "ax1.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "x = ax1.bar(num_qubits_range, avg_creation_times, yerr=std_creation_times, capsize=15, color='deepskyblue')\n",
    "autolabel(ax1.patches, ax1)\n",
    "ax1.set_xlabel('Number of Qubits')\n",
    "ax1.set_ylabel('Average Creation Time (ms)')\n",
    "ax1.set_title('Average Creation Time vs Number of Qubits',fontsize=14)\n",
    "\n",
    "\n",
    "ax2.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "\n",
    "\n",
    "Elapsed= ax2.bar(np.array(num_qubits_range) - bar_width / 2, avg_elapsed_times,yerr=std_elapsed_times, capsize=15, width=bar_width, color='cyan', label='Elapsed Time')\n",
    "Quantum= ax2.bar(np.array(num_qubits_range) + bar_width / 2, avg_quantum_times,yerr=std_quantum_times, capsize=15,width=bar_width, color='deepskyblue',label ='Quantum Time')\n",
    "autolabel(Elapsed,ax2,str='{:.1f}')\n",
    "autolabel(Quantum,ax2,str='{:.1f}')\n",
    "ax2.set_xlabel('Number of Qubits')\n",
    "ax2.set_ylabel('Average Time (ms)')\n",
    "ax2.set_title('Average Time vs Number of Qubits')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Normalized = ax3.bar(np.array(num_qubits_range) - bar_width / 2, avg_transpiled_depths, color='cyan', label='Normalized Depth', width=bar_width)  # Adjust width here\n",
    "Algorithmic = ax3.bar(np.array(num_qubits_range) + bar_width / 2,avg_circuit_depths, color='deepskyblue', label='Algorithmic Depth', width=bar_width)  # Adjust width here\n",
    "autolabel(Normalized,ax3,str='{:.2f}')\n",
    "autolabel(Algorithmic,ax3,str='{:.2f}')\n",
    "ax3.set_xlabel('Number of Qubits')\n",
    "ax3.set_ylabel('Average Circuit Depth')\n",
    "ax3.set_title('Average Circuit Depth vs Number of Qubits')\n",
    "ax3.legend()\n",
    "\n",
    "if gate_counts_plots == True:\n",
    "    ax4.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_1Q_counts = ax4.bar(np.array(num_qubits_range) - bar_width / 2, avg_1Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_1Q_counts = ax4.bar(np.array(num_qubits_range) + bar_width / 2, avg_1Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_1Q_counts,ax4,str='{}')\n",
    "    autolabel(Algorithmic_1Q_counts,ax4,str='{}')\n",
    "    ax4.set_xlabel('Number of Qubits')\n",
    "    ax4.set_ylabel('Average 1-Qubit Gate Counts')\n",
    "    ax4.set_title('Average 1-Qubit Gate Counts vs Number of Qubits')\n",
    "    ax4.legend()\n",
    "    \n",
    "    ax5.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    Normalized_2Q_counts = ax5.bar(np.array(num_qubits_range) - bar_width / 2, avg_2Q_Transpiled_gate_counts, color='cyan', label='Normalized Gate Counts', width=bar_width)  # Adjust width here\n",
    "    Algorithmic_2Q_counts = ax5.bar(np.array(num_qubits_range) + bar_width / 2, avg_2Q_algorithmic_gate_counts, color='deepskyblue', label='Algorithmic Gate Counts', width=bar_width)  # Adjust width here\n",
    "    autolabel(Normalized_2Q_counts,ax5,str='{}')\n",
    "    autolabel(Algorithmic_2Q_counts,ax5,str='{}')\n",
    "    ax5.set_xlabel('Number of Qubits')\n",
    "    ax5.set_ylabel('Average 2-Qubit Gate Counts')\n",
    "    ax5.set_title('Average 2-Qubit Gate Counts vs Number of Qubits')\n",
    "    ax5.legend()\n",
    "\n",
    "\n",
    "ax6.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "Hellinger = ax6.bar(np.array(num_qubits_range) - bar_width / 2, avg_Hf,yerr=std_hf, capsize=15, width=bar_width, label='Hellinger Fidelity',color='cyan')  # Adjust width here\n",
    "Normalized = ax6.bar(np.array(num_qubits_range) + bar_width / 2, avg_f,yerr=std_f, capsize=15, width=bar_width, label='Normalized Fidelity', color='deepskyblue')  # Adjust width here\n",
    "autolabel(Hellinger,ax6,str='{:.2f}')\n",
    "autolabel(Normalized,ax6,str='{:.2f}')\n",
    "ax6.set_xlabel('Number of Qubits')\n",
    "ax6.set_ylabel('Average Value')\n",
    "ax6.set_title(\"Fidelity Comparison\")\n",
    "ax6.legend()\n",
    "\n",
    "if Memory_utilization_plot == True:\n",
    "    ax7.set_xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "    x = ax7.bar(num_qubits_range, max_memory, color='turquoise', width=bar_width, label=\"Memory Utilizations\")\n",
    "    autolabel(ax7.patches, ax7)\n",
    "    ax7.set_xlabel('Number of Qubits')\n",
    "    ax7.set_ylabel('Maximum Memory Utilized (MB)')\n",
    "    ax7.set_title('Memory Utilized vs Number of Qubits',fontsize=14)\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "if saveplots == True:\n",
    "    plt.savefig(\"ParameterPlotsSample.jpg\")\n",
    "plt.show()\n",
    "\n",
    "num_qubits_range = Qubits\n",
    "\n",
    "# Quantum Volume Plot\n",
    "Suptitle = f\"Volumetric Positioning - {platform}\"\n",
    "appname=benchmark_name\n",
    "if QV_ == None:\n",
    "    QV=2048\n",
    "else:\n",
    "    QV=QV_\n",
    "depth_base =2\n",
    "\n",
    "ax = plot_volumetric_background(max_qubits=max_qbits, QV=QV,depth_base=depth_base, suptitle=Suptitle, colorbar_label=\"Avg Result Fidelity\")\n",
    "\n",
    "w_data = num_qubits_range\n",
    "# determine width for circuit\n",
    "w_max = 0\n",
    "for i in range(len(w_data)):\n",
    "    y = float(w_data[i])\n",
    "    w_max = max(w_max, y)\n",
    "\n",
    "d_tr_data = avg_transpiled_depths\n",
    "f_data = avg_f\n",
    "\n",
    "plot_volumetric_data(ax, w_data, d_tr_data, f_data, depth_base, fill=True,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, w_max=w_max)\n",
    "anno_volumetric_data(ax, depth_base,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, fill=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
